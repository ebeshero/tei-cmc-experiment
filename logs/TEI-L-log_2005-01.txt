=========================================================================
Date:         Mon, 3 Jan 2005 21:30:57 -0500
Reply-To:     Eric Lease Morgan <emorgan@ND.EDU>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Eric Lease Morgan <emorgan@ND.EDU>
Subject:      english/spanish dictionary
Mime-Version: 1.0 (Apple Message framework v619)
Content-Transfer-Encoding: 7bit
Content-Type: text/plain; charset=US-ASCII; format=flowed

Does anybody here know of an electronic English/Spanish dictionary
designed for printing?

--
Eric Lease Morgan
=========================================================================
Date:         Tue, 4 Jan 2005 09:54:00 +0000
Reply-To:     James.Cummings@ota.ahds.ac.uk
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         James Cummings <James.Cummings@OTA.AHDS.AC.UK>
Organization: Oxford Text Archive
Subject:      Re: english/spanish dictionary
Comments: To: Eric Lease Morgan <emorgan@ND.EDU>
In-Reply-To:  <AA0BC05E-5DF8-11D9-B08F-000393875D4E@nd.edu>
MIME-Version: 1.0
Content-Type: TEXT/PLAIN; charset=US-ASCII

On Mon, 3 Jan 2005, Eric Lease Morgan wrote:

> Does anybody here know of an electronic English/Spanish dictionary
> designed for printing?

Eric,

You may wish to try:

http://sourceforge.net/projects/freedict/

I don't know of the status of their Spanish dictionary but
they have a GPL license, and their intention is eventually
to have them all in TEI XML format.  (I don't believe most
of them currently are, yet.)

-James

---
Dr James Cummings, Oxford Text Archive, University of Oxford
James dot Cummings at oucs dot ox dot ac dot uk
=========================================================================
Date:         Tue, 4 Jan 2005 10:37:42 -0500
Reply-To:     David Sewell <dsewell@VIRGINIA.EDU>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         David Sewell <dsewell@VIRGINIA.EDU>
Subject:      Placement of <pb/>
MIME-Version: 1.0
Content-Type: TEXT/PLAIN; charset=US-ASCII

When marking up a printed book and capturing page numbering, local
practice is often to insist that a <pb/> must go inside a <div> of
whatever type or level is used to represent the main document divisions.
For example, assuming a volume of correspondence where letter 150 ends
on verso page 100 and letter 151 starts at the top of recto page 101,
you would code something like

   <!--end of letter 150-->
   </div>
   <div type="letter" id="L151">
   <pb n="101">
   [etc.]

instead of

   <!--end of letter 150-->
   </div>
   <pb n="101">
   <div type="letter" id="L151">
   [etc.]

Doing things that way makes it somewhat easier to write code to
determine which document a page break occurs in, or which documents
start or end on a page. But it's certainly not impossible to use XPath
tests so as to deal with a milestone element that can occur at the
boundary between two <div>s as well as inside one.

So: is there any *philosophical* reason not to place a <pb/> between two
<div>s when that corresponds to the page structure?

--
David Sewell, Editorial and Technical Manager
Electronic Imprint, The University of Virginia Press
PO Box 400318, Charlottesville, VA 22904-4318 USA
Courier: 310 Old Ivy Way, Suite 302, Charlottesville VA 22903
Email: dsewell@virginia.edu   Tel: +1 434 924 9973
Web: http://www.ei.virginia.edu/
=========================================================================
Date:         Tue, 4 Jan 2005 11:55:15 -0500
Reply-To:     "John W. Kennedy" <jwkenne@ATTGLOBAL.NET>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         "John W. Kennedy" <jwkenne@ATTGLOBAL.NET>
Subject:      Re: Placement of <pb/>
In-Reply-To:  <Pine.OSX.4.61.0501041029080.23787@lister.ei.virginia.edu>
MIME-version: 1.0
Content-type: text/plain; charset=ISO-8859-1; format=flowed
Content-transfer-encoding: 7BIT

David Sewell wrote:
> So: is there any *philosophical* reason not to place a <pb/> between two
> <div>s when that corresponds to the page structure?

I would extend the discussion to <fw>, as well.

--
John W. Kennedy
"You can, if you wish, class all science-fiction together; but it is
about as perceptive as classing the works of Ballantyne, Conrad and W.
W. Jacobs together as the 'sea-story' and then criticizing _that_."
   -- C. S. Lewis.  "An Experiment in Criticism"
=========================================================================
Date:         Tue, 4 Jan 2005 15:09:52 -0500
Reply-To:     Syd_Bauman@Brown.edu
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Syd Bauman <Syd_Bauman@BROWN.EDU>
Subject:      Re: Placement of <pb/>
In-Reply-To:  <41DACA73.60109@attglobal.net>
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit

> > So: is there any *philosophical* reason not to place a <pb> [and
> > <fw>s] between two <div>s when that corresponds to the page
> > structure?

In general I think they belong between the <div>s. At first blush it
seems to me that if I were to retrive a single <div> from a work, I
wouldn't want the <pb> that separated it from its siblings included.
=========================================================================
Date:         Tue, 4 Jan 2005 15:19:55 -0500
Reply-To:     Julia Flanders <Julia_Flanders@BROWN.EDU>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Julia Flanders <Julia_Flanders@BROWN.EDU>
Subject:      Re: Placement of <pb/>
In-Reply-To:  <200501042009.j04K9sl20015@listserv.brown.edu>
Mime-Version: 1.0
Content-Type: text/plain; charset="us-ascii" ; format="flowed"

And, as a matter of philosophy, I would say that placing the <pb/>
and <fw> within the <div> may often be  simply incorrect, a poor
representation of textual reality. The chapter ends, and then there's
a page break, and then the next chapter begins. It's not really
possible (in my mind at least) to imagine the chapter somehow
continuing after the page break and finishing... where? at the top of
the next page?

Catchwords are an interesting dimension of all this, but I'd be
inclined to say that the catchword is also interstitial material, not
part of either division but rather part of the pagination framework
that falls between.

So I'd agree, these things should go between <div>s in cases like this.

Best wishes, Julia

>>  > So: is there any *philosophical* reason not to place a <pb> [and
>>  > <fw>s] between two <div>s when that corresponds to the page
>>  > structure?
>
>In general I think they belong between the <div>s. At first blush it
>seems to me that if I were to retrive a single <div> from a work, I
>wouldn't want the <pb> that separated it from its siblings included.
=========================================================================
Date:         Tue, 4 Jan 2005 17:13:02 -0500
Reply-To:     Francois Lachance <lachance@ORIGIN.CHASS.UTORONTO.CA>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Francois Lachance <lachance@ORIGIN.CHASS.UTORONTO.CA>
Subject:      Re: Placement of <pb/>
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit

I like Julia's explanation of what can be termed terminal page breaks. How
would it jive with <pb> internal to a <div>? Would it be another example
of <pb> as an element independent of a relationship to <div>. If <pb> is
indeed considered independent of <div>, then does it matter where the <pb>
occurs at for example a chapter's end?

A page break and a page turn. Is <pb> as an element of markup, a noun
representing an aspect of the text or is it an instruction indicating how
to process the marked up text?

A related question "What is a line?" is explored by Kari Kraus in a
September 2003 entry at accidentals and substantives
http://karik.wordherders.net/archives/000693.html

That I am able to imagine the end of the chapter coming after a page break
or turning of the page may simply mean that the representations of textual
realities with which I have truck are for the most part representations of
readings of textual artefacts. For example, in some cases especially in
works without pagination indicators, the words and images end on the recto
page, the verso is blank and the subsequent chapter begins on the next
leaf. Is the blank page outside of either chapter? If so, at what depth of
nesting does it belong?

I would suggest that retrieving <div> elements and the processing of
whatever <pb> elements may be present in the retrieved elements are
separate activities producing different but congruent textual realities.




> And, as a matter of philosophy, I would say that placing the <pb/>
> and <fw> within the <div> may often be  simply incorrect, a poor
> representation of textual reality. The chapter ends, and then there's
> a page break, and then the next chapter begins. It's not really
> possible (in my mind at least) to imagine the chapter somehow
> continuing after the page break and finishing... where? at the top of
> the next page?
>
> Catchwords are an interesting dimension of all this, but I'd be
> inclined to say that the catchword is also interstitial material, not
> part of either division but rather part of the pagination framework
> that falls between.
>
> So I'd agree, these things should go between <div>s in cases like this.
>
> Best wishes, Julia
>
> >>  > So: is there any *philosophical* reason not to place a <pb> [and
> >>  > <fw>s] between two <div>s when that corresponds to the page
> >>  > structure?
> >
> >In general I think they belong between the <div>s. At first blush it
> >seems to me that if I were to retrive a single <div> from a work, I
> >wouldn't want the <pb> that separated it from its siblings included.
>


--
Francois Lachance, Scholar-at-large
http://www.chass.utoronto.ca/~lachance

A calendar is like a map. And just as maps have insets, calendars in the
21st century might have 'moments' expressed in flat local time fanning out
into "great circles" expressed in earth revolution time.
=========================================================================
Date:         Tue, 4 Jan 2005 20:48:16 EST
Reply-To:     DrWender@AOL.COM
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Herbert Wender <DrWender@AOL.COM>
Subject:      Re: Placement of <pb/>
MIME-Version: 1.0
Content-Type: multipart/alternative;
              boundary="part1_90.54751125.2f0ca160_boundary"

--part1_90.54751125.2f0ca160_boundary
Content-Type: text/plain; charset="ISO-8859-1"
Content-Transfer-Encoding: quoted-printable

In einer eMail vom 04.01.05 21:21:00 (MEZ) Mitteleurop=E4ische Zeit schreibt=
=20
Julia_Flanders@BROWN.EDU:


> Catchwords are an interesting dimension of all this, but I'd be
> inclined to say that the catchword is also interstitial material, not
> part of either division but rather part of the pagination framework
> that falls between.
>=20
Bravo! And therefore a language for page description
(dt.: Seitenbeschreibungssprache) - like PostScript -
should be to prefer in contexts where given materials
- books, manuscripts, typoscripts ... . are to be
described for purposes of textual critic.
The problem with "PB" is the same as with other
so-called "milestones" standing per definitionem for
the Nothing between to things, her between to leafs
resp. the two sides of one.
Marking up without milestones but with overlapping
physical resp. logical structure descriptions would give a=20
cleaner representation of the given relations, especially=20
when priority is given to the physical aspects:

...
<page no=3D"123">
<divX part=3Di>
...
</divX>
</page>
<page no=3D"124">
...

Phenomena like catchwords etc. can be placed as
found on the page: between </div> and </page>, or
at top between <page> and <div>, f.e. when on a single
page an error occurs in the 'Kolumnentitel' (an error
impossible in contexts of strict SGML-based text=20
processing, but not in the materials to describe in
contexts of textual critic).=20

Best wishes for the New Year,
hw


--part1_90.54751125.2f0ca160_boundary
Content-Type: text/html; charset="ISO-8859-1"
Content-Transfer-Encoding: quoted-printable

<HTML><FONT FACE=3Darial,helvetica><HTML><FONT  SIZE=3D3 PTSIZE=3D12 FAMILY=
=3D"SANSSERIF" FACE=3D"Arial" LANG=3D"2">In einer eMail vom 04.01.05 21:21:0=
0 (MEZ) Mitteleurop=E4ische Zeit schreibt Julia_Flanders@BROWN.EDU:<BR>
<BR>
</FONT><FONT  COLOR=3D"#000000" BACK=3D"#ffffff" style=3D"BACKGROUND-COLOR:=20=
#ffffff" SIZE=3D2 PTSIZE=3D10 FAMILY=3D"SANSSERIF" FACE=3D"Arial" LANG=3D"2"=
><BR>
<BLOCKQUOTE TYPE=3DCITE style=3D"BORDER-LEFT: #0000ff 2px solid; MARGIN-LEFT=
: 5px; MARGIN-RIGHT: 0px; PADDING-LEFT: 5px">Catchwords are an interesting d=
imension of all this, but I'd be<BR>
inclined to say that the catchword is also interstitial material, not<BR>
part of either division but rather part of the pagination framework<BR>
that falls between.<BR>
</BLOCKQUOTE><BR>
</FONT><FONT  COLOR=3D"#000000" BACK=3D"#ffffff" style=3D"BACKGROUND-COLOR:=20=
#ffffff" SIZE=3D3 PTSIZE=3D12 FAMILY=3D"SANSSERIF" FACE=3D"Arial" LANG=3D"2"=
>Bravo! And therefore a language for page description<BR>
(dt.: Seitenbeschreibungssprache) - like PostScript -<BR>
should be to prefer in contexts where given materials<BR>
- books, manuscripts, typoscripts ... . are to be<BR>
described for purposes of textual critic.<BR>
The problem with "PB" is the same as with other<BR>
so-called "milestones" standing per definitionem for<BR>
the Nothing between to things, her between to leafs<BR>
resp. the two sides of one.<BR>
Marking up without milestones but with overlapping<BR>
physical resp. logical structure descriptions would give a <BR>
cleaner representation of the given relations, especially <BR>
when priority is given to the physical aspects:<BR>
<BR>
...<BR>
&lt;page no=3D"123"&gt;<BR>
&lt;divX part=3Di&gt;<BR>
...<BR>
&lt;/divX&gt;<BR>
&lt;/page&gt;<BR>
&lt;page no=3D"124"&gt;<BR>
...<BR>
<BR>
Phenomena like catchwords etc. can be placed as<BR>
found on the page: between &lt;/div&gt; and &lt;/page&gt;, or<BR>
at top between &lt;page&gt; and &lt;div&gt;, f.e. when on a single<BR>
page an error occurs in the 'Kolumnentitel' (an error<BR>
impossible in contexts of strict SGML-based text <BR>
processing, but not in the materials to describe in<BR>
contexts of textual critic). <BR>
<BR>
Best wishes for the New Year,<BR>
hw<BR>
<BR>
</FONT></HTML>
--part1_90.54751125.2f0ca160_boundary--
=========================================================================
Date:         Wed, 5 Jan 2005 10:18:44 +0000
Reply-To:     Peter Flynn <pflynn@UCC.IE>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Peter Flynn <pflynn@UCC.IE>
Organization: University College Cork
Subject:      Re: Placement of <pb/>
In-Reply-To:  <16858.63504.242863.883201@emt.wwp.brown.edu>
Content-Type: text/plain
Mime-Version: 1.0
Content-Transfer-Encoding: 7bit

On Tue, 2005-01-04 at 20:09, Syd Bauman wrote:
> > > So: is there any *philosophical* reason not to place a <pb> [and
> > > <fw>s] between two <div>s when that corresponds to the page
> > > structure?
>
> In general I think they belong between the <div>s. At first blush it
> seems to me that if I were to retrive a single <div> from a work, I
> wouldn't want the <pb> that separated it from its siblings included.

Umm. But I might want to know what page it was...

Arguably that is metadata, and should be retrieved by the
search engine and displayed alongside, but not rendered as
part of the retrieved text. Retrievals must, in effect, do
an equivalent of XPath's preceding::pb or following::pb to
get the relevant page number if they are to provide this
kind of referenctial material.

I agree that PBs belong between DIVs, if page divisions
exist (in normal running text, of course, they may occur
at arbitrary places in mid-sentence or even mid-word,
which raises a whole other set of questions about whether
you include a leading or following space or not...)

On the other hand, in a full-scale document retrieval system
you probably *do* want the page-break element retrieved, so
that a subsequent display-formatter can do a full-page
typographic rendition, including the page number. That,
of course, doesn't mean the PB element has to be inside a
DIV instead of between them, if the retrieval engine can
grab the value without penalty, but it would make it far
simpler for the retrieval process if the page number came
with the retrieved DIV.

Catchwords are an interesting exception, being completely
non-structural, and just an accidental artifice of how the
words on the page happened to fall (leaving aside those
books where the author majorly influenced the compositor :-)
I would rather see the catchword or word-fragment marked
as such using additional inline markup on the word itself,
rather than added as an extra token in between DIVs. Maybe
I'm old-fashioned, but for me, textual integrity (of the
physical sort, not the metaphysical) consists in being able
to strip the markup and be left with reprocessable text,
so I wouldn't want intrusive extra occurrences of words or
word-fragments. But I digress :-)

///Peter
=========================================================================
Date:         Wed, 5 Jan 2005 13:45:56 +0000
Reply-To:     Richard Higgins <r.i.higgins@DURHAM.AC.UK>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Richard Higgins <r.i.higgins@DURHAM.AC.UK>
Subject:      Manuscript description module (P5) problems
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii; format=flowed
Content-Transfer-Encoding: 7bit

I think I have raised this first point already, so apologies for any
repetition if it has been addressed and I haven't found the new version.

In order for the manuscript description to work for creating catalogues
of manuscripts, the descriptions should be repeatable in the body,
rather than in the header, but currently it is only possible to describe
manuscripts in the header. As far as I can see the entry in
teiclasses.dtd (line 50 of the 2004-04-11 version) should substitute
"%n.msDescription;" for "%n.msIdentifier;". Only by doing this is it
possible to enter multiple full descriptions of manuscripts.

One other quibble. The element locus only allows text content, where it
would be useful to be able to have some means of introducing
superscript. Otherwise it is impossible to distinguish between "v"
abbreviating verso and "v" the Roman numeral. It is conventional to use
Roman numerals for prefatory pages added to a volume. In this situation
it may not be completely obvious if "ff. iv - xv" refers to folios 1
verso to 10 verso or folios 4 to 15.

--
# Richard Higgins
# Durham University Library
# Archives & Special Collections
# Palace Green
# Durham
# DH1 3RN
# E-Mail: r.i.higgins@durham.ac.uk
=========================================================================
Date:         Wed, 5 Jan 2005 11:19:47 -0500
Reply-To:     Francois Lachance <lachance@ORIGIN.CHASS.UTORONTO.CA>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Francois Lachance <lachance@ORIGIN.CHASS.UTORONTO.CA>
Subject:      Manuscript description module (P5) problems
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit

One of Richard's questions raises another for me. Is it indeed
"superscripts" that is the object of the encoding or is it the distinction
between number and abbreviation?


> One other quibble. The element locus only allows text content, where it
> would be useful to be able to have some means of introducing
> superscript. Otherwise it is impossible to distinguish between "v"
> abbreviating verso and "v" the Roman numeral. It is conventional to use
> Roman numerals for prefatory pages added to a volume. In this situation
> it may not be completely obvious if "ff. iv - xv" refers to folios 1
> verso to 10 verso or folios 4 to 15.


ff. <num>i</num><abbr>v</abbr> to <num>x</num><abbr>v</abbr>

General entity references could be created for frequently used
abbreviations.

For example

<!ENTITY v "&lt;abbr*gt;v&lt;/abbr&gt;">

allowing for

        &v;

in the markup.

--
Francois Lachance, Scholar-at-large
http://www.chass.utoronto.ca/~lachance

A calendar is like a map. And just as maps have insets, calendars in the
21st century might have 'moments' expressed in flat local time fanning out
into "great circles" expressed in earth revolution time.
=========================================================================
Date:         Wed, 5 Jan 2005 11:10:55 -0500
Reply-To:     Julia Flanders <Julia_Flanders@BROWN.EDU>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Julia Flanders <Julia_Flanders@BROWN.EDU>
Subject:      Re: Placement of <pb/>
In-Reply-To:  <200501051018.j05AIql19882@listserv.brown.edu>
Mime-Version: 1.0
Content-Type: text/plain; charset="us-ascii" ; format="flowed"

This is pretty much what I would hope for: put the <pb/> in the
representationally right place, and accommodate your processing to
get the results you need. The retrieval engine should be able to find
the relevant value from the <pb/> without having the <pb/> suffer an
artificial location.

>On the other hand, in a full-scale document retrieval system
>you probably *do* want the page-break element retrieved, so
>that a subsequent display-formatter can do a full-page
>typographic rendition, including the page number. That,
>of course, doesn't mean the PB element has to be inside a
>DIV instead of between them, if the retrieval engine can
>grab the value without penalty, but it would make it far
>simpler for the retrieval process if the page number came
>with the retrieved DIV.

I think the key in what you say below is the word "reprocessable".
Encoding a catchword as <fw type="catch">inter-</fw> *does* allow you
to strip the markup and leave behind a reprocessable text. The
wrinkle is that your conception of reprocessing here is an idealizing
one that regards the original book (with its page breaks) as a form
of processing. That's fine, and that's why you encoded the catchword
as <fw type="catch">, so that you could not only strip out the
markup, but also strip out the words-on-the-page that are part of the
original "processing" and reveal the "unprocessed" text as you
understand it. I don't see that you lose any functionality here. But
given the growing critical significance of the physical disposition
of words and the configuration of language in physical form,
approaches to encoding that retain the original "processing" have a
certain extra usefulness.

Having said that, I'm not sure that your proposed alternative markup
of the catchword (as additional inline markup of the word itself)
would be less useful as evidence of the original layout. But we were
really discussing encoding philosophy, not practical outcomes.

Best wishes, Julia

>Catchwords are an interesting exception, being completely
>non-structural, and just an accidental artifice of how the
>words on the page happened to fall (leaving aside those
>books where the author majorly influenced the compositor :-)
>I would rather see the catchword or word-fragment marked
>as such using additional inline markup on the word itself,
>rather than added as an extra token in between DIVs. Maybe
>I'm old-fashioned, but for me, textual integrity (of the
>physical sort, not the metaphysical) consists in being able
>to strip the markup and be left with reprocessable text,
>so I wouldn't want intrusive extra occurrences of words or
>word-fragments. But I digress :-)
>
>///Peter
=========================================================================
Date:         Wed, 5 Jan 2005 16:34:03 +0000
Reply-To:     Peter Flynn <pflynn@UCC.IE>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Peter Flynn <pflynn@UCC.IE>
Organization: University College Cork
Subject:      Re: Placement of <pb/>
In-Reply-To:  <a0620070dbe01bea7a7c2@[128.148.157.102]>
Content-Type: text/plain
Mime-Version: 1.0
Content-Transfer-Encoding: 7bit

On Wed, 2005-01-05 at 16:10, Julia Flanders wrote:
> I think the key in what you say below is the word "reprocessable".
> Encoding a catchword as <fw type="catch">inter-</fw> *does* allow you
> to strip the markup and leave behind a reprocessable text. The
> wrinkle is that your conception of reprocessing here is an idealizing
> one that regards the original book (with its page breaks) as a form
> of processing. That's fine, and that's why you encoded the catchword
> as <fw type="catch">, so that you could not only strip out the
> markup, but also strip out the words-on-the-page that are part of the
> original "processing" and reveal the "unprocessed" text as you
> understand it. I don't see that you lose any functionality here. But
> given the growing critical significance of the physical disposition
> of words and the configuration of language in physical form,
> approaches to encoding that retain the original "processing" have a
> certain extra usefulness.

Absolutely. Idealized is right: my requirements are rather different
from those of the lit crit, and I certainly don't have a problem
with the catchword being included between pages as well, so long as
it's marked unambiguously. Making a modern typographical facsimile
requires the markup to be precise.

The PB task becomes more interesting when you find an encoder has put
it in a different place on chapter-start pages, because the printer
has put it in a different place (ie bottom center instead of top L/R
or whatever). To say nothing of the nouvelle vague typography of
magazines, which places it in a reversed-out tint bleeding off the
foredge, vertically positioned according to how far through the mag
you are :-)

///Peter
=========================================================================
Date:         Wed, 5 Jan 2005 16:40:37 +0000
Reply-To:     Sebastian Rahtz <sebastian.rahtz@COMPUTING-SERVICES.OXFORD.AC.UK>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Sebastian Rahtz <sebastian.rahtz@COMPUTING-SERVICES.OXFORD.AC.UK>
Subject:      Re: Placement of <pb/>
Comments: To: Peter Flynn <pflynn@UCC.IE>
In-Reply-To:  <200501051634.j05GY9l23089@listserv.brown.edu>
MIME-Version: 1.0
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit

Peter Flynn wrote:

>
>The PB task becomes more interesting when you find an encoder has put
>it in a different place on chapter-start pages, because the printer
>has put it in a different place (ie bottom center instead of top L/R
>or whatever). To say nothing of the nouvelle vague typography of
>magazines, which places it in a reversed-out tint bleeding off the
>foredge, vertically positioned according to how far through the mag
>you are :-)
>
>
I'd say this was a rendition property of the entire document, to be
encoded somewhere (where?) in the header, along with things like
text body width, default font family, border widths etc.

--
Sebastian Rahtz
Information Manager, Oxford University Computing Services
13 Banbury Road, Oxford OX2 6NN. Phone +44 1865 283431

OSS Watch: JISC Open Source Advisory Service
http://www.oss-watch.ac.uk
=========================================================================
Date:         Wed, 5 Jan 2005 11:50:42 -0500
Reply-To:     "Paul F. Schaffner" <pfs@UMICH.EDU>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         "Paul F. Schaffner" <pfs@UMICH.EDU>
Subject:      Re: Placement of <pb/>
In-Reply-To:  <1104920323.16528.187.camel@oimelc.ucc.ie>
MIME-Version: 1.0
Content-Type: TEXT/PLAIN; charset=US-ASCII

Driven as usual by expediency of retrieval more than by metaphysics, we've
continued to encode as </div><div><pb/> rather than </div><pb/><div>
(and indeed also as </p><p><pb/> etc.) albeit with a bad conscience
and unhappy awareness that <pb/>s really belong between things.

But I've also been moving in two other, and perhaps contradictory,
directions: (1) explicitly to treat the <pb> as a container for
page-level metadata, by abandoning its empty status and instead allowing
it to contain other page-level elements--specifically, <fw>; and
(2) (for books in which the major divs are typically smaller than a
page, but we nevertheless wish to record within each div information
about the page on which it appears) to move the metadata function
of the <pb> into a second element (e.g. <pr> = 'page reference') that
can appear virtually anywhere in the text stream, independent
of the physical page-turning event. The natural convergence of
these two impulses would be a divorce between the two functions of
<pb>: (1) to mark an event, and (2) to contain page-level metadata
(including running headers, page numbers, sequence numbers, catchwords,
and quire signatures) with the latter function moved to or at
least duplicated in the new element. One could thus encode
</div><pb/><div><pr><fw>...</fw></pr> etc.


If we're going to talk about page-breaks, here's another simple
question: how do you record the page turning information when
the reading sequence of the text requires that one turn the
same page more than once? E.g. in a multi-column text, in
which the text sequence proceeds through a paragraph at the top of
page 1, then hits a column split and goes down the left column
of page 1, onto the left column of page 2, then back to the middle
of page 1 (at the top of the right column), then down that
column and onto the right column of page 2. Is each turning of the
page a <pb>? Even when that turning is 'back' or when it leads to
or from somewhere in the middle of the page, not the top or bottom?
If you don't encode this way (as crudely illustrated below), what
*do* you do?

pfs
--------------------------------------------------------------------
Paul Schaffner | pfs@umich.edu | http://www-personal.umich.edu/~pfs/
316 Hatcher Library N, Univ. of Michigan, Ann Arbor MI 48109-1205
--------------------------------------------------------------------

   -p.1-                   -p.2-
  xxxxxxxxxxx         yyyy     zzzz
xxxxxxxxxxxxx         yyyy     zzzz
xxxxxxxxxxxxx         yyyy     zzzz
                      yyyy     zzzz
yyyy     zzzz         yyyy     zzzz
yyyy     zzzz
yyyy     zzzz          qqqqqqqqqqqq
yyyy     zzzz         qqqqqqqqqqqqq
yyyy     zzzz         qqqqqqqqqqqqq


<pb n="1">
<p>xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx</p>
<p>yyyyyyyyyyyy<pb n="2">yyyyyyyyyy</p>
<pb n="1">
<p>zzzzzzzzzzzz<pb n="2">zzzzzzzzzz</p>
<p>qqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqq</p>
=========================================================================
Date:         Wed, 5 Jan 2005 13:04:59 -0500
Reply-To:     Francois Lachance <lachance@ORIGIN.CHASS.UTORONTO.CA>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Francois Lachance <lachance@ORIGIN.CHASS.UTORONTO.CA>
Subject:      Re: Placement of <pb/> and <fw>
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit

In Paul's redesciption of the <pb> question into event / metadata
categories, I'm intrigued by the suggestion of capturing pagination
information through the <fw> element.


> <pb>: (1) to mark an event, and (2) to contain page-level metadata
> (including running headers, page numbers, sequence numbers, catchwords,
> and quire signatures) with the latter function moved to or at
> least duplicated in the new element. One could thus encode
> </div><pb/><div><pr><fw>...</fw></pr> etc.


But why create a new element?

<fw type="pageno" place="top-right">29</fw>

See 18.3 Headers, Footers, and Similar Matter
of the P4 Guidelines :

http://www.tei-c.org/P4X/PH.html#PHSK

See as well http://www.tei-c.org/P4X/ref-FW.html

<quote>
Where running heads are consistent throughout a chapter or section, it is
usually more convenient to relate them to the chapter or section, e.g. by
use of the rend attribute. The <fw> element is intended for cases where
the running head changes from page to page, or where details of page
layout and the internal structure of the running heads, are of paramount
importance.
</quote>


This passage from the Guidelines and Paul's multi-column spread over more
than one page lead me back to ask what is being encoded by <pb>. If it is
page numbering, read <pb> as similar to framework of type page number.
If it is a break in the flow of text, read <pb> as "break to next
page" (similar to reading <lb> as "break to next line").

The encoding of typographic line breaks in prose raises similar issues:
<quote>
Encoders should adopt a clear and consistent policy as to whether the
numbers associated with line breaks relate to the physical sequence number
of the line within the page, or to some aspect of the logical structure of
the text.
</quote>
http://www.tei-c.org/P4X/ref-LINEBR.html


Tangent:
Has anyone experience in marking up typescript where there is evidence
of line feeds without carriage returns? I think the case of CRLFs helps
by analogy separate out the page break from the page numeration. It seems
that <pb> has been used both to mark a break in the flow of the text and
to capture information about pagination.



--
Francois Lachance, Scholar-at-large
http://www.chass.utoronto.ca/~lachance

A calendar is like a map. And just as maps have insets, calendars in the
21st century might have 'moments' expressed in flat local time fanning out
into "great circles" expressed in earth revolution time.
=========================================================================
Date:         Wed, 5 Jan 2005 14:20:24 -0500
Reply-To:     Syd_Bauman@Brown.edu
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Syd Bauman <Syd_Bauman@BROWN.EDU>
Subject:      Re: Placement of <pb/>
In-Reply-To:  <1104920323.16528.187.camel@oimelc.ucc.ie>
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit

> > In general I think they belong between the <div>s. At first blush
> > it seems to me that if I were to retrive a single <div> from a
> > work, I wouldn't want the <pb> that separated it from its
> > siblings included.
>
> Umm. But I might want to know what page it was...

Absolutely! But that holds true even if the element you are
extracting is an entire <div0> or a single <c>. So even in cases
where it is *very* unlikely that a <pb> would be inside the element
extracted, you'd like to have software that told you what page it
came from. So the preceding::pb sort of method is a must-have :-)
=========================================================================
Date:         Wed, 5 Jan 2005 20:44:44 +0000
Reply-To:     Lou Burnard <lou.burnard@COMPUTING-SERVICES.OXFORD.AC.UK>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Lou Burnard <lou.burnard@COMPUTING-SERVICES.OXFORD.AC.UK>
Subject:      Re: Placement of <pb/>
Comments: To: "Paul F. Schaffner" <pfs@UMICH.EDU>
In-Reply-To:  <200501051650.j05Goil24703@listserv.brown.edu>
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii; format=flowed
Content-Transfer-Encoding: 7bit

Paul F. Schaffner wrote:

> Driven as usual by expediency of retrieval more than by metaphysics, we've
> continued to encode as </div><div><pb/> rather than </div><pb/><div>
> (and indeed also as </p><p><pb/> etc.) albeit with a bad conscience
> and unhappy awareness that <pb/>s really belong between things.

I wonder about that. Seems to me that if you're using <div>s to organize
your text, then the <pb/>s should be neither between nor within the
<div>s. Think of them as manifestations intruding from another dimension
entirely. From the div perspective, their traces might look like points,
popping up here and there in our dimension, but really they are beings
of another kilter altogether. Even when they happen to pop up inside a
<div>, they're not *really* in it -- they just happen to have come
through some inter-dimensional wormhole at that point.
=========================================================================
Date:         Wed, 5 Jan 2005 16:14:17 -0500
Reply-To:     David Sewell <dsewell@VIRGINIA.EDU>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         David Sewell <dsewell@VIRGINIA.EDU>
Subject:      Re: Placement of <pb/>
In-Reply-To:  <16860.15864.556123.153109@emt.wwp.brown.edu>
MIME-Version: 1.0
Content-Type: TEXT/PLAIN; charset=US-ASCII

On Wed, 5 Jan 2005, Syd Bauman wrote:

> So even in cases
> where it is *very* unlikely that a <pb> would be inside the element
> extracted, you'd like to have software that told you what page it
> came from. So the preceding::pb sort of method is a must-have :-)

Ha. How did I guess that my query would create a TEI-L thread leading to
ontological debate and ending up in science fiction? I appreciate all
the thoughts on justification for various usage choices; we've started
out with a "put the <pb> where it falls" practice and will stick with
that as house style.

Meanwhile, I'll offer a bit of sample XML markup and XSLT code to
address the processing/retrieval issue. It's not really too hard to
locate milestone elements relative to container elements even when they
can fall inside or between those elements. Examples are here:

http://lister.ei.virginia.edu/~drs2n/pb-handling-example.html

This is only one approach.

--
David Sewell, Editorial and Technical Manager
Electronic Imprint, The University of Virginia Press
PO Box 400318, Charlottesville, VA 22904-4318 USA
Courier: 310 Old Ivy Way, Suite 302, Charlottesville VA 22903
Email: dsewell@virginia.edu   Tel: +1 434 924 9973
Web: http://www.ei.virginia.edu/
=========================================================================
Date:         Wed, 5 Jan 2005 21:36:55 +0000
Reply-To:     Sebastian Rahtz <sebastian.rahtz@COMPUTING-SERVICES.OXFORD.AC.UK>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Sebastian Rahtz <sebastian.rahtz@COMPUTING-SERVICES.OXFORD.AC.UK>
Subject:      Re: Placement of <pb/>
Comments: To: David Sewell <dsewell@VIRGINIA.EDU>
In-Reply-To:  <200501052119.j05LJpl16322@listserv.brown.edu>
MIME-Version: 1.0
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit

David Sewell wrote:

>http://lister.ei.virginia.edu/~drs2n/pb-handling-example.html
>
>
I have some slight concern about preceding::pb[1]. I suspect that
some XSLT implementations will find this expensive. Can anyone
confirm this in practice?

to nitpick, I propose

 <xsl:if test="ancestor::div">
                  <li><xsl:value-of select="ancestor::div/@id"/></li>
 </xsl:if>

should have [1] after the second "div". and in the elegant

 <xsl:for-each select="following::div[preceding::pb[1][@n=$pageNo]]">

   <li><xsl:value-of select="@id"/></li>
 </xsl:for-each>

I suspect the result is incorrect when the last div has multiple pages.

--
Sebastian Rahtz
Information Manager, Oxford University Computing Services
13 Banbury Road, Oxford OX2 6NN. Phone +44 1865 283431

OSS Watch: JISC Open Source Advisory Service
http://www.oss-watch.ac.uk
=========================================================================
Date:         Wed, 5 Jan 2005 23:27:53 -0000
Reply-To:     Michael Beddow <mbteil-2@mbeddow.net>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Michael Beddow <mbteil-2@MBEDDOW.NET>
Subject:      Re: Placement of <pb/>
MIME-Version: 1.0
Content-Type: text/plain; charset="iso-8859-1"
Content-Transfer-Encoding: 7bit

Sebastian Rahtz wrote:

> to nitpick, I propose
>
>  <xsl:if test="ancestor::div">
>                   <li><xsl:value-of select="ancestor::div/@id"/></li>
>  </xsl:if>
>
> should have [1] after the second "div".

Actually, I think that's rather an important amendment. Without it, the (not
implausible) addition of
<div type = "month" id="M7">
[...]
</div>
enclosing the existing <div>s would break this piece of the code.

I'll expand on this a bit, because it's something that people finding their
way around XPath axes often find confusing. The name of the axis "ancestor"
(like the similarly singular "sibling", "preceding-sibling",
"following-sibling" axes) is singular because there's only one axis. But
along that one axis, looking from the current node, lie ALL the ancestorS of
that node, including the document root. And if the current node has more
than one ancestor matching our pattern, we will get a node set (or a
sequence) containing *all* those matches. Now (to really add to the
confusion) although the processor moves backwards from the current node
along the ancestor axis, i.e. in reverse document order,  when *gathering*
the nodes for us, if we inspect the resulting nodeset/sequence after it has
been assembled, we will find it is in document order. So if, after
modifying the document so that it acquires an enclosing <div> of type
"month" round all the entry <div>s, we just ask for ancestor::div/@id, we
will get the id value of the first item in the resulting nodeset, i.e. the
id of the first ancestor div *in document order*, the one of type="month",
which is not what we want. However, when used along a reverse axis while the
nodes are being gathered, the position()=N function or its abbreviated
predicate form [N] counts the nodes as they are encountered in reverse
document order, so Sebastian's modification to ancestor::div[1]/@id will
always give us what we really want, the id value of the innermost enclosing
div of the current node (the first one the processor meets going backwards
along the ancestor axis) no matter how many enclosing divs there may be.

Michael Beddow






 and in the elegant
>
>  <xsl:for-each select="following::div[preceding::pb[1][@n=$pageNo]]">
>
>    <li><xsl:value-of select="@id"/></li>
>  </xsl:for-each>
>
> I suspect the result is incorrect when the last div has multiple pages.
>
> --
> Sebastian Rahtz
> Information Manager, Oxford University Computing Services
> 13 Banbury Road, Oxford OX2 6NN. Phone +44 1865 283431
>
> OSS Watch: JISC Open Source Advisory Service
> http://www.oss-watch.ac.uk
>
=========================================================================
Date:         Wed, 5 Jan 2005 18:33:43 -0500
Reply-To:     "John W. Kennedy" <jwkenne@ATTGLOBAL.NET>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         "John W. Kennedy" <jwkenne@ATTGLOBAL.NET>
Subject:      Re: Placement of <pb/> and <fw>
In-Reply-To:  <200501051805.NAA76543@origin.chass.utoronto.ca>
MIME-version: 1.0
Content-type: text/plain; charset=ISO-8859-1; format=flowed
Content-transfer-encoding: 7BIT

Here, for whatever it's worth, is what I did with the first act break in
"Double Falshood". (Reformatted for human readability.)

         <stage type="exit" rend="italic">
           <hi rend="roman">[</hi>Exit.
         </stage>
       </sp>
       <stage type="curtain" rend="italic">
         End of the First Act.
         <figure><figDesc>Floral tailpiece</figDesc></figure>
         <fw place="bottom-right" type="catch">ACT</fw>
       </stage>
     </div2>
   </div1>
   <div1 type="act" id="II" n="II">
     <div2 type="scene" id="II.i" n="i">
       <head>
         <pb n="13"/>
         <fw place="top-centre" type="head">
           <hi rend="italic">The</hi>
           <hi rend="smallCaps">
             <orig reg="Distressed">Distrest</orig> Lovers.
           </hi>
         </fw>
         <fw place="top-right" type="page">13</fw>
         <figure><figDesc>Floral bar with bowl</figDesc></figure>
         ACT II. SCENE I.
       </head>
       <stage type="scene" rend="italic">
         <hi rend="roman">SCENE,</hi>
         The Prospect of a Village.
       </stage>

--
John W. Kennedy
"The poor have sometimes objected to being governed badly; the rich have
always objected to being governed at all."
   -- G. K. Chesterton.  "The Man Who Was Thursday"
=========================================================================
Date:         Thu, 6 Jan 2005 00:26:20 +0000
Reply-To:     Sebastian Rahtz <sebastian.rahtz@COMPUTING-SERVICES.OXFORD.AC.UK>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Sebastian Rahtz <sebastian.rahtz@COMPUTING-SERVICES.OXFORD.AC.UK>
Subject:      tei xsl stylesheets, v 3.12
In-Reply-To:  <41DBB5FE.5020306@computing-services.oxford.ac.uk>
MIME-Version: 1.0
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit

I have updated all public copies of my XSLT stylesheet family to version
3.12. This is
still an interim update, pending a complete reorganisation, but it fixes
an important
problem reported by Liam Magee and (maybe even more importantly) includes
some test  files, if you get the master copies from CVS in Sourceforge.

The test runs some of the stylesheets using xsltproc, Saxon  and Xalan,
which caught
some odd nasties - I have been using only xsltproc for some time, and had
forgotten that it is sometimes too forgiving (eg of duplicate templates).

No, I haven't resolved the license issue yet.

--
Sebastian Rahtz
Information Manager, Oxford University Computing Services
13 Banbury Road, Oxford OX2 6NN. Phone +44 1865 283431

OSS Watch: JISC Open Source Advisory Service
http://www.oss-watch.ac.uk
=========================================================================
Date:         Thu, 6 Jan 2005 10:04:34 +0000
Reply-To:     Peter Flynn <pflynn@UCC.IE>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Peter Flynn <pflynn@UCC.IE>
Organization: University College Cork
Subject:      Re: Placement of <pb/>
In-Reply-To:  <41DC1885.5070308@computing-services.oxford.ac.uk>
Content-Type: text/plain
Mime-Version: 1.0
Content-Transfer-Encoding: 7bit

On Wed, 2005-01-05 at 16:40, Sebastian Rahtz wrote:
> Peter Flynn wrote:
>
> >
> >The PB task becomes more interesting when you find an encoder has put
> >it in a different place on chapter-start pages, because the printer
> >has put it in a different place (ie bottom center instead of top L/R
> >or whatever). To say nothing of the nouvelle vague typography of
> >magazines, which places it in a reversed-out tint bleeding off the
> >foredge, vertically positioned according to how far through the mag
> >you are :-)
> >
> >
> I'd say this was a rendition property of the entire document, to be
> encoded somewhere (where?) in the header, along with things like
> text body width, default font family, border widths etc.

It certainly should be...but I was describing the position where the
document had already been fully encoded, perhaps some time ago, and
had just been handed to us for formatting :-)

I'd be interested to know how many TEI-L readers encounter this "lets
do it the hard way" syndrome. I'm thinking of circumstances where huge
amounts of effort have been expended on inappropriate, perhaps
repetitive, manual encoding, when a simple specification in the header
(as Sebastian suggests) would have done it. And, more importantly,
what you have done to tackle the problem, or what you think can be done.

///Peter
=========================================================================
Date:         Thu, 6 Jan 2005 10:09:17 +0000
Reply-To:     Sebastian Rahtz <sebastian.rahtz@COMPUTING-SERVICES.OXFORD.AC.UK>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Sebastian Rahtz <sebastian.rahtz@COMPUTING-SERVICES.OXFORD.AC.UK>
Subject:      Re: Placement of <pb/>
Comments: To: Peter Flynn <pflynn@UCC.IE>
In-Reply-To:  <200501061004.j06A4el03241@listserv.brown.edu>
MIME-Version: 1.0
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit

Peter Flynn wrote:

> I'm thinking of circumstances where huge
>amounts of effort have been expended on inappropriate, perhaps
>repetitive, manual encoding, when a simple specification in the header
>(as Sebastian suggests) would have done it. And, more importantly,
>what you have done to tackle the problem, or what you think can be done.
>
>
easy, you charge the client extra :-}

Sebastian
=========================================================================
Date:         Thu, 6 Jan 2005 16:34:52 +0200
Reply-To:     George Cristian Bina <george@OXYGENXML.COM>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         George Cristian Bina <george@OXYGENXML.COM>
Subject:      [ANN] oXygen XML Editor 5.1 beta
MIME-Version: 1.0
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit

Happy New Year everybody!

I just wanted to post a short note to let you know that we made
available a beta version of <oXygen/> 5.1.
The full announcement is here:
http://www.oxygenxml.com/pipermail/oxygen-user/2005-January/000345.html

Some of the new features that you may find interesting for TEI are:
* Folding support
* Improved Relax NG support (content sensitive content completion and
model view support).
* Support for ID values on content completion
* Support for XSLTProc, MSXML 3.0, MSXML 4.0 and MSXML.Net as XSLT
transformers.
* Code templates
* Automatic detection of formatting settings
* Hard line wrap as you edit

We will be happy to receive your feedback on this beta version and we
will be interested in particular in feedback on the improved Relax NG
support taking into account that TEI is moving to Relax NG as main
schema language.

Best Regards,
George
---------------------------------------------------------------------
George Cristian Bina
<oXygen/> XML Editor, Schema Editor and XSLT Editor/Debugger
http://www.oxygenxml.com
=========================================================================
Date:         Thu, 6 Jan 2005 17:55:41 +0000
Reply-To:     Lou Burnard <lou.burnard@COMPUTING-SERVICES.OXFORD.AC.UK>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Lou Burnard <lou.burnard@COMPUTING-SERVICES.OXFORD.AC.UK>
Subject:      Re: Manuscript description module (P5) problems
Comments: To: Richard Higgins <r.i.higgins@DURHAM.AC.UK>
In-Reply-To:  <200501051346.j05Dk4l03271@listserv.brown.edu>
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii; format=flowed
Content-Transfer-Encoding: 7bit

At present, msDescription is indeed permitted only within the
sourceDescription, in a TEI header. In the MASTER dtd  it was also
permitted wherever a paragraph was permitted, and thus also within the
body of a text. I cannot honestly remember whether this change was a
conscious decision on the part of the workgroup or a simple oversight.
It would be easy enough to add msDescription to the tei.paragraph class,
which should have the desired effect. (Your suggestion about replacing
the reference to msIdentifier with one to msDescription would have the
effect of adding msDescription to the tei.phrase class, which is
probably not you want.)

As regards your "other quibble", it does seem a shame that Unicode has
given us characters for superscript numbers but not for superscript
letters! The content model for <locus> at the moment doesn't allow us
even to use the <g> element which is available for extra non-Unicode
characters -- it should be tei.text rather than text -- which might
help. I'm reluctant to allow the full range of phrase-level content
inside this element as this would permit horrors like self-nesting loci,
but I suppose one could allow for a few specifics like <number> <hi> etc.

Thanks for the feedback, and apologies for the delay in responding.

best wishes for the new year to you and all readers of TEI-L!

Lou


Richard Higgins wrote:

> I think I have raised this first point already, so apologies for any
> repetition if it has been addressed and I haven't found the new version.
>
> In order for the manuscript description to work for creating catalogues
> of manuscripts, the descriptions should be repeatable in the body,
> rather than in the header, but currently it is only possible to describe
> manuscripts in the header. As far as I can see the entry in
> teiclasses.dtd (line 50 of the 2004-04-11 version) should substitute
> "%n.msDescription;" for "%n.msIdentifier;". Only by doing this is it
> possible to enter multiple full descriptions of manuscripts.
>
> One other quibble. The element locus only allows text content, where it
> would be useful to be able to have some means of introducing
> superscript. Otherwise it is impossible to distinguish between "v"
> abbreviating verso and "v" the Roman numeral. It is conventional to use
> Roman numerals for prefatory pages added to a volume. In this situation
> it may not be completely obvious if "ff. iv - xv" refers to folios 1
> verso to 10 verso or folios 4 to 15.
>
> --
> # Richard Higgins
> # Durham University Library
> # Archives & Special Collections
> # Palace Green
> # Durham
> # DH1 3RN
> # E-Mail: r.i.higgins@durham.ac.uk
>
=========================================================================
Date:         Thu, 6 Jan 2005 20:09:12 +0000
Reply-To:     Sebastian Rahtz <sebastian.rahtz@COMPUTING-SERVICES.OXFORD.AC.UK>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Sebastian Rahtz <sebastian.rahtz@COMPUTING-SERVICES.OXFORD.AC.UK>
Subject:      tei-emacs for Windows update
Comments: cc: Barry Cornelius <barry.cornelius@durham.ac.uk>
MIME-Version: 1.0
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit

I have updated the files at http://www.tei-c.org/Software/tei-emacs/ to
bring the Windows
packaging of Emacs up to date with schemas, stylesheets, etc.  For the
clever folk, there's
included a copy of the new "osx" compiled for Windows.

As ever, I'm keen to hear of any problems.

--
Sebastian Rahtz
Information Manager, Oxford University Computing Services
13 Banbury Road, Oxford OX2 6NN. Phone +44 1865 283431

OSS Watch: JISC Open Source Advisory Service
http://www.oss-watch.ac.uk
=========================================================================
Date:         Thu, 6 Jan 2005 22:48:50 +0100
Reply-To:     Gautier Poupeau <gotpoupeau@INFONIE.FR>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Gautier Poupeau <gotpoupeau@INFONIE.FR>
Subject:      Re: Manuscript description module (P5) problems
In-Reply-To:  <41DD7B9D.4020209@computing-services.oxford.ac.uk>
MIME-Version: 1.0
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 8bit

Lou Burnard a écrit :

> At present, msDescription is indeed permitted only within the
> sourceDescription, in a TEI header. In the MASTER dtd  it was also
> permitted wherever a paragraph was permitted, and thus also within the
> body of a text. I cannot honestly remember whether this change was a
> conscious decision on the part of the workgroup or a simple oversight.
> It would be easy enough to add msDescription to the tei.paragraph class,
> which should have the desired effect. (Your suggestion about replacing
> the reference to msIdentifier with one to msDescription would have the
> effect of adding msDescription to the tei.phrase class, which is
> probably not you want.)

I would like making an another suggestion. Could we permitt
msDescription in <witness> element ? I think it's logical, because we
use the <witList> ans <witness> element to list all manuscrits used for
an scientifical edition of a text, so i would like describe each
manuscrit in the witness. Moreover, in this context, we could use
msDescription to describe a manuscrit, but also for a charter eg or an
another hand writing, because the manuscript description contains all
elements to describe this type of sources.
Moreover, with you choice, how can we make a manuscript inventory in one
TEI document ?


Gautier Poupeau,
Responsable du site Web de l'Ecole des chartes, http://www.enc.sorbonne.fr
=========================================================================
Date:         Thu, 6 Jan 2005 19:24:21 -0500
Reply-To:     Syd_Bauman@Brown.edu
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Syd Bauman <Syd_Bauman@BROWN.EDU>
Subject:      Re: [ANN] oXygen XML Editor 5.1 beta
In-Reply-To:  <41DD4C8C.5070208@oxygenxml.com>
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit

Thank you, <oXygen>.

[quotes are from the announcement to oxygen-user]

| We have almost ready a new version of oXygen and we made available a
| couple of distributions of a beta version of oXygen 5.1.
|
| Windows without a JVM:
| http://www.oxygenxml.com/v5.1beta/InstData/Windows/NoVM/oxygen.exe
| All platforms:
| http://www.oxygenxml.com/v5.1beta/InstData/All/oxygen.tar.gz
| Eclipse site URL:
| http://www.oxygenxml.com/v5.1beta/InstData/Eclipse/site.xml

Errr... MacOS X?


| * Really improved Relax NG support

Excellent!


| * Schematron support

Cool!


| * Support for XSLTProc, MSXML 3.0, MSXML 4.0 and MSXML.Net as XSLT
|   transformers.

Good. (I'm wondering, though, why there isn't generic support for any
transformer I want, or at least any one that reads from STDIN, writes
to STDOUT, etc.?)


| * Support for ID values on content completion. oXygen will present
| the ID values collected in the last validate action on the content
| completion proposals where an IDREF or an IDREFS type is specified.
| This works not only with documents that have a DTD associated but
| also with documents that have an XML Schema or a Relax NG schema
| associated.

Super. Although there are probably other systems out there that do
this, our local extensions to Emacs is the only such system I'm aware
of, and it doesn't work with RelaxNG, only with DTDs. However, I'm
wondering if
* xml:id= will be recognized as an ID type attribute even in the
  absence of a schema, and
* if completion would be attempted on an attribute of data-type
  xsd:anyURI when the first character is "#".


| * Content completion support also on element values (for elements
|   with XML Schema simple type content)

I'm hoping this is true whether W3C Schema Language or RelaxNG is
being used.


| * Sortable Tables

With only particular table models or any generic table? Sounds useful
either way, and absolutely great if it supports TEI tables.


| * Better undo support

Yay! Can never have enough undo. (Of course, I'm at least partially a
product of Andries Van Dam's course, so it shouldn't surprise anyone
that I say that.)


| * Updated the TEI framework

Yay! Thanks. With luck in a few months you can start including a
framework for TEI P5, too.
=========================================================================
Date:         Thu, 6 Jan 2005 20:41:10 -0500
Reply-To:     David Sewell <dsewell@VIRGINIA.EDU>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         David Sewell <dsewell@VIRGINIA.EDU>
Subject:      Re: [ANN] oXygen XML Editor 5.1 beta
In-Reply-To:  <16861.54965.797096.253262@emt.wwp.brown.edu>
MIME-Version: 1.0
Content-Type: TEXT/PLAIN; charset=US-ASCII; format=flowed

On Thu, 6 Jan 2005, Syd Bauman wrote:

> Thank you, <oXygen>.
>
> [quotes are from the announcement to oxygen-user]
>
> | We have almost ready a new version of oXygen and we made available a
> | couple of distributions of a beta version of oXygen 5.1.
> |
> | Windows without a JVM:
> | http://www.oxygenxml.com/v5.1beta/InstData/Windows/NoVM/oxygen.exe
> | All platforms:
> | http://www.oxygenxml.com/v5.1beta/InstData/All/oxygen.tar.gz
> | Eclipse site URL:
> | http://www.oxygenxml.com/v5.1beta/InstData/Eclipse/site.xml
>
> Errr... MacOS X?

The "All platforms" version will run on OS X; this beta version just
doesn't have an OS X installer. Download and unarchive the
file. Inside the resulting folder is a file "oxygenMac.sh" that is an
executable shell startup script to launch the application with some
Mac-specific settings.

A quick tour of the beta suggests that a couple of the new features
may not be working right under OS X, so feedback from Mac folk should
be useful.

DS

--
David Sewell, Editorial and Technical Manager
Electronic Imprint, The University of Virginia Press
PO Box 400318, Charlottesville, VA 22904-4318 USA
Courier: 310 Old Ivy Way, Suite 302, Charlottesville VA 22903
Email: dsewell@virginia.edu   Tel: +1 434 924 9973
=========================================================================
Date:         Thu, 6 Jan 2005 21:10:01 EST
Reply-To:     DrWender@AOL.COM
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Herbert Wender <DrWender@AOL.COM>
Subject:      Re: Placement of <pb/>
MIME-Version: 1.0
Content-Type: multipart/alternative;
              boundary="part1_12a.542a47d5.2f0f4979_boundary"

--part1_12a.542a47d5.2f0f4979_boundary
Content-Type: text/plain; charset="ISO-8859-1"
Content-Transfer-Encoding: quoted-printable

In einer eMail vom 06.01.05 11:16:11 (MEZ) Mitteleurop=E4ische Zeit schreibt=
=20
sebastian.rahtz@COMPUTING-SERVICES.OXFORD.AC.UK:


> Peter Flynn wrote:
>=20
> > I'm thinking of circumstances where huge
> >amounts of effort have been expended on inappropriate, perhaps
> >repetitive, manual encoding, when a simple specification in the header
> >(as Sebastian suggests) would have done it. And, more importantly,
> >what you have done to tackle the problem, or what you think can be done.
> >
> >
> easy, you charge the client extra :-}
>=20

That's TEI at it's best: Blow up the encoding instructions
by hundreds of pages, enforce repetitive encoding by the=20
governing rule "Make explicit the implicit" - and then
"charge the client extra". Thanks for making explicit
the consequences too.

hw



--part1_12a.542a47d5.2f0f4979_boundary
Content-Type: text/html; charset="ISO-8859-1"
Content-Transfer-Encoding: quoted-printable

<HTML><FONT FACE=3Darial,helvetica><HTML><FONT  SIZE=3D3 PTSIZE=3D12 FAMILY=
=3D"SANSSERIF" FACE=3D"Arial" LANG=3D"2">In einer eMail vom 06.01.05 11:16:1=
1 (MEZ) Mitteleurop=E4ische Zeit schreibt sebastian.rahtz@COMPUTING-SERVICES=
.OXFORD.AC.UK:<BR>
<BR>
</FONT><FONT  COLOR=3D"#000000" BACK=3D"#ffffff" style=3D"BACKGROUND-COLOR:=20=
#ffffff" SIZE=3D2 PTSIZE=3D10 FAMILY=3D"SANSSERIF" FACE=3D"Arial" LANG=3D"2"=
><BR>
<BLOCKQUOTE TYPE=3DCITE style=3D"BORDER-LEFT: #0000ff 2px solid; MARGIN-LEFT=
: 5px; MARGIN-RIGHT: 0px; PADDING-LEFT: 5px">Peter Flynn wrote:<BR>
<BR>
&gt; I'm thinking of circumstances where huge<BR>
&gt;amounts of effort have been expended on inappropriate, perhaps<BR>
&gt;repetitive, manual encoding, when a simple specification in the header<B=
R>
&gt;(as Sebastian suggests) would have done it. And, more importantly,<BR>
&gt;what you have done to tackle the problem, or what you think can be done.=
<BR>
&gt;<BR>
&gt;<BR>
easy, you charge the client extra :-}<BR>
</BLOCKQUOTE><BR>
</FONT><FONT  COLOR=3D"#000000" BACK=3D"#ffffff" style=3D"BACKGROUND-COLOR:=20=
#ffffff" SIZE=3D3 PTSIZE=3D12 FAMILY=3D"SANSSERIF" FACE=3D"Arial" LANG=3D"2"=
><BR>
That's TEI at it's best: Blow up the encoding instructions<BR>
by hundreds of pages, enforce repetitive encoding by the <BR>
governing rule "Make explicit the implicit" - and then<BR>
"charge the client extra". Thanks for making explicit<BR>
the consequences too.<BR>
<BR>
hw<BR>
<BR>
<BR>
</FONT></HTML>
--part1_12a.542a47d5.2f0f4979_boundary--
=========================================================================
Date:         Fri, 7 Jan 2005 11:18:41 +0200
Reply-To:     George Cristian Bina <george@OXYGENXML.COM>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         George Cristian Bina <george@OXYGENXML.COM>
Subject:      Re: [ANN] oXygen XML Editor 5.1 beta
Comments: To: David Sewell <dsewell@VIRGINIA.EDU>
In-Reply-To:  <Pine.WNT.4.61.0501062032370.1216@student>
MIME-Version: 1.0
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit

[...]
>> Errr... MacOS X?
>
>
> The "All platforms" version will run on OS X; this beta version just
> doesn't have an OS X installer.
[...]

Here it is:
http://www.oxygenxml.com/v5.1beta/InstData/MacOSX/oxygen.tar.gz

Best Regards,
George
---------------------------------------------------------------------
George Cristian Bina
<oXygen/> XML Editor, Schema Editor and XSLT Editor/Debugger
http://www.oxygenxml.com
=========================================================================
Date:         Fri, 7 Jan 2005 11:54:18 +0200
Reply-To:     George Cristian Bina <george@OXYGENXML.COM>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         George Cristian Bina <george@OXYGENXML.COM>
Subject:      Re: [ANN] oXygen XML Editor 5.1 beta
Comments: To: Syd_Bauman@Brown.edu
In-Reply-To:  <16861.54965.797096.253262@emt.wwp.brown.edu>
MIME-Version: 1.0
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit

Hi Syd,

 > Errr... MacOS X?

http://www.oxygenxml.com/v5.1beta/InstData/MacOSX/oxygen.tar.gz

> | * Support for XSLTProc, MSXML 3.0, MSXML 4.0 and MSXML.Net as XSLT
> |   transformers.
>
> Good. (I'm wondering, though, why there isn't generic support for any
> transformer I want, or at least any one that reads from STDIN, writes
> to STDOUT, etc.?)

For something like that I think you can use the external tools support.
That is basically a command like that is constructed using some macros
that are expanded at execution time, see:
http://www.oxygenxml.com/doc/ug-standalone/ch03.html#external-tools

> | * Support for ID values on content completion. oXygen will present
> | the ID values collected in the last validate action on the content
> | completion proposals where an IDREF or an IDREFS type is specified.
> | This works not only with documents that have a DTD associated but
> | also with documents that have an XML Schema or a Relax NG schema
> | associated.
>
> Super. Although there are probably other systems out there that do
> this, our local extensions to Emacs is the only such system I'm aware
> of, and it doesn't work with RelaxNG, only with DTDs. However, I'm
> wondering if
> * xml:id= will be recognized as an ID type attribute even in the
>   absence of a schema, and

No, it will not recognize that.  But even if oXygen will recognize that
as an ID then it will just collect the IDs and nothing more because it
will not be able to identify the IDREF or IDREFS values.

> * if completion would be attempted on an attribute of data-type
>   xsd:anyURI when the first character is "#".

No, it does not do that.

> | * Content completion support also on element values (for elements
> |   with XML Schema simple type content)
>
> I'm hoping this is true whether W3C Schema Language or RelaxNG is
> being used.

It works only for XML Schema now but we plan to extend that also to
Relax NG.

>
> | * Sortable Tables
>
> With only particular table models or any generic table? Sounds useful
> either way, and absolutely great if it supports TEI tables.

This refers to the GUI tables from oXygen. For instance the table that
presents the variables in the XSLT Debugger perspective.

Best Regards,
George
---------------------------------------------------------------------
George Cristian Bina
<oXygen/> XML Editor, Schema Editor and XSLT Editor/Debugger
http://www.oxygenxml.com
=========================================================================
Date:         Fri, 7 Jan 2005 10:22:52 +0000
Reply-To:     Sebastian Rahtz <sebastian.rahtz@COMPUTING-SERVICES.OXFORD.AC.UK>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Sebastian Rahtz <sebastian.rahtz@COMPUTING-SERVICES.OXFORD.AC.UK>
Subject:      Re: Placement of <pb/>
Comments: To: DrWender@AOL.COM
In-Reply-To:  <200501070210.j072A7l21412@listserv.brown.edu>
MIME-Version: 1.0
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit

Herbert Wender wrote:

>That's TEI at it's best: Blow up the encoding instructions
>by hundreds of pages, enforce repetitive encoding by the
>governing rule "Make explicit the implicit"
>
Thats an odd assertion. Why do you think the TEI mandates
"Make explicit the implicit" ?

Sebastian
=========================================================================
Date:         Fri, 7 Jan 2005 06:21:31 -0500
Reply-To:     Syd_Bauman@Brown.edu
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Syd Bauman <Syd_Bauman@BROWN.EDU>
Subject:      Re: [ANN] oXygen XML Editor 5.1 beta
In-Reply-To:  <41DE5C4A.8020304@oxygenxml.com>
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit

Thanks for the quick response.


> http://www.oxygenxml.com/v5.1beta/InstData/MacOSX/oxygen.tar.gz

Cool, thanks. Just installed it, hope to play with it soon. (I have
vague recollections of problems with hard-coded path names last time
I had 2 versions installed simultaneously, though.)


> For something like that I think you can use the external tools support.
> http://www.oxygenxml.com/doc/ug-standalone/ch03.html#external-tools

Oooh! Nifty. Hadn't noticed that in the internal help documentation
before. I just tried it out, and some commands work exactly as
expected, but neither the egrep command nor anything piped seemed to
work. Will try to check into this further and perhaps submit bug
report later.


> No, it will not recognize [xml:id= w/o schema]. But even if oXygen
> will recognize that as an ID then it will just collect the IDs and
> nothing more because it will not be able to identify the IDREF or
> IDREFS values.

Good point.


> > * if completion would be attempted on an attribute of data-type
> >   xsd:anyURI when the first character is "#".
> No, it does not do that.

Probably should. TEI plans to use this mechanism in P5, and W3C has
it in their working draft "Modularization of XHTML in XML Schema".[1]
I think it's reasonable to presume declaring an attribute as
xsd:anyURI will become pretty common, and that users will want the
completion feature for said attributes.


> It [element content completion] works only for XML Schema now but
> we plan to extend that also to Relax NG.

Looking forward.


> This refers to the GUI tables from oXygen. For instance the table
> that presents the variables in the XSLT Debugger perspective.

Ooops, sorry. I completely misunderstood you. Yes, I just tested it;
works. I can see this being quite useful with one of my favorite
oXygen features: the ability to just type in an XPath into the XPath
expression field and see a list of returned nodes (or more commonly,
in my case, an error message)-: I'll send some detailed comments on
this off-list.


Notes
-----
[1] However, this WD uses a string for multiple URIs [W3C Schema]:
      <!-- a space-separated list of Uniform Resource Identifiers, see [URI] -->
      <xs:simpleType name="URIs">
        <xs:list itemType="xs:string"/>
      </xs:simpleType>
    whereas TEI is planning to use a list of URIs [RelaxNG]:
      <rng:list>
        <rng:oneOrMore>
          <rng:data type="anyURI"/>
        </rng:oneOrMore>
      </rng:list>
    My gut instinct is that the W3C approach will make it difficult
    for oXygen to recognize these attributes as ones that deserve
    special treatment. (There appears to be only 1 such attribute in
    XHTML, btw: the archive= attribute of <object>.)
=========================================================================
Date:         Fri, 7 Jan 2005 15:51:37 +0200
Reply-To:     George Cristian Bina <george@OXYGENXML.COM>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         George Cristian Bina <george@OXYGENXML.COM>
Subject:      Re: [ANN] oXygen XML Editor 5.1 beta
Comments: To: Syd_Bauman@Brown.edu
In-Reply-To:  <16862.28859.876548.873702@emt.wwp.brown.edu>
MIME-Version: 1.0
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit

Hi Syd,

>>For something like that I think you can use the external tools support.
>>http://www.oxygenxml.com/doc/ug-standalone/ch03.html#external-tools
>
>
> Oooh! Nifty. Hadn't noticed that in the internal help documentation
> before. I just tried it out, and some commands work exactly as
> expected, but neither the egrep command nor anything piped seemed to
> work. Will try to check into this further and perhaps submit bug
> report later.

The pipe symbol is interpreted by the shell application. You can make
that work if you put your commands in a shell script for instance and
call that in the command line from oXygen, something like
/bin/sh myScriptFile.sh ${cfn}
(not tested)

>>>* if completion would be attempted on an attribute of data-type
>>>  xsd:anyURI when the first character is "#".
>>
>>No, it does not do that.
>
>
> Probably should. TEI plans to use this mechanism in P5, and W3C has
> it in their working draft "Modularization of XHTML in XML Schema".[1]
> I think it's reasonable to presume declaring an attribute as
> xsd:anyURI will become pretty common, and that users will want the
> completion feature for said attributes.

It is simpler from an implementation POV to determine that the value has
xsd:anyURI as type and just offer #id1, #id2, etc. as possible values.
This can be done easily for XML Schema, for Relax NG it is more
difficult because the attribute can match more than one pattern.

Best Regards,
George
---------------------------------------------------------------------
George Cristian Bina
<oXygen/> XML Editor, Schema Editor and XSLT Editor/Debugger
http://www.oxygenxml.com
=========================================================================
Date:         Fri, 7 Jan 2005 16:40:35 +0000
Reply-To:     Sebastian Rahtz <sebastian.rahtz@COMPUTING-SERVICES.OXFORD.AC.UK>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Sebastian Rahtz <sebastian.rahtz@COMPUTING-SERVICES.OXFORD.AC.UK>
Subject:      oXygen for Debian folks
MIME-Version: 1.0
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit

If you're feeling strong, like the TEI, use Debian Linux, and want to
try oXygen and TEI P5,
grab a .deb package from http://tei.oucs.ox.ac.uk/teideb/. You'll need
to get a
license from oXygen, of course, for it to work at all.

I have tinkered a bit with the default setup, and it may not even work,
so _caveat downloador_

I have replaced the TEI XSL stylesheets included in the oXygen bundle
with references to ones already on the system, if you use my other
TEI Debian packages, and I have made them default to P5.

Sebastian
=========================================================================
Date:         Fri, 7 Jan 2005 17:13:47 +0000
Reply-To:     Sebastian Rahtz <sebastian.rahtz@COMPUTING-SERVICES.OXFORD.AC.UK>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Sebastian Rahtz <sebastian.rahtz@COMPUTING-SERVICES.OXFORD.AC.UK>
Subject:      relicensed TEI XSL stylesheets
MIME-Version: 1.0
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit

I have re-rereleased all the XSLT stylesheets which I have written for
the TEI Consortium
under an LGPL licence, rather than a GPL licence. Now at version 4.0.

The main reason for doing this is that the LGPL protects the TEIC's
interests
as well as the GPL, and imposes less burden on commercial software vendors.
The revolutionary amongst us may actively wish to impose that burden, but
in this case the interests of the TEIC seem more important.

Sebastian Rahtz
=========================================================================
Date:         Fri, 7 Jan 2005 20:04:57 EST
Reply-To:     DrWender@AOL.COM
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Herbert Wender <DrWender@AOL.COM>
Subject:      Re: Placement of <pb/>
Comments: To: sebastian.rahtz@COMPUTING-SERVICES.OXFORD.AC.UK
MIME-Version: 1.0
Content-Type: multipart/alternative;
              boundary="part1_97.5661ed07.2f108bb9_boundary"

--part1_97.5661ed07.2f108bb9_boundary
Content-Type: text/plain; charset="ISO-8859-1"
Content-Transfer-Encoding: quoted-printable

In einer eMail vom 07.01.05 11:30:20 (MEZ) Mitteleurop=E4ische Zeit schreibt=
=20
sebastian.rahtz@COMPUTING-SERVICES.OXFORD.AC.UK:


> Thats an odd assertion. Why do you think the TEI mandates
> "Make explicit the implicit" ?
>=20

Because I've read it (I think in the late eigthies) in the=20
"Gentle Introduction". And the phrase is already there
in the World Wide Web as we see by google-ing=20
"making explicit what is conjectural or implicit"
with a lot of derived occurences.

Ask some elder man from the TEI board
(or encoding philosopher Lachance)
if my understanding of TEIs approach to encoding
is so odd as my Englisch ;-)

Best regards,
Herbert



--part1_97.5661ed07.2f108bb9_boundary
Content-Type: text/html; charset="ISO-8859-1"
Content-Transfer-Encoding: quoted-printable

<HTML><FONT FACE=3Darial,helvetica><HTML><FONT  SIZE=3D3 PTSIZE=3D12 FAMILY=
=3D"SANSSERIF" FACE=3D"Arial" LANG=3D"2">In einer eMail vom 07.01.05 11:30:2=
0 (MEZ) Mitteleurop=E4ische Zeit schreibt sebastian.rahtz@COMPUTING-SERVICES=
.OXFORD.AC.UK:<BR>
<BR>
</FONT><FONT  COLOR=3D"#000000" BACK=3D"#ffffff" style=3D"BACKGROUND-COLOR:=20=
#ffffff" SIZE=3D2 PTSIZE=3D10 FAMILY=3D"SANSSERIF" FACE=3D"Arial" LANG=3D"2"=
><BR>
<BLOCKQUOTE TYPE=3DCITE style=3D"BORDER-LEFT: #0000ff 2px solid; MARGIN-LEFT=
: 5px; MARGIN-RIGHT: 0px; PADDING-LEFT: 5px">Thats an odd assertion. Why do=20=
you think the TEI mandates<BR>
"Make explicit the implicit" ?<BR>
</BLOCKQUOTE><BR>
</FONT><FONT  COLOR=3D"#000000" BACK=3D"#ffffff" style=3D"BACKGROUND-COLOR:=20=
#ffffff" SIZE=3D3 PTSIZE=3D12 FAMILY=3D"SANSSERIF" FACE=3D"Arial" LANG=3D"2"=
><BR>
Because I've read it (I think in the late eigthies) in the <BR>
"Gentle Introduction". And the phrase is already there<BR>
in the World Wide Web as we see by google-ing <BR>
"</FONT><FONT  COLOR=3D"#000000" BACK=3D"#ffffff" style=3D"BACKGROUND-COLOR:=
 #ffffff" SIZE=3D2 PTSIZE=3D10 FAMILY=3D"SANSSERIF" FACE=3D"Arial" LANG=3D"2=
">making explicit what is conjectural or implicit</FONT><FONT  COLOR=3D"#000=
000" BACK=3D"#ffffff" style=3D"BACKGROUND-COLOR: #ffffff" SIZE=3D3 PTSIZE=
=3D12 FAMILY=3D"SANSSERIF" FACE=3D"Arial" LANG=3D"2">"<BR>
with a lot of derived occurences.<BR>
<BR>
Ask some elder man from the TEI board<BR>
(or encoding philosopher Lachance)<BR>
if my understanding of TEIs approach to encoding<BR>
is so odd as my Englisch ;-)<BR>
<BR>
Best regards,<BR>
Herbert<BR>
<BR>
<BR>
</FONT></HTML>
--part1_97.5661ed07.2f108bb9_boundary--
=========================================================================
Date:         Sat, 8 Jan 2005 00:07:30 -0500
Reply-To:     Syd_Bauman@Brown.edu
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Syd Bauman <Syd_Bauman@BROWN.EDU>
Subject:      Re: Placement of <pb/>
In-Reply-To:  <97.5661ed07.2f108bb9@aol.com>
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit

> > Thats an odd assertion. Why do you think the TEI mandates "Make
> > explicit the implicit" ?

> Because I've read it (I think in the late eigthies) in the "Gentle
> Introduction".

Indeed, the sentence you are refering to appears in the "Gentle
Introduction to SGML" chapter of P2:

  Encoding a text for computer processing is in principle, like
  transcribing a manuscript from <foreign lang=LA>scriptio
  continua</foreign>, a process of making explicit what is
  conjectural or implicit, a process of directing the user as to how
  the content of the text should be interpreted.

(Note the lack of quotation marks around the attribute value -- P2
was written in SGML, not XML.) And has since become the following in
P4 (and has yet to be changed for P5, either):

  Encoding a text for computer processing is in principle, like
  transcribing a manuscript from <foreign lang="LA">scriptio
  continua</foreign>,<note place="foot">In the <q>continuous
  writing</q> characteristic of manuscripts from the early classical
  period, words are written continuously with no intervening spaces
  or punctuation.</note> a process of making explicit what is
  conjectural or implicit, a process of directing the user as to how
  the content of the text should be (or has been) interpreted.</p>

But I hardly think that defining markup in this way lays TEI open to
a charge of "mandating" anything. Even in those cases where TEI does
recommend particular features be explicitly marked up, that's all it
is -- a recommendation, a guideline, a suggestion, some advice.

And furthermore, either of the two encodings Peter describes (the
laborious manual encoding of some repetative detail, or the simple
specification of the detail once in the header) is making explicit
the same feature of the text; the difference being that the former is
more direct while the latter is more efficient.
=========================================================================
Date:         Fri, 7 Jan 2005 23:10:43 -0700
Reply-To:     daniel.odonnell@uleth.ca
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Daniel O'Donnell <daniel.odonnell@ULETH.CA>
Organization: Department of English, University of Lethbridge
Subject:      Re: Placement of <pb/>
In-Reply-To:  <200501080507.j0857Xl05449@listserv.brown.edu>
MIME-Version: 1.0
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit

Maybe I've been missing something: is mandating explicitness a bad
thing? A strength of the TEI--but also an inherent weakness--is that it
_mandates_ very little specific markup. This makes it so powerful as a
language for scholars, but also makes it difficult (sorry, interesting)
to apply and use. But its various possibilities are very explicit.
Sometimes this can seem a little silly: ultimately, emphasis, foreign,
highlighting, title@level=m can all be understood as another way of
saying "italics" (I once had a conversation like this with a dean, so I
know whereof I speak). But if one doesn't care about that kind of
structural explicitness, there are other languages. Html 2.0 is pretty
good at describing what one sees, for example, and <i> and <b> are still
allowed in 4.0.

-dan "not-a-markup-philosopher-but-there-you-have-my-two-cents-worth"
o'donnell

Syd Bauman wrote:
>>>Thats an odd assertion. Why do you think the TEI mandates "Make
>>>explicit the implicit" ?
>
>
>>Because I've read it (I think in the late eigthies) in the "Gentle
>>Introduction".
>
>
> Indeed, the sentence you are refering to appears in the "Gentle
> Introduction to SGML" chapter of P2:
>
>   Encoding a text for computer processing is in principle, like
>   transcribing a manuscript from <foreign lang=LA>scriptio
>   continua</foreign>, a process of making explicit what is
>   conjectural or implicit, a process of directing the user as to how
>   the content of the text should be interpreted.
>
> (Note the lack of quotation marks around the attribute value -- P2
> was written in SGML, not XML.) And has since become the following in
> P4 (and has yet to be changed for P5, either):
>
>   Encoding a text for computer processing is in principle, like
>   transcribing a manuscript from <foreign lang="LA">scriptio
>   continua</foreign>,<note place="foot">In the <q>continuous
>   writing</q> characteristic of manuscripts from the early classical
>   period, words are written continuously with no intervening spaces
>   or punctuation.</note> a process of making explicit what is
>   conjectural or implicit, a process of directing the user as to how
>   the content of the text should be (or has been) interpreted.</p>
>
> But I hardly think that defining markup in this way lays TEI open to
> a charge of "mandating" anything. Even in those cases where TEI does
> recommend particular features be explicitly marked up, that's all it
> is -- a recommendation, a guideline, a suggestion, some advice.
>
> And furthermore, either of the two encodings Peter describes (the
> laborious manual encoding of some repetative detail, or the simple
> specification of the detail once in the header) is making explicit
> the same feature of the text; the difference being that the former is
> more direct while the latter is more efficient.

--
Daniel Paul O'Donnell, PhD
Associate Professor of English
University of Lethbridge
Lethbridge AB T1K 3M4
Tel. (403) 329-2377
Fax. (403) 382-7191
E-mail <daniel.odonnell@uleth.ca>
Home Page <http://people.uleth.ca/~daniel.odonnell/>
The Digital Medievalist Project: <http://www.digitalmedievalist.org/>
=========================================================================
Date:         Sat, 8 Jan 2005 08:04:57 EST
Reply-To:     DrWender@AOL.COM
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Herbert Wender <DrWender@AOL.COM>
Subject:      Re: Placement of <pb/>
Comments: To: Syd_Bauman@BROWN.EDU
MIME-Version: 1.0
Content-Type: multipart/alternative;
              boundary="part1_90.54b9cb2b.2f113479_boundary"

--part1_90.54b9cb2b.2f113479_boundary
Content-Type: text/plain; charset="ISO-8859-1"
Content-Transfer-Encoding: quoted-printable

In einer eMail vom 08.01.05 06:08:46 (MEZ) Mitteleurop=E4ische Zeit schreibt=
=20
Syd_Bauman@BROWN.EDU:


> But I hardly think that defining markup in this way lays TEI open to
> a charge of "mandating" anything. Even in those cases where TEI does
> recommend particular features be explicitly marked up, that's all it
> is -- a recommendation, a guideline, a suggestion, some advice.
>=20


First, sorry for the awkward citation by cutting&pasting
the second "explicit" in the text; the paragraph starts with:
"Generalizing from that sense, we define markup, or (synonymously)=20
encoding, as any means of making explicit an interpretation of a text."
That's what I've remembered reading Sebastians
interpretation of my mail:
Thats an odd assertion. Why do you think the TEI mandates
"Make explicit the implicit" ?

Second, I've _not_ said "TEI mandates" anything,
but asserted a "governing rule" perhaps not intrinsically
misleading but in effect leading many TEI practitioners
to a markup what I would judge as 'information overload'
(sometimes simple redundancy). Looking the source
code f.e. of Kennedys "Double Falshood" markup
I have a feeling, a little bit as with some critical editions:
The most interesting deviations of standard schemes
are hardly visible in the bulk of ongoing trivialities.
It's my opinion now - I'm willing to hear arguments
against it.

Third, I affirm that in the origins it was _not_ the=20
_intention_ by establishing TEI to enforce the
coding now to be charged with extra costs for
typesetting a TEI conformant edition. But it must be
allowed to ask why the (visible) practice of encoding
is how it is, you would perhaps say "silly". That's
the question I'm interested in.

Best regards,
Herbert

--part1_90.54b9cb2b.2f113479_boundary
Content-Type: text/html; charset="ISO-8859-1"
Content-Transfer-Encoding: quoted-printable

<HTML><FONT FACE=3Darial,helvetica><HTML><FONT  SIZE=3D3 PTSIZE=3D12 FAMILY=
=3D"SANSSERIF" FACE=3D"Arial" LANG=3D"2">In einer eMail vom 08.01.05 06:08:4=
6 (MEZ) Mitteleurop=E4ische Zeit schreibt Syd_Bauman@BROWN.EDU:<BR>
<BR>
</FONT><FONT  COLOR=3D"#000000" BACK=3D"#ffffff" style=3D"BACKGROUND-COLOR:=20=
#ffffff" SIZE=3D2 PTSIZE=3D10 FAMILY=3D"SANSSERIF" FACE=3D"Arial" LANG=3D"2"=
><BR>
<BLOCKQUOTE TYPE=3DCITE style=3D"BORDER-LEFT: #0000ff 2px solid; MARGIN-LEFT=
: 5px; MARGIN-RIGHT: 0px; PADDING-LEFT: 5px">But I hardly think that definin=
g markup in this way lays TEI open to<BR>
a charge of "mandating" anything. Even in those cases where TEI does<BR>
recommend particular features be explicitly marked up, that's all it<BR>
is -- a recommendation, a guideline, a suggestion, some advice.<BR>
</BLOCKQUOTE><BR>
</FONT><FONT  COLOR=3D"#000000" BACK=3D"#ffffff" style=3D"BACKGROUND-COLOR:=20=
#ffffff" SIZE=3D3 PTSIZE=3D12 FAMILY=3D"SANSSERIF" FACE=3D"Arial" LANG=3D"2"=
><BR>
<BR>
First, sorry for the awkward citation by cutting&amp;pasting<BR>
the second "explicit" in the text; the paragraph starts with:<BR>
"</FONT><FONT  COLOR=3D"#000000" BACK=3D"#ffffff" style=3D"BACKGROUND-COLOR:=
 #ffffff" SIZE=3D2 PTSIZE=3D10 FAMILY=3D"SANSSERIF" FACE=3D"Arial" LANG=3D"2=
">Generalizing from that sense, we define markup, or (synonymously) <BR>
encoding, as any means of making explicit an interpretation of a text.</FONT=
><FONT  COLOR=3D"#000000" BACK=3D"#ffffff" style=3D"BACKGROUND-COLOR: #fffff=
f" SIZE=3D3 PTSIZE=3D12 FAMILY=3D"SANSSERIF" FACE=3D"Arial" LANG=3D"2">"<BR>
That's what I've remembered reading Sebastians<BR>
interpretation of my mail:<BR>
</FONT><FONT  COLOR=3D"#000000" BACK=3D"#ffffff" style=3D"BACKGROUND-COLOR:=20=
#ffffff" SIZE=3D2 PTSIZE=3D10 FAMILY=3D"SANSSERIF" FACE=3D"Arial" LANG=3D"2"=
>Thats an odd assertion. Why do you think the TEI mandates<BR>
"Make explicit the implicit" ?</FONT><FONT  COLOR=3D"#000000" BACK=3D"#fffff=
f" style=3D"BACKGROUND-COLOR: #ffffff" SIZE=3D3 PTSIZE=3D12 FAMILY=3D"SANSSE=
RIF" FACE=3D"Arial" LANG=3D"2"><BR>
<BR>
Second, I've _not_ said "TEI mandates" anything,<BR>
but asserted a "governing rule" perhaps not intrinsically<BR>
misleading but in effect leading many TEI practitioners<BR>
to a markup what I would judge as 'information overload'<BR>
(sometimes simple redundancy). Looking the source<BR>
code f.e. of Kennedys "Double Falshood" markup<BR>
I have a feeling, a little bit as with some critical editions:<BR>
The most interesting deviations of standard schemes<BR>
are hardly visible in the bulk of ongoing trivialities.<BR>
It's my opinion now - I'm willing to hear arguments<BR>
against it.<BR>
<BR>
Third, I affirm that in the origins it was _not_ the <BR>
_intention_ by establishing TEI to enforce the<BR>
coding now to be charged with extra costs for<BR>
typesetting a TEI conformant edition. But it must be<BR>
allowed to ask why the (visible) practice of encoding<BR>
is how it is, you would perhaps say "silly". That's<BR>
the question I'm interested in.<BR>
<BR>
Best regards,<BR>
Herbert<BR>
</FONT></HTML>
--part1_90.54b9cb2b.2f113479_boundary--
=========================================================================
Date:         Sat, 8 Jan 2005 09:52:05 -0500
Reply-To:     "John W. Kennedy" <jwkenne@ATTGLOBAL.NET>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         "John W. Kennedy" <jwkenne@ATTGLOBAL.NET>
Subject:      Re: Placement of <pb/>
In-Reply-To:  <90.54b9cb2b.2f113479@aol.com>
MIME-version: 1.0
Content-type: text/plain; charset=ISO-8859-1; format=flowed
Content-transfer-encoding: 7BIT

Herbert Wender wrote:
> Looking the source
> code f.e. of Kennedys "Double Falshood" markup
> I have a feeling, a little bit as with some critical editions:
> The most interesting deviations of standard schemes
> are hardly visible in the bulk of ongoing trivialities.

I am a bad example--an amateur (and a long-ago physics major at that)
who decided to create a critical e-text only after discovering that
there was neither a public e-text available, nor a critical text of any
kind, and that /some/ scholarship, furthermore, has been based on bad
copies. I /chose/ to include all possible information, including
catchwords, press figures, and running heads (including errors in same).

(I also wrote a Perl program that allowed me to print out the TEI with
original line breaks, page breaks, etc., which made it much easier for
me to eyeball differences during my limited time available with physical
editions.)

But that is the TEI version. I also have an XHTML 1.1 version (and an
alternative HTML 4.01 version, for the sake of those foolish enough to
use Microsoft's Internet Explorer, which, after five years, still cannot
read XHTML); and an OpenOffice.org version with modern spelling and
punctuation, footnotes on hard words instead of footnotes on 1728 inking
failures, and pointing of the verse for the use of amateur actors.

But remember always, unwanted information can always be filtered out,
but discarded information cannot be filtered back in.

--
John W. Kennedy
"You can, if you wish, class all science-fiction together; but it is
about as perceptive as classing the works of Ballantyne, Conrad and W.
W. Jacobs together as the 'sea-story' and then criticizing _that_."
   -- C. S. Lewis.  "An Experiment in Criticism"
=========================================================================
Date:         Sat, 8 Jan 2005 10:33:18 -0500
Reply-To:     Francois Lachance <lachance@ORIGIN.CHASS.UTORONTO.CA>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Francois Lachance <lachance@ORIGIN.CHASS.UTORONTO.CA>
Subject:      Efficient/Effective markup was (Re: Placement of <pb/>
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit

Syd's invoking of efficiency leads me to ask about effectiveness:

> And furthermore, either of the two encodings Peter describes (the
> laborious manual encoding of some repetative detail, or the simple
> specification of the detail once in the header) is making explicit
> the same feature of the text; the difference being that the former is
> more direct while the latter is more efficient.

I am thinking about the use case where parts of a marked-up document are
processed (or are the object of information interchange) and the header
doesn't come along...

That <q rend="db_underline">laborious manual encoding</q> can slow down
the reading process and offer a different way of inhabiting or exploring
the textual universe exposed or constructed by the object of encoding
through a series of encounters with encoders. Granted there may be some
tediousness and laboriousness if all manual encoding is done from scratch.
Try a few minutes of keying in both mark-up tags and marked-up elements
and attributes For a touch typist with a knowledge of the tag set this is
sometimes faster than inserting markup from drop down menu. It work asking
just how manual is manual. I recall tinkering with several passes of
search and replace to produce high granularity. I was able to introduce a
host of <gi>c</gi) elements and as well experience the joys of the
multiple undo which allowed me to view the cumulative results in a layered
fashion. This leads to questions like the desirability of creating
libraries of transformations for automating aspects of repetitious
encoding. It also leads to questions about similar libraries for
viewing/analysis [by analolgy with multiple undo ... multiple show].

--
Francois Lachance, Scholar-at-large
http://www.chass.utoronto.ca/~lachance

A calendar is like a map. And just as maps have insets, calendars in the
21st century might have 'moments' expressed in flat local time fanning out
into "great circles" expressed in earth revolution time.
=========================================================================
Date:         Sat, 8 Jan 2005 10:54:55 -0500
Reply-To:     Francois Lachance <lachance@ORIGIN.CHASS.UTORONTO.CA>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Francois Lachance <lachance@ORIGIN.CHASS.UTORONTO.CA>
Subject:      The I in TEI was (Re: Placement of <pb/>)
In-Reply-To:  <no.id> from "Herbert Wender" at Jan 07, 2005 08:04:57 PM
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit

It is as a mere reader that pick up the "mandate" thread. Not so much in
reading the recommendations contained int the chapters of the TEI
Guidelines as prescriptive or descriptive, but simply in reading the the
title of the Guidelines [P3 April 8, 1994]:

        Guidelines for Electronic Text Encoding and Interchange

Emphasis, depending on a reader's parsing habits, falls

        for [...] Interchange

        for Electronic [...] Interchange

        for [...] Text Encoding and Interchange

I wonder if for other readers the notion of "interchange" changes with the
emphasis. It does for me. Of course, I begin and return often to
descriptions and theorizations of non-electronic interchange. There are
other ways.


--
Francois Lachance, Scholar-at-large
http://www.chass.utoronto.ca/~lachance/jardin/html/blogTEI.htm#modeling101
=========================================================================
Date:         Sun, 9 Jan 2005 05:56:50 EST
Reply-To:     DrWender@AOL.COM
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Herbert Wender <DrWender@AOL.COM>
Subject:      Re: Placement of <pb/>
Comments: To: jwkenne@ATTGLOBAL.NET
MIME-Version: 1.0
Content-Type: multipart/alternative;
              boundary="part1_6.3c192ebe.2f1267f2_boundary"

--part1_6.3c192ebe.2f1267f2_boundary
Content-Type: text/plain; charset="ISO-8859-1"
Content-Transfer-Encoding: quoted-printable

In einer eMail vom 08.01.05 15:53:08 (MEZ) Mitteleurop=E4ische Zeit schreibt=
=20
jwkenne@ATTGLOBAL.NET:


> Herbert Wender wrote:
> > Looking the source
> > code f.e. of Kennedys "Double Falshood" markup
> > I have a feeling, a little bit as with some critical editions:
> > The most interesting deviations of standard schemes
> > are hardly visible in the bulk of ongoing trivialities.
>=20
>=20
> [...] I /chose/ to include all possible information, including
> catchwords, press figures, and running heads (including errors in same).
>=20
>=20

Surely I do _not_ criticize this practice of transmitting
"all possible information" as such - all facsimile editions
very estimated by me (H=F6lderlin, Kafka, Trakl & others)
with transcriptions on the counterpage of the facsimiles do
the same and can't do it otherwise. (Perhaps this is their
weakest point: they can't generalize in cases of
recurrent phenomena.)

When I suspect 'information overload' I mean the mass
of markup material found in the examples I'm studying
which I - amateur in TEI questions - judge as redundant
wondering why not some procedures are foreseen for
derive derived information - in my view this is an
equivalent term for 'exlicited information given implicite
in the described object - from some already existent (basic)
markup or from object text itself. I'm using your edition
as example because it was already mentioned in this
thread, and would take following page breaks
resp. headers of some div-s:

<div1 type=3D"preface" id=3D"Preface" rend=3D"roman">
<head><pb n=3D"ix"/><figure><figDesc>Floral ornament with peacocks</figDesc>=
<
/figure><hi rend=3D"caps">Preface<lb/>of the<lb/>Editor.</hi><lb/></head>
[...]
</front>
<body rend=3D"roman">
<head><pb n=3D"1"/><figure><figDesc>Floral ornament with putti</figDesc><
/figure><title><hi rend=3D"caps">Double <orig reg=3D"Falsehood">Falshood</or=
ig>;<lb/>or,<
/hi><lb/><hi rend=3D"italic">The</hi> <orig reg=3D"Distressed">D<hi=20
rend=3D"smallCaps">istrest</hi></orig> L<hi rend=3D"smallCaps">overs</hi>.</=
title><figure><
figDesc>Rule</figDesc></figure></head>
<div1 type=3D"act" id=3D"I" n=3D"I">
<div2 type=3D"scene" id=3D"I.i" n=3D"i">
<head><hi rend=3D"caps">Act</hi> I. <hi rend=3D"caps">Scene</hi> I.</head>
[...]
alone I<fw place=3D"bottom-right" type=3D"catch">snatch'd</fw><pb n=3D"14"/>=
<fw=20
place=3D"top-left" type=3D"page">14</fw><fw place=3D"top-centre" type=3D"hea=
d">D<hi=20
rend=3D"smallCaps">ouble</hi> <orig reg=3D"Falsehood">F<hi rend=3D"smallCaps=
">alshood</hi>
</orig>; <hi rend=3D"italic">or,</hi></fw>snatch'd [...]

Strictly differentiating between the two levels of text,
object and meta text, i.e. the stuff between the tags resp.=20
the markup strewed in by the editor (BTW the content
of element "figDesc" I would put in editor's [brackets]),
I understand that you build a consistent parallel
segmentation because the given denominations in
object text like "Act I." etc., "Scene I." etc. are maybe
inconsistent (but I would prefer a system of default
references where the described object is consistent).
It seems there is a well defined building rule for
the "id" strings of "div1" and "div2" level: To build
a div2-id take the iancestor-id mark the segmentation
of composed id by a point and add the n-value
of the given div2 element; to build div1-id you take
only the n-value of the given div1 element. Probably
this system of id-references could be formulated as
inductive for level 1 and level i+1? Must the results
all be in place given becaus someone would extract
some piece of the TEI-encoded source without the
appropriate ancestor informtions (as Franc,ois Lachance
in one of his last mails seems to be mentioning)?
Or is it an implication of a pure declarative markup system
strictly avoiding (resp. banning in XSLT) all what could
be seen as 'procedural'? This is a question like some
others earlier discussed, a question of 'markup
philosophy'; I was not intending to criticize especially
the discussed edition which I admire as example of
good editorial practice independently of the encoding
discussions.

Best regards,
Herbert










--part1_6.3c192ebe.2f1267f2_boundary
Content-Type: text/html; charset="ISO-8859-1"
Content-Transfer-Encoding: quoted-printable

<HTML><FONT FACE=3Darial,helvetica><HTML><FONT  SIZE=3D3 PTSIZE=3D12 FAMILY=
=3D"SANSSERIF" FACE=3D"Arial" LANG=3D"2">In einer eMail vom 08.01.05 15:53:0=
8 (MEZ) Mitteleurop=E4ische Zeit schreibt jwkenne@ATTGLOBAL.NET:<BR>
<BR>
</FONT><FONT  COLOR=3D"#000000" BACK=3D"#ffffff" style=3D"BACKGROUND-COLOR:=20=
#ffffff" SIZE=3D2 PTSIZE=3D10 FAMILY=3D"SANSSERIF" FACE=3D"Arial" LANG=3D"2"=
><BR>
<BLOCKQUOTE TYPE=3DCITE style=3D"BORDER-LEFT: #0000ff 2px solid; MARGIN-LEFT=
: 5px; MARGIN-RIGHT: 0px; PADDING-LEFT: 5px">Herbert Wender wrote:<BR>
&gt; Looking the source<BR>
&gt; code f.e. of Kennedys "Double Falshood" markup<BR>
&gt; I have a feeling, a little bit as with some critical editions:<BR>
&gt; The most interesting deviations of standard schemes<BR>
&gt; are hardly visible in the bulk of ongoing trivialities.<BR>
<BR>
<BR>
[...] I /chose/ to include all possible information, including<BR>
catchwords, press figures, and running heads (including errors in same).<BR>
<BR>
</BLOCKQUOTE><BR>
</FONT><FONT  COLOR=3D"#000000" BACK=3D"#ffffff" style=3D"BACKGROUND-COLOR:=20=
#ffffff" SIZE=3D3 PTSIZE=3D12 FAMILY=3D"SANSSERIF" FACE=3D"Arial" LANG=3D"2"=
><BR>
Surely I do _not_ criticize this practice of transmitting<BR>
"all possible information" as such - all facsimile editions<BR>
very estimated by me (H=F6lderlin, Kafka, Trakl &amp; others)<BR>
with transcriptions on the counterpage of the facsimiles do<BR>
the same and can't do it otherwise. (Perhaps this is their<BR>
weakest point: they can't generalize in cases of<BR>
recurrent phenomena.)<BR>
<BR>
When I suspect 'information overload' I mean the mass<BR>
of markup material found in the examples I'm studying<BR>
which I - amateur in TEI questions - judge as redundant<BR>
wondering why not some procedures are foreseen for<BR>
derive derived information - in my view this is an<BR>
equivalent term for 'exlicited information given implicite<BR>
in the described object - from some already existent (basic)<BR>
markup or from object text itself. I'm using your edition<BR>
as example because it was already mentioned in this<BR>
thread, and would take following page breaks<BR>
resp. headers of some div-s:<BR>
<BR>
&lt;div1 type=3D"preface" id=3D"Preface" rend=3D"roman"&gt;<BR>
&lt;head&gt;&lt;pb n=3D"ix"/&gt;&lt;figure&gt;&lt;figDesc&gt;Floral ornament=
 with peacocks&lt;/figDesc&gt;&lt;/figure&gt;&lt;hi rend=3D"caps"&gt;Preface=
&lt;lb/&gt;of the&lt;lb/&gt;Editor.&lt;/hi&gt;&lt;lb/&gt;&lt;/head&gt;<BR>
[...]<BR>
&lt;/front&gt;<BR>
&lt;body rend=3D"roman"&gt;<BR>
&lt;head&gt;&lt;pb n=3D"1"/&gt;&lt;figure&gt;&lt;figDesc&gt;Floral ornament=20=
with putti&lt;/figDesc&gt;&lt;/figure&gt;&lt;title&gt;&lt;hi rend=3D"caps"&g=
t;Double &lt;orig reg=3D"Falsehood"&gt;Falshood&lt;/orig&gt;;&lt;lb/&gt;or,&=
lt;/hi&gt;&lt;lb/&gt;&lt;hi rend=3D"italic"&gt;The&lt;/hi&gt; &lt;orig reg=
=3D"Distressed"&gt;D&lt;hi rend=3D"smallCaps"&gt;istrest&lt;/hi&gt;&lt;/orig=
&gt; L&lt;hi rend=3D"smallCaps"&gt;overs&lt;/hi&gt;.&lt;/title&gt;&lt;figure=
&gt;&lt;figDesc&gt;Rule&lt;/figDesc&gt;&lt;/figure&gt;&lt;/head&gt;<BR>
&lt;div1 type=3D"act" id=3D"I" n=3D"I"&gt;<BR>
&lt;div2 type=3D"scene" id=3D"I.i" n=3D"i"&gt;<BR>
&lt;head&gt;&lt;hi rend=3D"caps"&gt;Act&lt;/hi&gt; I. &lt;hi rend=3D"caps"&g=
t;Scene&lt;/hi&gt; I.&lt;/head&gt;<BR>
[...]<BR>
alone I&lt;fw place=3D"bottom-right" type=3D"catch"&gt;snatch'd&lt;/fw&gt;&l=
t;pb n=3D"14"/&gt;&lt;fw place=3D"top-left" type=3D"page"&gt;14&lt;/fw&gt;&l=
t;fw place=3D"top-centre" type=3D"head"&gt;D&lt;hi rend=3D"smallCaps"&gt;oub=
le&lt;/hi&gt; &lt;orig reg=3D"Falsehood"&gt;F&lt;hi rend=3D"smallCaps"&gt;al=
shood&lt;/hi&gt;&lt;/orig&gt;; &lt;hi rend=3D"italic"&gt;or,&lt;/hi&gt;&lt;/=
fw&gt;snatch'd [...]<BR>
<BR>
Strictly differentiating between the two levels of text,<BR>
object and meta text, i.e. the stuff between the tags resp. <BR>
the markup strewed in by the editor (BTW the content<BR>
of element "figDesc" I would put in editor's [brackets]),<BR>
I understand that you build a consistent parallel<BR>
segmentation because the given denominations in<BR>
object text like "Act I." etc., "Scene I." etc. are maybe<BR>
inconsistent (but I would prefer a system of default<BR>
references where the described object is consistent).<BR>
It seems there is a well defined building rule for<BR>
the "id" strings of "div1" and "div2" level: To build<BR>
a div2-id take the iancestor-id mark the segmentation<BR>
of composed id by a point and add the n-value<BR>
of the given div2 element; to build div1-id you take<BR>
only the n-value of the given div1 element. Probably<BR>
this system of id-references could be formulated as<BR>
inductive for level 1 and level i+1? Must the results<BR>
all be in place given becaus someone would extract<BR>
some piece of the TEI-encoded source without the<BR>
appropriate ancestor informtions (as Franc,ois Lachance<BR>
in one of his last mails seems to be mentioning)?<BR>
Or is it an implication of a pure declarative markup system<BR>
strictly avoiding (resp. banning in XSLT) all what could<BR>
be seen as 'procedural'? This is a question like some<BR>
others earlier discussed, a question of 'markup<BR>
philosophy'; I was not intending to criticize especially<BR>
the discussed edition which I admire as example of<BR>
good editorial practice independently of the encoding<BR>
discussions.<BR>
<BR>
Best regards,<BR>
Herbert<BR>
<BR>
<BR>
<BR>
<BR>
<BR>
<BR>
<BR>
<BR>
<BR>
</FONT></HTML>
--part1_6.3c192ebe.2f1267f2_boundary--
=========================================================================
Date:         Sun, 9 Jan 2005 04:12:33 +0000
Reply-To:     Sebastian Rahtz <sebastian.rahtz@COMPUTING-SERVICES.OXFORD.AC.UK>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Sebastian Rahtz <sebastian.rahtz@COMPUTING-SERVICES.OXFORD.AC.UK>
Subject:      Re: [ANN] oXygen XML Editor 5.1 beta
In-Reply-To:  <200501061430.j06EUbl21513@listserv.brown.edu>
MIME-Version: 1.0
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit

For oXygen, TEI P5 and Roma fans, I  have updated the schemas and
stylesheets which Roma (http://www.tei-c.org/Roma/) uses
so that Relax NG and W3C Schemas which are generated contain
descriptions of all elements, attributes and
attribute value lists, as schema annotations.  If you use the W3C Schema
result with oXygen 1.5, it will show you
the annotations when you put in new elements or attributes, or hover
over elements. Maybe I'm just
bemused by gadgets, but I reckon this is pretty cool, and an excellent
feature of the editor....

You won't get this feature with the TEI shipped with oXygen by default,
but I hope the good folks at Synco RO Soft will ship the P5 schemas
in future releases.

--
Sebastian Rahtz
Information Manager, Oxford University Computing Services
13 Banbury Road, Oxford OX2 6NN. Phone +44 1865 283431

OSS Watch: JISC Open Source Advisory Service
http://www.oss-watch.ac.uk
=========================================================================
Date:         Tue, 11 Jan 2005 09:05:26 +0100
Reply-To:     Gjert Kristoffersen <gjert.kristoffersen@AKSIS.UIB.NO>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Gjert Kristoffersen <gjert.kristoffersen@AKSIS.UIB.NO>
Subject:      Annotation of speech corpora for phonological analysis
MIME-Version: 1.0
Content-Type: text/html; charset=us-ascii
Content-Transfer-Encoding: 7bit

<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
<head>
  <meta content="text/html;charset=ISO-8859-1" http-equiv="Content-Type">
  <title></title>
</head>
<body bgcolor="#ffffff" text="#000000">
<><span style=""><br>
<o:p></o:p>On behalf of a group
of European phonologists/sociolinguists, I&#8217;m looking for people who
have
experience in XML-coding of transcriptions of speech for use in
phonological
analysis from different perspectives, such as sociolinguistic
variation,
structurally constrained variation, language change etc. What I have
been able
to find in the TEI guidelines is not very satisfactory for our needs,
so we
would be interested in developing cooperation with experts on
TEI-markup and an
interest in phonology and/or phonetics. <o:p></o:p></span></>
<p class="MsoNormal"><span style="">The first step planned
is to submit an application to the European Science Foundation this
spring for
funding of an exploratory workshop in 2006 where we would convene a
group of
phonologists with interest and experience in the use of speech corpora,
experts
on database construction and experts on XML-coding. The last two
groups, to the
extent that they are not phonologists or phoneticians as well, should
have an
interest in and a basic understanding of phonology. All participants
must work
in Europe.<br>
</span></p>
<><span lang="NO-BOK">Best regards<br>
<br>
Gjert Kristoffersen<br>
------------------------------------------<br>
<br>
Forskningsdirekt&oslash;r / Research Director<br>
- Avdeling for kultur, spr&aring;k og informasjonsteknologi (Aksis),
Universitetsforskning (Unifob) AS<br>
- Department of culture, language and information technology (Aksis),
Universitetsforskning (Unifob) AS<br>
<a class="moz-txt-link-freetext" href="http://www.aksis.uib.no/">http://www.aksis.uib.no/</a><br>
<br>
Professor i nordisk spr&aring;kvitenskap / Professor of Scandinavian
Linguistics<br>
Nordisk institutt / Dept. of Scandinavian Languages and Literature<br>
Universitetet i Bergen / University of Bergen</span></>
<p class="MsoNormal"><span lang="NO-BOK">Telefon / Telephone: +47 55 58
29 50<br>
Mobile / Mobile: +47 90 19 77 09<br>
Telefaks / Telefax: +47 55 58 94 70<br>
<a class="moz-txt-link-freetext" href="http://helmer.hit.uib.no/Gjert/">http://helmer.hit.uib.no/Gjert/</a></span></p>
<p class="MsoNormal"><span style="">&nbsp;<o:p></o:p></span></p>
</body>
</html>
=========================================================================
Date:         Tue, 11 Jan 2005 10:54:56 +0100
Reply-To:     Daniele Marotta <marotta@CRIBECU.SNS.IT>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Daniele Marotta <marotta@CRIBECU.SNS.IT>
Subject:      About <front> - table of content - <figure>
MIME-Version: 1.0
Content-Type: multipart/alternative;
              boundary="----=_NextPart_000_001C_01C4F7CB.FCEB3030"

This is a multi-part message in MIME format.

------=_NextPart_000_001C_01C4F7CB.FCEB3030
Content-Type: text/plain;
        charset="iso-8859-1"
Content-Transfer-Encoding: quoted-printable

Hi all,
I should ask three questions:

=20

1. about use of <front>. I work on texts that haven't always a structure =
so made: "prefatory matter-body of text-final matter" =
(<front></front><body></body><back></back>), but also on those with:

a) prefatory matter referred to whole document and prefatory matter =
referred to single section of main body (for example, dedications of =
single books)

b) prefatory matter that, even if it refer to single section, talk about =
subjects tipically of another section (that usually get an own preface =
or dedication, etc).

I would note that I'm talking about texts regarded as unitary, that is, =
forming an organic whole, and not as composite.=20

For example, if there is a work that presents one preface and two books =
each one has a dedication, is it correct to mark as in the next way?

=20

<TEI.2>=20

<teiHeader> <!-- ... --> </teiHeader>=20

<text>=20

<front>=20

<div1 n=3D"1" type=3D"preface">...</div1>

</front>=20

<body>=20

<div1 n=3D"1" type=3D"book">

<div2 n=3D"1" type=3D"dedication">...</div2>

<div2 n=3D"2" type=3D"chapter">...</div2>

...................................

</div1>

<div1 n=3D"2" type=3D"book">

<div2 n=3D"1" type=3D"dedication">...</div2>

<div2 n=3D"2" type=3D"chapter">...</div2>

...................................

</div1>

</body>=20

</text>=20

</TEI.2>

=20

For example, if there is a work composed of three books whose two first =
have a common dedication and third has a own dedication, is it correct =
to mark as in the next way?

=20

<TEI.2>=20

<teiHeader> <!-- ... --> </teiHeader>=20

<text>=20

<body>=20

<div1 n=3D"1" type=3D"book">

<div2 n=3D"1" type=3D"dedication">...</div2>

<div2 n=3D"2" type=3D"chapter">...</div2>

...................................

</div1>

<div1 n=3D"2" type=3D"book">

<div2 n=3D"1" type=3D"chapter">...</div2>

...................................

</div1>

<div1 type=3D"book" n=3D"3">

<div2 n=3D"1" type=3D"dedication">...</div2>

<div2 n=3D"2" type=3D"chapter">...</div2>

...................................

</div1>

</body>=20

</text>=20

</TEI.2>

=20

Alternatively, is it correct that all parts of the work are considered =
as <body> indistinctly?

=20

2. about automatic production of table of contents of digital edition=20

Our software, that elaborate .xml files, is able to produce =
automatically the table of contents by <div>, but the titles that =
compose it are not taken by content model <head>, because they could be =
different in the form and/or in the content. Moreover, we use a short =
title, always led to <div>, that allows to contextualize the results of =
research inside the text.=20

For these reasons I thought to add to the <head>, that include the title =
present on the source, other two <head>, that present a different type, =
in which are present the titles added by the encoder for the elaboration =
of the text and not added to the text.

For example,

=20

source: "Caput I. Incertam esse artem istam iudicio etiam principum =
illius.

=20

Sed ne sola auctoritate pugnemus, demonstrabimus toto

hoc opere certis rationibus reiectam iure a sanctis istam

.........................................................................=
................"

=20

marked text:          ..........................................

<div1 n=3D"1" type=3D"chapter">

<head>Caput I. Incertam esse artem istam iudicio etiam principum =
illius.</head>

<head type=3D"alternative">Caput I. </head>

<head type=3D"short">Cap. I</head>

<p>Sed ne sola auctoritate pugnemus, demonstrabimus toto

hoc opere certis rationibus reiectam iure a sanctis istam

.........................................................................=
................</p>

                               </div1>

                               =
...........................................

Is all this procedure correct or must the <head> contain only the text =
present really in the source?

In this last case, in TEI is it present a tag able to meet this =
requirement or is it more correct introduce a new dedicated tag?

=20

3. about <figure>: is it correct to reproduce inside <p> the text =
present in the image or is it necessary to reproduce it inside <text>? =
If it is possible to use <p> to distinguish image text from caption, is =
it correct to mark as next way?

=20

<figure>

         <head></head>

         <p><!--caption--></p>

         <p><seg type=3D"imgText"><!--text present in the =
image--></seg></p>

</figure>



Thank you very much in advance.
Daniele Marotta

--=20
 =
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D
  Daniele Marotta - Computer Research for Cultural Heritage Centre
 ------------------------------------------------------------------
  via della Faggiola, 19 - 56127 Pisa (Italy)
  Phone:  +39 (0)50 509409
  e-mail: marotta@cribecu.sns.it=20


------=_NextPart_000_001C_01C4F7CB.FCEB3030
Content-Type: text/html;
        charset="iso-8859-1"
Content-Transfer-Encoding: quoted-printable

<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN">
<HTML><HEAD>
<META http-equiv=3DContent-Type content=3D"text/html; =
charset=3Diso-8859-1">
<META content=3D"MSHTML 6.00.2723.2500" name=3DGENERATOR>
<STYLE></STYLE>
</HEAD>
<BODY bgColor=3D#ffffff>
<DIV>Hi all,</DIV>
<DIV>
<P class=3DMsoNormal style=3D"MARGIN: 0cm 0cm 0pt"><SPAN lang=3DEN-GB=20
style=3D"mso-ansi-language: EN-GB">I should ask&nbsp;three=20
questions:<?xml:namespace prefix =3D o ns =3D=20
"urn:schemas-microsoft-com:office:office" /><o:p></o:p></SPAN></P>
<P class=3DMsoNormal style=3D"MARGIN: 0cm 0cm 0pt"><SPAN lang=3DEN-GB=20
style=3D"mso-ansi-language: EN-GB"><o:p>&nbsp;</o:p></SPAN></P>
<P class=3DMsoNormal style=3D"MARGIN: 0cm 0cm 0pt"><SPAN lang=3DEN-GB=20
style=3D"mso-ansi-language: EN-GB">1. about use of &lt;front&gt;. I work =
on texts=20
that haven=92t always a structure so made: "prefatory matter-body of =
text-final=20
matter"=20
(&lt;front&gt;&lt;/front&gt;&lt;body&gt;&lt;/body&gt;&lt;back&gt;&lt;/bac=
k&gt;),=20
but also on those with:<o:p></o:p></SPAN></P>
<P class=3DMsoNormal style=3D"MARGIN: 0cm 0cm 0pt 35.25pt"><SPAN =
lang=3DEN-GB=20
style=3D"mso-ansi-language: EN-GB">a) prefatory matter referred to whole =
document=20
and prefatory matter referred to single section of main body (for =
example,=20
dedications of single books)<o:p></o:p></SPAN></P>
<P class=3DMsoNormal style=3D"MARGIN: 0cm 0cm 0pt 35.25pt"><SPAN =
lang=3DEN-GB=20
style=3D"mso-ansi-language: EN-GB">b) prefatory matter that, even if it =
refer to=20
single section, talk about subjects tipically of another section (that =
usually=20
get an own preface or dedication, etc).<o:p></o:p></SPAN></P>
<P class=3DMsoNormal style=3D"MARGIN: 0cm 0cm 0pt"><SPAN lang=3DEN-GB=20
style=3D"mso-ansi-language: EN-GB">I would note that I=92m talking about =
texts=20
regarded as <EM><SPAN style=3D"FONT-STYLE: normal">unitary, =
</SPAN></EM>that is,=20
forming an organic whole, <EM><SPAN style=3D"FONT-STYLE: normal">and not =
as=20
composite. <o:p></o:p></SPAN></EM></SPAN></P>
<P class=3DMsoNormal style=3D"MARGIN: 0cm 0cm 0pt"><EM><SPAN =
lang=3DEN-GB=20
style=3D"FONT-STYLE: normal; mso-ansi-language: EN-GB">For example, if =
there is a=20
work that presents one preface and two books each one has a dedication, =
is it=20
correct to mark as in the next way?<o:p></o:p></SPAN></EM></P>
<P class=3DMsoNormal style=3D"MARGIN: 0cm 0cm 0pt"><EM><SPAN =
lang=3DEN-GB=20
style=3D"FONT-STYLE: normal; mso-ansi-language: =
EN-GB"><o:p>&nbsp;</o:p></SPAN></EM></P>
<P class=3DMsoNormal style=3D"MARGIN: 0cm 0cm 0pt; TEXT-INDENT: =
35.4pt"><SPAN=20
lang=3DEN-GB style=3D"mso-ansi-language: EN-GB">&lt;TEI.2&gt; =
<o:p></o:p></SPAN></P>
<P class=3DMsoNormal style=3D"MARGIN: 0cm 0cm 0pt 35.4pt; TEXT-INDENT: =
35.4pt"><SPAN=20
lang=3DEN-GB style=3D"mso-ansi-language: EN-GB">&lt;teiHeader&gt; =
&lt;!-- ... --&gt;=20
&lt;/teiHeader&gt; <o:p></o:p></SPAN></P>
<P class=3DMsoNormal style=3D"MARGIN: 0cm 0cm 0pt 35.4pt; TEXT-INDENT: =
35.4pt"><SPAN=20
lang=3DEN-GB style=3D"mso-ansi-language: EN-GB">&lt;text&gt; =
<o:p></o:p></SPAN></P>
<P class=3DMsoNormal style=3D"MARGIN: 0cm 0cm 0pt 70.8pt; TEXT-INDENT: =
35.4pt"><SPAN=20
lang=3DEN-GB style=3D"mso-ansi-language: EN-GB">&lt;front&gt; =
<o:p></o:p></SPAN></P>
<P class=3DMsoNormal=20
style=3D"MARGIN: 0cm 0cm 0pt 106.2pt; TEXT-INDENT: 35.4pt"><SPAN =
lang=3DEN-GB=20
style=3D"mso-ansi-language: EN-GB">&lt;div1 n=3D"1"=20
type=3D"preface"&gt;...&lt;/div1&gt;<o:p></o:p></SPAN></P>
<P class=3DMsoNormal style=3D"MARGIN: 0cm 0cm 0pt 70.8pt; TEXT-INDENT: =
35.4pt"><SPAN=20
lang=3DEN-GB style=3D"mso-ansi-language: EN-GB">&lt;/front&gt;=20
<o:p></o:p></SPAN></P>
<P class=3DMsoNormal style=3D"MARGIN: 0cm 0cm 0pt 70.8pt; TEXT-INDENT: =
35.4pt"><SPAN=20
lang=3DEN-GB style=3D"mso-ansi-language: EN-GB">&lt;body&gt; =
<o:p></o:p></SPAN></P>
<P class=3DMsoNormal=20
style=3D"MARGIN: 0cm 0cm 0pt 106.2pt; TEXT-INDENT: 35.4pt"><SPAN =
lang=3DEN-GB=20
style=3D"mso-ansi-language: EN-GB">&lt;div1 n=3D"1"=20
type=3D"book"&gt;<o:p></o:p></SPAN></P>
<P class=3DMsoNormal=20
style=3D"MARGIN: 0cm 0cm 0pt 141.6pt; TEXT-INDENT: 35.4pt"><SPAN =
lang=3DEN-GB=20
style=3D"mso-ansi-language: EN-GB">&lt;div2 n=3D"1"=20
type=3D"dedication"&gt;...&lt;/div2&gt;<o:p></o:p></SPAN></P>
<P class=3DMsoNormal=20
style=3D"MARGIN: 0cm 0cm 0pt 141.6pt; TEXT-INDENT: 35.4pt"><SPAN =
lang=3DEN-GB=20
style=3D"mso-ansi-language: EN-GB">&lt;div2 n=3D"2"=20
type=3D"chapter"&gt;...&lt;/div2&gt;<o:p></o:p></SPAN></P>
<P class=3DMsoNormal=20
style=3D"MARGIN: 0cm 0cm 0pt 141.6pt; TEXT-INDENT: 35.4pt"><SPAN =
lang=3DEN-GB=20
style=3D"mso-ansi-language: =
EN-GB">...................................<o:p></o:p></SPAN></P>
<P class=3DMsoNormal=20
style=3D"MARGIN: 0cm 0cm 0pt 106.2pt; TEXT-INDENT: 35.4pt"><SPAN =
lang=3DEN-GB=20
style=3D"mso-ansi-language: EN-GB">&lt;/div1&gt;<o:p></o:p></SPAN></P>
<P class=3DMsoNormal=20
style=3D"MARGIN: 0cm 0cm 0pt 106.2pt; TEXT-INDENT: 35.4pt"><SPAN =
lang=3DEN-GB=20
style=3D"mso-ansi-language: EN-GB">&lt;div1 n=3D"2"=20
type=3D"book"&gt;<o:p></o:p></SPAN></P>
<P class=3DMsoNormal=20
style=3D"MARGIN: 0cm 0cm 0pt 141.6pt; TEXT-INDENT: 35.4pt"><SPAN =
lang=3DEN-GB=20
style=3D"mso-ansi-language: EN-GB">&lt;div2 n=3D"1"=20
type=3D"dedication"&gt;...&lt;/div2&gt;<o:p></o:p></SPAN></P>
<P class=3DMsoNormal=20
style=3D"MARGIN: 0cm 0cm 0pt 141.6pt; TEXT-INDENT: 35.4pt"><SPAN =
lang=3DEN-GB=20
style=3D"mso-ansi-language: EN-GB">&lt;div2 n=3D"2"=20
type=3D"chapter"&gt;...&lt;/div2&gt;<o:p></o:p></SPAN></P>
<P class=3DMsoNormal=20
style=3D"MARGIN: 0cm 0cm 0pt 141.6pt; TEXT-INDENT: 35.4pt"><SPAN =
lang=3DEN-GB=20
style=3D"mso-ansi-language: =
EN-GB">...................................<o:p></o:p></SPAN></P>
<P class=3DMsoNormal=20
style=3D"MARGIN: 0cm 0cm 0pt 106.2pt; TEXT-INDENT: 35.4pt"><SPAN =
lang=3DEN-GB=20
style=3D"mso-ansi-language: EN-GB">&lt;/div1&gt;<o:p></o:p></SPAN></P>
<P class=3DMsoNormal style=3D"MARGIN: 0cm 0cm 0pt 70.8pt; TEXT-INDENT: =
35.4pt"><SPAN=20
lang=3DEN-GB style=3D"mso-ansi-language: EN-GB">&lt;/body&gt; =
<o:p></o:p></SPAN></P>
<P class=3DMsoNormal style=3D"MARGIN: 0cm 0cm 0pt 35.4pt; TEXT-INDENT: =
35.4pt"><SPAN=20
lang=3DEN-GB style=3D"mso-ansi-language: EN-GB">&lt;/text&gt; =
<o:p></o:p></SPAN></P>
<P class=3DMsoNormal style=3D"MARGIN: 0cm 0cm 0pt; TEXT-INDENT: =
35.4pt"><SPAN=20
lang=3DEN-GB style=3D"mso-ansi-language: =
EN-GB">&lt;/TEI.2&gt;<o:p></o:p></SPAN></P>
<P class=3DMsoNormal style=3D"MARGIN: 0cm 0cm 0pt"><SPAN lang=3DEN-GB=20
style=3D"mso-ansi-language: EN-GB"><o:p>&nbsp;</o:p></SPAN></P>
<P class=3DMsoNormal style=3D"MARGIN: 0cm 0cm 0pt"><SPAN lang=3DEN-GB=20
style=3D"mso-ansi-language: EN-GB">For example, <EM><SPAN=20
style=3D"FONT-STYLE: normal">if there is a work composed of three books =
whose two=20
first have a common dedication and third has a own dedication, is it =
correct to=20
mark as in the next way?<o:p></o:p></SPAN></EM></SPAN></P>
<P class=3DMsoNormal style=3D"MARGIN: 0cm 0cm 0pt"><SPAN lang=3DEN-GB=20
style=3D"mso-ansi-language: EN-GB"><SPAN=20
style=3D"mso-spacerun: yes">&nbsp;</SPAN><o:p></o:p></SPAN></P>
<P class=3DMsoNormal style=3D"MARGIN: 0cm 0cm 0pt; TEXT-INDENT: =
35.4pt"><SPAN=20
lang=3DEN-GB style=3D"mso-ansi-language: EN-GB">&lt;TEI.2&gt; =
<o:p></o:p></SPAN></P>
<P class=3DMsoNormal style=3D"MARGIN: 0cm 0cm 0pt 35.4pt; TEXT-INDENT: =
35.4pt"><SPAN=20
lang=3DEN-GB style=3D"mso-ansi-language: EN-GB">&lt;teiHeader&gt; =
&lt;!-- ... --&gt;=20
&lt;/teiHeader&gt; <o:p></o:p></SPAN></P>
<P class=3DMsoNormal style=3D"MARGIN: 0cm 0cm 0pt 35.4pt; TEXT-INDENT: =
35.4pt"><SPAN=20
lang=3DEN-GB style=3D"mso-ansi-language: EN-GB">&lt;text&gt; =
<o:p></o:p></SPAN></P>
<P class=3DMsoNormal style=3D"MARGIN: 0cm 0cm 0pt 70.8pt; TEXT-INDENT: =
35.4pt"><SPAN=20
lang=3DEN-GB style=3D"mso-ansi-language: EN-GB">&lt;body&gt; =
<o:p></o:p></SPAN></P>
<P class=3DMsoNormal=20
style=3D"MARGIN: 0cm 0cm 0pt 106.2pt; TEXT-INDENT: 35.4pt"><SPAN =
lang=3DEN-GB=20
style=3D"mso-ansi-language: EN-GB">&lt;div1 n=3D"1"=20
type=3D"book"&gt;<o:p></o:p></SPAN></P>
<P class=3DMsoNormal=20
style=3D"MARGIN: 0cm 0cm 0pt 141.6pt; TEXT-INDENT: 35.4pt"><SPAN =
lang=3DEN-GB=20
style=3D"mso-ansi-language: EN-GB">&lt;div2 n=3D"1"=20
type=3D"dedication"&gt;...&lt;/div2&gt;<o:p></o:p></SPAN></P>
<P class=3DMsoNormal=20
style=3D"MARGIN: 0cm 0cm 0pt 141.6pt; TEXT-INDENT: 35.4pt"><SPAN =
lang=3DEN-GB=20
style=3D"mso-ansi-language: EN-GB">&lt;div2 n=3D"2"=20
type=3D"chapter"&gt;...&lt;/div2&gt;<o:p></o:p></SPAN></P>
<P class=3DMsoNormal=20
style=3D"MARGIN: 0cm 0cm 0pt 141.6pt; TEXT-INDENT: 35.4pt"><SPAN =
lang=3DEN-GB=20
style=3D"mso-ansi-language: =
EN-GB">...................................<o:p></o:p></SPAN></P>
<P class=3DMsoNormal=20
style=3D"MARGIN: 0cm 0cm 0pt 106.2pt; TEXT-INDENT: 35.4pt"><SPAN =
lang=3DEN-GB=20
style=3D"mso-ansi-language: EN-GB">&lt;/div1&gt;<o:p></o:p></SPAN></P>
<P class=3DMsoNormal=20
style=3D"MARGIN: 0cm 0cm 0pt 106.2pt; TEXT-INDENT: 35.4pt"><SPAN =
lang=3DEN-GB=20
style=3D"mso-ansi-language: EN-GB">&lt;div1 n=3D"2"=20
type=3D"book"&gt;<o:p></o:p></SPAN></P>
<P class=3DMsoNormal=20
style=3D"MARGIN: 0cm 0cm 0pt 141.6pt; TEXT-INDENT: 35.4pt"><SPAN =
lang=3DEN-GB=20
style=3D"mso-ansi-language: EN-GB">&lt;div2 n=3D"1"=20
type=3D"chapter"&gt;...&lt;/div2&gt;<o:p></o:p></SPAN></P>
<P class=3DMsoNormal=20
style=3D"MARGIN: 0cm 0cm 0pt 141.6pt; TEXT-INDENT: 35.4pt"><SPAN =
lang=3DEN-GB=20
style=3D"mso-ansi-language: =
EN-GB">...................................<o:p></o:p></SPAN></P>
<P class=3DMsoNormal=20
style=3D"MARGIN: 0cm 0cm 0pt 106.2pt; TEXT-INDENT: 35.4pt"><SPAN =
lang=3DEN-GB=20
style=3D"mso-ansi-language: EN-GB">&lt;/div1&gt;<o:p></o:p></SPAN></P>
<P class=3DMsoNormal=20
style=3D"MARGIN: 0cm 0cm 0pt 106.2pt; TEXT-INDENT: 35.4pt"><SPAN =
lang=3DEN-GB=20
style=3D"mso-ansi-language: EN-GB">&lt;div1 type=3D"book"=20
n=3D"3"&gt;<o:p></o:p></SPAN></P>
<P class=3DMsoNormal=20
style=3D"MARGIN: 0cm 0cm 0pt 141.6pt; TEXT-INDENT: 35.4pt"><SPAN =
lang=3DEN-GB=20
style=3D"mso-ansi-language: EN-GB">&lt;div2 n=3D"1"=20
type=3D"dedication"&gt;...&lt;/div2&gt;<o:p></o:p></SPAN></P>
<P class=3DMsoNormal=20
style=3D"MARGIN: 0cm 0cm 0pt 141.6pt; TEXT-INDENT: 35.4pt"><SPAN =
lang=3DEN-GB=20
style=3D"mso-ansi-language: EN-GB">&lt;div2 n=3D"2"=20
type=3D"chapter"&gt;...&lt;/div2&gt;<o:p></o:p></SPAN></P>
<P class=3DMsoNormal=20
style=3D"MARGIN: 0cm 0cm 0pt 141.6pt; TEXT-INDENT: =
35.4pt">...................................</P>
<P class=3DMsoNormal=20
style=3D"MARGIN: 0cm 0cm 0pt 106.2pt; TEXT-INDENT: =
35.4pt">&lt;/div1&gt;</P>
<P class=3DMsoNormal=20
style=3D"MARGIN: 0cm 0cm 0pt 70.8pt; TEXT-INDENT: 35.4pt">&lt;/body&gt; =
</P>
<P class=3DMsoNormal=20
style=3D"MARGIN: 0cm 0cm 0pt 35.4pt; TEXT-INDENT: 35.4pt">&lt;/text&gt; =
</P>
<P class=3DMsoNormal style=3D"MARGIN: 0cm 0cm 0pt">&lt;/TEI.2&gt;</P>
<P class=3DMsoNormal style=3D"MARGIN: 0cm 0cm 0pt"><o:p>&nbsp;</o:p></P>
<P class=3DMsoNormal style=3D"MARGIN: 0cm 0cm 0pt"><SPAN lang=3DEN-GB=20
style=3D"mso-ansi-language: EN-GB">Alternatively, is it correct that all =
parts of=20
the work are considered as &lt;body&gt; =
indistinctly?<o:p></o:p></SPAN></P>
<P class=3DMsoNormal style=3D"MARGIN: 0cm 0cm 0pt"><SPAN lang=3DEN-GB=20
style=3D"mso-ansi-language: EN-GB"><o:p>&nbsp;</o:p></SPAN></P>
<P class=3DMsoNormal style=3D"MARGIN: 0cm 0cm 0pt"><SPAN lang=3DEN-GB=20
style=3D"mso-ansi-language: EN-GB">2. about automatic production of =
table of=20
contents of digital edition <o:p></o:p></SPAN></P>
<P class=3DMsoNormal style=3D"MARGIN: 0cm 0cm 0pt"><SPAN lang=3DEN-GB=20
style=3D"mso-ansi-language: EN-GB">Our software, that elaborate .xml =
files, is=20
able to produce automatically the table of contents by &lt;div&gt;, but =
the=20
titles that compose it are not taken by content model &lt;head&gt;, =
because they=20
could be different in the form and/or in the content. Moreover, we use a =
short=20
title, always led to &lt;div&gt;, that allows to contextualize the =
results of=20
research inside the text. <o:p></o:p></SPAN></P>
<P class=3DMsoNormal style=3D"MARGIN: 0cm 0cm 0pt"><SPAN lang=3DEN-GB=20
style=3D"mso-ansi-language: EN-GB">For these reasons I thought to add to =
the=20
&lt;head&gt;, that include the title present on the source, other two=20
&lt;head&gt;, that present a different type, in which are present the =
titles=20
added by the encoder for the elaboration of the text and not added to =
the=20
text.<o:p></o:p></SPAN></P>
<P class=3DMsoNormal style=3D"MARGIN: 0cm 0cm 0pt"><SPAN lang=3DEN-GB=20
style=3D"mso-ansi-language: EN-GB">For example,<o:p></o:p></SPAN></P>
<P class=3DMsoNormal style=3D"MARGIN: 0cm 0cm 0pt"><SPAN lang=3DEN-GB=20
style=3D"mso-ansi-language: EN-GB"><o:p>&nbsp;</o:p></SPAN></P>
<P class=3DMsoNormal style=3D"MARGIN: 0cm 0cm 0pt"><SPAN lang=3DEN-GB=20
style=3D"mso-ansi-language: EN-GB">source: "Caput I. Incertam esse artem =
istam=20
iudicio etiam principum illius.<o:p></o:p></SPAN></P>
<P class=3DMsoNormal style=3D"MARGIN: 0cm 0cm 0pt"><SPAN lang=3DEN-GB=20
style=3D"mso-ansi-language: EN-GB"><o:p>&nbsp;</o:p></SPAN></P>
<P class=3DMsoNormal style=3D"MARGIN: 0cm 0cm 0pt; TEXT-INDENT: =
35.4pt">Sed ne sola=20
auctoritate pugnemus, demonstrabimus toto<o:p></o:p></P>
<P class=3DMsoNormal style=3D"MARGIN: 0cm 0cm 0pt; TEXT-INDENT: =
35.4pt"><SPAN=20
lang=3DEN-GB style=3D"mso-ansi-language: EN-GB">hoc opere certis =
rationibus reiectam=20
iure a sanctis istam<o:p></o:p></SPAN></P>
<P class=3DMsoNormal style=3D"MARGIN: 0cm 0cm 0pt; TEXT-INDENT: =
35.4pt"><SPAN=20
lang=3DEN-GB=20
style=3D"mso-ansi-language: =
EN-GB">..................................................................=
......................."<o:p></o:p></SPAN></P>
<P class=3DMsoNormal style=3D"MARGIN: 0cm 0cm 0pt"><SPAN lang=3DEN-GB=20
style=3D"mso-ansi-language: EN-GB"><o:p>&nbsp;</o:p></SPAN></P>
<P class=3DMsoNormal style=3D"MARGIN: 0cm 0cm 0pt"><SPAN lang=3DEN-GB=20
style=3D"mso-ansi-language: EN-GB">marked text: <SPAN=20
style=3D"mso-tab-count: =
1">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=20
</SPAN>..........................................<o:p></o:p></SPAN></P>
<P class=3DMsoNormal style=3D"MARGIN: 0cm 0cm 0pt 35.4pt; TEXT-INDENT: =
35.4pt"><SPAN=20
lang=3DEN-GB style=3D"mso-ansi-language: EN-GB">&lt;div1 n=3D"1"=20
type=3D"chapter"&gt;<o:p></o:p></SPAN></P>
<P class=3DMsoNormal style=3D"MARGIN: 0cm 0cm 0pt 70.8pt; TEXT-INDENT: =
35.4pt"><SPAN=20
lang=3DEN-GB style=3D"mso-ansi-language: EN-GB">&lt;head&gt;Caput I. =
Incertam esse=20
artem istam iudicio etiam principum =
illius.&lt;/head&gt;<o:p></o:p></SPAN></P>
<P class=3DMsoNormal style=3D"MARGIN: 0cm 0cm 0pt 106.2pt"><SPAN =
lang=3DEN-GB=20
style=3D"mso-ansi-language: EN-GB">&lt;head =
type=3D"alternative"&gt;Caput I.=20
&lt;/head&gt;<o:p></o:p></SPAN></P>
<P class=3DMsoNormal style=3D"MARGIN: 0cm 0cm 0pt 70.8pt; TEXT-INDENT: =
35.4pt"><SPAN=20
lang=3DEN-GB style=3D"mso-ansi-language: EN-GB">&lt;head =
type=3D"short"&gt;Cap.=20
I&lt;/head&gt;<o:p></o:p></SPAN></P>
<P class=3DMsoNormal style=3D"MARGIN: 0cm 0cm 0pt 70.8pt; TEXT-INDENT: =
35.4pt"><SPAN=20
lang=3DEN-GB style=3D"mso-ansi-language: EN-GB">&lt;p&gt;</SPAN>Sed ne =
sola=20
auctoritate pugnemus, demonstrabimus toto<o:p></o:p></P>
<P class=3DMsoNormal style=3D"MARGIN: 0cm 0cm 0pt 70.8pt; TEXT-INDENT: =
35.4pt"><SPAN=20
lang=3DEN-GB style=3D"mso-ansi-language: EN-GB">hoc opere certis =
rationibus reiectam=20
iure a sanctis istam<o:p></o:p></SPAN></P>
<P class=3DMsoNormal style=3D"MARGIN: 0cm 0cm 0pt 70.8pt; TEXT-INDENT: =
35.4pt"><SPAN=20
lang=3DEN-GB=20
style=3D"mso-ansi-language: =
EN-GB">..................................................................=
.......................&lt;/p&gt;<o:p></o:p></SPAN></P>
<P class=3DMsoNormal style=3D"MARGIN: 0cm 0cm 0pt"><SPAN lang=3DEN-GB=20
style=3D"mso-ansi-language: EN-GB"><SPAN=20
style=3D"mso-tab-count: =
2">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbs=
p;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp=
;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=20
</SPAN>&lt;/div1&gt;<o:p></o:p></SPAN></P>
<P class=3DMsoNormal style=3D"MARGIN: 0cm 0cm 0pt"><SPAN lang=3DEN-GB=20
style=3D"mso-ansi-language: EN-GB"><SPAN=20
style=3D"mso-tab-count: =
2">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbs=
p;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp=
;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=20
</SPAN>...........................................<o:p></o:p></SPAN></P>
<P class=3DMsoNormal style=3D"MARGIN: 0cm 0cm 0pt"><SPAN lang=3DEN-GB=20
style=3D"mso-ansi-language: EN-GB">Is all this procedure correct or must =
the=20
&lt;head&gt; contain only the text present really in the=20
source?<o:p></o:p></SPAN></P>
<P class=3DMsoNormal style=3D"MARGIN: 0cm 0cm 0pt"><SPAN lang=3DEN-GB=20
style=3D"mso-ansi-language: EN-GB">In this last case, in TEI is it =
present a tag=20
able to meet this requirement or is it more correct introduce a new =
dedicated=20
tag?<o:p></o:p></SPAN></P>
<P class=3DMsoNormal style=3D"MARGIN: 0cm 0cm 0pt"><SPAN lang=3DEN-GB=20
style=3D"mso-ansi-language: EN-GB"><o:p>&nbsp;</o:p></SPAN></P>
<P class=3DMsoNormal style=3D"MARGIN: 0cm 0cm 0pt"><SPAN lang=3DEN-GB=20
style=3D"mso-ansi-language: EN-GB">3. about &lt;figure&gt;: is it =
correct to=20
reproduce inside &lt;p&gt; the text present in the image or is it =
necessary to=20
reproduce it inside &lt;text&gt;? If it is possible to use &lt;p&gt; to=20
distinguish image text from caption, is it correct to mark as next=20
way?<o:p></o:p></SPAN></P>
<P class=3DMsoNormal style=3D"MARGIN: 0cm 0cm 0pt"><SPAN lang=3DEN-GB=20
style=3D"mso-ansi-language: EN-GB"><o:p>&nbsp;</o:p></SPAN></P>
<P class=3DMsoNormal style=3D"MARGIN: 0cm 0cm 0pt"><SPAN lang=3DEN-GB=20
style=3D"mso-ansi-language: EN-GB">&lt;figure&gt;<o:p></o:p></SPAN></P>
<P class=3DMsoNormal style=3D"MARGIN: 0cm 0cm 0pt"><SPAN lang=3DEN-GB=20
style=3D"mso-ansi-language: EN-GB"><SPAN=20
style=3D"mso-tab-count: =
1">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</SPAN>&lt;head&=
gt;&lt;/head&gt;<o:p></o:p></SPAN></P>
<P class=3DMsoNormal style=3D"MARGIN: 0cm 0cm 0pt"><SPAN lang=3DEN-GB=20
style=3D"mso-ansi-language: EN-GB"><SPAN=20
style=3D"mso-tab-count: =
1">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</SPAN>&lt;p&gt;=
&lt;!--caption--&gt;&lt;/p&gt;<o:p></o:p></SPAN></P>
<P class=3DMsoNormal style=3D"MARGIN: 0cm 0cm 0pt"><SPAN lang=3DEN-GB=20
style=3D"mso-ansi-language: EN-GB"><SPAN=20
style=3D"mso-tab-count: =
1">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</SPAN>&lt;p&gt;=
&lt;seg=20
type=3D"imgText"&gt;&lt;!--text present in the=20
image--&gt;&lt;/seg&gt;&lt;/p&gt;<o:p></o:p></SPAN></P>
<P class=3DMsoNormal style=3D"MARGIN: 0cm 0cm 0pt"><SPAN lang=3DEN-GB=20
style=3D"mso-ansi-language: EN-GB">&lt;/figure&gt;</SPAN></P>
<P class=3DMsoNormal style=3D"MARGIN: 0cm 0cm 0pt"><SPAN lang=3DEN-GB=20
style=3D"mso-ansi-language: EN-GB"></SPAN>&nbsp;</P>
<P class=3DMsoNormal style=3D"MARGIN: 0cm 0cm 0pt"><SPAN lang=3DEN-GB=20
style=3D"mso-ansi-language: EN-GB">Thank you very much in =
advance.<BR>Daniele=20
Marotta<BR><BR>--=20
<BR>&nbsp;=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D<BR>&nbsp;&nb=
sp;Daniele=20
Marotta&nbsp;- Computer Research for Cultural Heritage=20
Centre<BR>&nbsp;---------------------------------------------------------=
---------<BR>&nbsp;=20
via della Faggiola, 19 - 56127 Pisa (Italy)<BR>&nbsp; Phone:&nbsp; +39 =
(0)50=20
509409<BR>&nbsp; e-mail: <A=20
href=3D"mailto:marotta@cribecu.sns.it">marotta@cribecu.sns.it</A>=20
</SPAN></P></DIV></BODY></HTML>

------=_NextPart_000_001C_01C4F7CB.FCEB3030--
=========================================================================
Date:         Tue, 11 Jan 2005 10:25:45 -0500
Reply-To:     thc4@COLUMBIA.EDU
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Terry Catapano <thc4@COLUMBIA.EDU>
Subject:      Re: [ANN] oXygen XML Editor 5.1 beta
In-Reply-To:  <41E0AF31.1060000@computing-services.oxford.ac.uk>
MIME-Version: 1.0
Content-Type: TEXT/PLAIN; charset=US-ASCII; format=flowed

I'd love to get the updated RelaxNG and W3C Schemas from Roma, but I can't
seem to get beyond the second screen ("Set your Parameters"). All "Submit
Query" does is refresh the screen. Am I missing something? Is there any
documentation on how to use Roma? Is it just broken?

Terry

On Sun, 9 Jan 2005, Sebastian Rahtz wrote:

> For oXygen, TEI P5 and Roma fans, I  have updated the schemas and
> stylesheets which Roma (http://www.tei-c.org/Roma/) uses
> so that Relax NG and W3C Schemas which are generated contain
> descriptions of all elements, attributes and
> attribute value lists, as schema annotations.  If you use the W3C Schema
> result with oXygen 1.5, it will show you
> the annotations when you put in new elements or attributes, or hover
> over elements. Maybe I'm just
> bemused by gadgets, but I reckon this is pretty cool, and an excellent
> feature of the editor....
>
> You won't get this feature with the TEI shipped with oXygen by default,
> but I hope the good folks at Synco RO Soft will ship the P5 schemas
> in future releases.
>
> --
> Sebastian Rahtz
> Information Manager, Oxford University Computing Services
> 13 Banbury Road, Oxford OX2 6NN. Phone +44 1865 283431
>
> OSS Watch: JISC Open Source Advisory Service
> http://www.oss-watch.ac.uk
>

Terry Catapano
Special Collections Analyst/Librarian
Columbia University Libraries Digital Program
212-854-9942
thc4@columbia.edu
=========================================================================
Date:         Tue, 11 Jan 2005 06:35:51 +0000
Reply-To:     Sebastian Rahtz <sebastian.rahtz@COMPUTING-SERVICES.OXFORD.AC.UK>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Sebastian Rahtz <sebastian.rahtz@COMPUTING-SERVICES.OXFORD.AC.UK>
Subject:      Re: [ANN] oXygen XML Editor 5.1 beta
Comments: To: thc4@COLUMBIA.EDU
In-Reply-To:  <200501111535.j0BFZll17807@listserv.brown.edu>
MIME-Version: 1.0
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit

Terry Catapano wrote:

>I'd love to get the updated RelaxNG and W3C Schemas from Roma, but I can't
>seem to get beyond the second screen ("Set your Parameters"). All "Submit
>Query" does is refresh the screen. Am I missing something? Is there any
>documentation on how to use Roma? Is it just broken?
>
>
>
select "Schema" from the row of boxes at the top.

no, its not broken, but it does need more documentation.....

--
Sebastian Rahtz
Information Manager, Oxford University Computing Services
13 Banbury Road, Oxford OX2 6NN. Phone +44 1865 283431

OSS Watch: JISC Open Source Advisory Service
http://www.oss-watch.ac.uk
=========================================================================
Date:         Tue, 11 Jan 2005 10:40:22 -0500
Reply-To:     Syd_Bauman@Brown.edu
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Syd Bauman <Syd_Bauman@BROWN.EDU>
Subject:      Re: About <front> - table of content - <figure>
In-Reply-To:  <001f01c4f7c3$9b317690$4bd5a8c0@MARCEL>
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit

> I should ask three questions:

Interesting questions all.


> I would note that I'm talking about texts regarded as unitary, that
> is, forming an organic whole, and not as composite.

I'm having a lot of trouble wrapping my mind around this. Maybe
(alright, likely) I come at reality from too much of an encoder's
perspective, but sometimes I think that if a work has separate
prefatory matter for divisions within, that *makes* it composite.
(Especially if you call them "books" :-)


> For example, if there is a work that presents one preface and two
> books each one has a dedication, is it correct to mark as in the
> next way?
>
> <TEI.2>
>   <teiHeader> <!-- ... --> </teiHeader>
>   <text>
>     <front>
>       <div1 n="1" type="preface"> <!-- ... --> </div1>
>     </front>
>     <body>
>       <div1 n="1" type="book">
>         <div2 n="1" type="dedication"> <!-- ... --> </div2>
>         <div2 n="2" type="chapter"> <!-- ... --> </div2>
>         <!-- ... -->
>       </div1>
>       <div1 n="2" type="book">
>         <div2 n="1" type="dedication"> <!-- ... --> </div2>
>         <div2 n="2" type="chapter"> <!-- ... --> </div2>
>         <!-- ... -->
>       </div1>
>     </body>
>   </text>
> </TEI.2>

I think the short answer is "yes", as long as you believe this
represents the document's structure for your purposes, this is a
correct encoding. You might want to consider making the n= value of
the first chapter "1", the second chapter "2", and so on.

However, I'd encourage you to consider the alternatives:

<TEI.2>
  <teiHeader> <!-- ... --> </teiHeader>
  <text>
    <front>
      <div1 n="1" type="preface"> <!-- ... --> </div1>
    </front>
    <group>
      <text n="1">
        <front>
          <div1 n="1" type="dedication"> <!-- ... --> </div1>
        </front>
        <body>
          <div1 n="1" type="chapter"> <!-- ... --> </div1>
          <div1 n="2" type="chapter"> <!-- ... --> </div1>
          <!-- ... -->
        </body>
      </text>
      <text n="2">
        <front>
          <div1 n="1" type="dedication"> <!-- ... --> </div1>
        </front>
        <body>
          <div1 n="1" type="chapter"> <!-- ... --> </div1>
          <div1 n="2" type="chapter"> <!-- ... --> </div1>
          <!-- ... -->
        </body>
      </text>
    </group>
  </text>
</TEI.2>

Or even using <teiCorpus.2>, which is applicable if each of the
"book"s has its own metadata.


> Alternatively, is it correct that all parts of the work are
> considered as <body> indistinctly?

I don't understand the structure you're asking about, here.


> 2. about automatic production of table of contents of digital
> edition ... the titles ... are not [the] content [of] <head>
> <div1 n="1" type="chapter">
>   <head>Caput I. Incertam esse artem istam iudicio etiam principum
>     illius.</head>
>   <head type="alternative">Caput I. </head>
>   <head type="short">Cap. I</head>
>   <!-- ... -->


> Is all this procedure correct or must the <head> contain only the
> text present really in the source?

The above encoding is acceptable -- TEI does not mandate that <head>
contain only text actually present in the original source. However,
for most scholarly uses of a text, it is important to be able to
differentiate what was in the source from what wasn't. So while you
may choose to set up house rules at your project that say "<head>
with type= of 'alternative' or 'short' did not appear in the source",
you should
a) be completely consistent about it, and
b) document this usage thoroughly in the <encodingDesc> in the
   <teiHeader>.

That said, I would probably lean towards other methods of
differentiating things that were in the source from things that were
not. Some possibilities:

* use n=. E.g.
  <div1 n="Cap. I" type="chapter">
    <head>Caput I. Incertam esse artem istam iudicio etiam principum
      illius.</head>
    <!-- ... -->
  </div1>
  Really nice system, has 2 disadvantages:
  - you can no longer use n= for sequential numbering; I don't think
    of this as much of a problem, as the one thing a computer can do
    *really* well is count;
  - you can not use any further encoding inside the value of n=, for
    example to indicate a foreign language or technical term. So
       <head>Predictions about <title><name>Harry Potter</name> and
         the Half-Blood Prince</title></head>
    could become
       n="HP6 predictions"
    but not
       n="<name>Harry Potter</name> 6 predictions"

* use <label>. E.g.
  <div1 n="1" type="chapter">
    <head>Caput I. Incertam esse artem istam iudicio etiam principum
      illius.</head>
    <label>Cap. I</label>
    <!-- ... -->
  </div1>
  Could work very well, but essentially requires that you not use
  <label> for anything else (or at least, be *very* careful about
  doing so), lest the two uses become confused.

* don't encode it. I.e., consider the "Cap. I" that is generated for
  a table of contents to be part of the processing, rather than part
  of the encoding. A style-sheet or other software would either need
  an algorithm for transforming generic <head> contents into
  shortened versions, or would need to perform a table look-up.

* encode it all, including the table of contents. E.g.
  <div type="TOC">
    <head>Table of Contents</head>
    <list>
      <item><rs>Cap I.</rs> <ptr target="B1CH01"/></item>
      <!-- ... -->
    </list>
  </div>
  <!-- ... -->
  <div1 n="1" type="chapter" id="B1CH01">
    <head>Caput I. Incertam esse artem istam iudicio etiam principum
      illius.</head>
    <!-- ... -->
  </div1>
  If the table of contents doesn't actually appear in the source, you
  should mention that the <div type="TOC"> is a modern editorial
  intervention in the <encodingDesc> of the <teiHeader>.


> 3. about <figure>: is it correct to reproduce inside <p> the text
> present in the image or is it necessary to reproduce it inside
> <text>?

No, it is not correct. Text that is *inside* the figure should be
inside <text><body><p>, cumbersome as that is. Thus your example
would be

              <figure>
                <head><!-- heading --></head>
                <p><!-- caption --></p>
                <text>
                  <body>
                    <p><!-- text present in the image --></p>
                  </body>
                </text>
              </figure>

Note that how <figure>s are handled in P5 is up for debate, and those
interested should make a point of contributing to the discussions on
the subject at
http://sourceforge.net/tracker/index.php?func=detail&aid=1020570&group_id=106328&atid=644065

Hope this helps.
=========================================================================
Date:         Tue, 11 Jan 2005 15:47:26 +0000
Reply-To:     Lou Burnard <lou.burnard@COMPUTING-SERVICES.OXFORD.AC.UK>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Lou Burnard <lou.burnard@COMPUTING-SERVICES.OXFORD.AC.UK>
Subject:      Re: [ANN] oXygen XML Editor 5.1 beta
Comments: To: thc4@COLUMBIA.EDU
In-Reply-To:  <200501111535.j0BFZll17807@listserv.brown.edu>
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii; format=flowed
Content-Transfer-Encoding: 7bit

This is one of those interface issues that catches everyone the first
time they use it, and then again six months later when they've forgotten
all about it.

You use the "Submit" button on the Parameterization screen *only* if you
want to change e.g. the interface language, or to load up a previously
saved specification.

If you want to go ahead and select modules or define new elements etc.,
just press the appropriate button on the menu at the top of the screen
(e.g. "Modules")

Lou


Terry Catapano wrote:

> I'd love to get the updated RelaxNG and W3C Schemas from Roma, but I can't
> seem to get beyond the second screen ("Set your Parameters"). All "Submit
> Query" does is refresh the screen. Am I missing something? Is there any
> documentation on how to use Roma? Is it just broken?
>
> Terry
>
> On Sun, 9 Jan 2005, Sebastian Rahtz wrote:
>
>
>>For oXygen, TEI P5 and Roma fans, I  have updated the schemas and
>>stylesheets which Roma (http://www.tei-c.org/Roma/) uses
>>so that Relax NG and W3C Schemas which are generated contain
>>descriptions of all elements, attributes and
>>attribute value lists, as schema annotations.  If you use the W3C Schema
>>result with oXygen 1.5, it will show you
>>the annotations when you put in new elements or attributes, or hover
>>over elements. Maybe I'm just
>>bemused by gadgets, but I reckon this is pretty cool, and an excellent
>>feature of the editor....
>>
>>You won't get this feature with the TEI shipped with oXygen by default,
>>but I hope the good folks at Synco RO Soft will ship the P5 schemas
>>in future releases.
>>
>>--
>>Sebastian Rahtz
>>Information Manager, Oxford University Computing Services
>>13 Banbury Road, Oxford OX2 6NN. Phone +44 1865 283431
>>
>>OSS Watch: JISC Open Source Advisory Service
>>http://www.oss-watch.ac.uk
>>
>
>
> Terry Catapano
> Special Collections Analyst/Librarian
> Columbia University Libraries Digital Program
> 212-854-9942
> thc4@columbia.edu
>
=========================================================================
Date:         Tue, 11 Jan 2005 10:49:27 -0500
Reply-To:     thc4@COLUMBIA.EDU
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Terry Catapano <thc4@COLUMBIA.EDU>
Subject:      Re: [ANN] oXygen XML Editor 5.1 beta
In-Reply-To:  <41E373C7.3020104@computing-services.oxford.ac.uk>
MIME-Version: 1.0
Content-Type: TEXT/PLAIN; charset=US-ASCII; format=flowed

Thanks, Sebastian. Follow the row of boxes...I get it now.

And I'm very much liking the result.

Terry



On Tue, 11 Jan
2005, Sebastian Rahtz wrote:

> Terry Catapano wrote:
>
>> I'd love to get the updated RelaxNG and W3C Schemas from Roma, but I can't
>> seem to get beyond the second screen ("Set your Parameters"). All "Submit
>> Query" does is refresh the screen. Am I missing something? Is there any
>> documentation on how to use Roma? Is it just broken?
>>
>>
> select "Schema" from the row of boxes at the top.
>
> no, its not broken, but it does need more documentation.....
>
> --
> Sebastian Rahtz      Information Manager, Oxford University Computing
> Services
> 13 Banbury Road, Oxford OX2 6NN. Phone +44 1865 283431
>
> OSS Watch: JISC Open Source Advisory Service
> http://www.oss-watch.ac.uk
>

Terry Catapano
Special Collections Analyst/Librarian
Columbia University Libraries Digital Program
212-854-9942
thc4@columbia.edu
=========================================================================
Date:         Tue, 11 Jan 2005 15:51:12 +0000
Reply-To:     Lou Burnard <lou.burnard@COMPUTING-SERVICES.OXFORD.AC.UK>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Lou Burnard <lou.burnard@COMPUTING-SERVICES.OXFORD.AC.UK>
Subject:      Re: [ANN] oXygen XML Editor 5.1 beta
Comments: To: Sebastian Rahtz <sebastian.rahtz@computing-services.oxford.ac.uk>
In-Reply-To:  <200501111537.j0BFbcl17949@listserv.brown.edu>
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii; format=flowed
Content-Transfer-Encoding: 7bit

p.s. http://www.tei-c.org/Talks/2004/Wuerzburg/roma-exercise.pdf walks
you through the process of using Roma and is mostly right.


Sebastian Rahtz wrote:

> Terry Catapano wrote:
>
>
>>I'd love to get the updated RelaxNG and W3C Schemas from Roma, but I can't
>>seem to get beyond the second screen ("Set your Parameters"). All "Submit
>>Query" does is refresh the screen. Am I missing something? Is there any
>>documentation on how to use Roma? Is it just broken?
>>
>>
>>
>
> select "Schema" from the row of boxes at the top.
>
> no, its not broken, but it does need more documentation.....
>
> --
> Sebastian Rahtz
> Information Manager, Oxford University Computing Services
> 13 Banbury Road, Oxford OX2 6NN. Phone +44 1865 283431
>
> OSS Watch: JISC Open Source Advisory Service
> http://www.oss-watch.ac.uk
>
=========================================================================
Date:         Tue, 11 Jan 2005 22:54:38 -0700
Reply-To:     daniel.odonnell@uleth.ca
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Daniel O'Donnell <daniel.odonnell@ULETH.CA>
Organization: Department of English, University of Lethbridge
Subject:      Remote local extensions
MIME-Version: 1.0
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit

I have a dumb question I'm sure I should know the answer to: is it
possible/how does one invoke extension files stored on a server rather
than a local computer? I'm talking here about the extending the dtd
section found in the first section of 29
<http://www.tei-c.org/P4X/MD.html> and in 3.2.4
<http://www.tei-c.org/P4X/ST.html#STBAUS>. All the examples use local
files.

I've tried

<!ENTITY % TEI.extensions.ent SYSTEM
'http://people.uleth.ca/~caedmon/xml/extensions/extensions.ent' >
<!ENTITY % TEI.extensions.dtd  SYSTEM
'http://people.uleth.ca/~caedmon/xml/extensions/extensions.dtd'>

but emacs gags.

Am I missing something? This is proper syntax, isn't it? I've tried a
couple of different locations and keep getting an external entity not found.
-dan
--
Daniel Paul O'Donnell, PhD
Associate Professor of English
University of Lethbridge
Lethbridge AB T1K 3M4
Tel. (403) 329-2377
Fax. (403) 382-7191
E-mail <daniel.odonnell@uleth.ca>
Home Page <http://people.uleth.ca/~daniel.odonnell/>
The Digital Medievalist Project: <http://www.digitalmedievalist.org/>
=========================================================================
Date:         Wed, 12 Jan 2005 01:26:42 -0500
Reply-To:     Syd_Bauman@Brown.edu
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Syd Bauman <Syd_Bauman@BROWN.EDU>
Subject:      Re: Remote local extensions
In-Reply-To:  <41E4BB9E.60603@uleth.ca>
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit

> I have a dumb question I'm sure I should know the answer to: is
> it possible/how does one invoke extension files stored on a
> server rather than a local computer?

Not a dumb question at all, for the results of testing will likely
be quite mysterious.


> I've tried
>  <!ENTITY % TEI.extensions.ent SYSTEM
>  'http://people.uleth.ca/~caedmon/xml/extensions/extensions.ent' >
>  <!ENTITY % TEI.extensions.dtd  SYSTEM
>  'http://people.uleth.ca/~caedmon/xml/extensions/extensions.dtd'>
> but emacs gags.

This is indeed the proper syntax. This correctly assocates the entity
'TEI.extensions.dtd' with the system resource
'http://people.uleth.ca/~caedmon/xml/extensions/extensions.dtd'. The
problem is that the system you're using (Emacs/psgml I'm going to
bet) doesn't know how to resolve an http: system resource. In fact,
many systems don't know how to resolve anything but local file paths.
I know sgmls cannot, I am pretty sure nsgmls cannot, I don't even
think onsgmls can; however I do think xmllint can, although I'm not
sure.
=========================================================================
Date:         Wed, 12 Jan 2005 09:46:58 +0000
Reply-To:     Sebastian Rahtz <sebastian.rahtz@COMPUTING-SERVICES.OXFORD.AC.UK>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Sebastian Rahtz <sebastian.rahtz@COMPUTING-SERVICES.OXFORD.AC.UK>
Subject:      Re: Remote local extensions
Comments: To: daniel.odonnell@uleth.ca
In-Reply-To:  <200501120554.j0C5sXl14497@listserv.brown.edu>
MIME-Version: 1.0
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit

Daniel O'Donnell wrote:

><!ENTITY % TEI.extensions.ent SYSTEM
>'http://people.uleth.ca/~caedmon/xml/extensions/extensions.ent' >
><!ENTITY % TEI.extensions.dtd  SYSTEM
>'http://people.uleth.ca/~caedmon/xml/extensions/extensions.dtd'>
>
>but emacs gags.
>
>
>
That's a problem with emacs, in that it does not follow URLs properly.
Your syntax is fine, your tool is broken.

Sebastian
=========================================================================
Date:         Wed, 12 Jan 2005 09:53:37 +0000
Reply-To:     Sebastian Rahtz <sebastian.rahtz@COMPUTING-SERVICES.OXFORD.AC.UK>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Sebastian Rahtz <sebastian.rahtz@COMPUTING-SERVICES.OXFORD.AC.UK>
Subject:      Re: Remote local extensions
Comments: To: Syd_Bauman@BROWN.EDU
In-Reply-To:  <200501120626.j0C6Qkl16630@listserv.brown.edu>
MIME-Version: 1.0
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit

Syd Bauman wrote:

> The
>problem is that the system you're using (Emacs/psgml I'm going to
>bet) doesn't know how to resolve an http: system resource. In fact,
>many systems don't know how to resolve anything but local file paths.
>I know sgmls cannot, I am pretty sure nsgmls cannot, I don't even
>think onsgmls can; however I do think xmllint can, although I'm not
>sure
>
>
onsgmls, xmllint, rxp, jing, etc all follow URLs as expected
unless my brain has turned to putty.

all the Java-based editors should do the right thing

Sebastian
=========================================================================
Date:         Wed, 12 Jan 2005 11:34:47 +0100
Reply-To:     Roberto Rosselli Del Turco <rosselli@LING.UNIPI.IT>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Roberto Rosselli Del Turco <rosselli@LING.UNIPI.IT>
Subject:      Re: Remote local extensions
Comments: To: Sebastian Rahtz <sebastian.rahtz@COMPUTING-SERVICES.OXFORD.AC.UK>
In-Reply-To:  <41E4F212.9010704@computing-services.oxford.ac.uk>
Content-Type: text/plain
Mime-Version: 1.0
Content-Transfer-Encoding: 7bit

Il giorno mer, 12-01-2005 alle 09:46 +0000, Sebastian Rahtz ha scritto:
> Daniel O'Donnell wrote:
>
> ><!ENTITY % TEI.extensions.ent SYSTEM
> >'http://people.uleth.ca/~caedmon/xml/extensions/extensions.ent' >
> ><!ENTITY % TEI.extensions.dtd  SYSTEM
> >'http://people.uleth.ca/~caedmon/xml/extensions/extensions.dtd'>
> >
> >but emacs gags.
> >
> >
> >
> That's a problem with emacs, in that it does not follow URLs properly.
> Your syntax is fine, your tool is broken.

Is that a problem with psgml, or is it definitely emacs at fault?
Speaking of which, how about including some other free XML editors in
TEI Knoppix? (Which I'm playing with right now, looks nice)

Ciao

--

Roberto Rosselli Del Turco      roberto.rossellidelturco at unito.it
Dipartimento di Scienze         rosselli at ling.unipi.it
del Linguaggio                  Then spoke the thunder  DA
Universita' di Torino           Datta: what have we given?  (TSE)

  Hige sceal the heardra,     heorte the cenre,
  mod sceal the mare,       the ure maegen litlath.  (Maldon 312-3)
=========================================================================
Date:         Wed, 12 Jan 2005 10:50:08 +0000
Reply-To:     Sebastian Rahtz <sebastian.rahtz@COMPUTING-SERVICES.OXFORD.AC.UK>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Sebastian Rahtz <sebastian.rahtz@COMPUTING-SERVICES.OXFORD.AC.UK>
Subject:      Re: Remote local extensions
Comments: To: Roberto Rosselli Del Turco <rosselli@ling.unipi.it>
In-Reply-To:  <1105526087.7120.42.camel@loki.grendelsmere>
MIME-Version: 1.0
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit

Roberto Rosselli Del Turco wrote:

>Is that a problem with psgml, or is it definitely emacs at fault?
>
>
I am not sure whether Emacs _could_ do it, but psgml-in-emacs certainly
does not

>Speaking of which, how about including some other free XML editors in
>TEI Knoppix? (Which I'm playing with right now, looks nice)
>
>
show me a good open source XML editor and I will include it. Preferably one
already available as a Debian package, but not essential. Preferably one
which
understands Relax NG and/or W3C Schema.

sebastian
=========================================================================
Date:         Wed, 12 Jan 2005 10:50:52 -0000
Reply-To:     Michael Beddow <mbteil-2@mbeddow.net>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Michael Beddow <mbteil-2@MBEDDOW.NET>
Subject:      Re: Remote local extensions
MIME-Version: 1.0
Content-Type: text/plain; charset="iso-8859-1"
Content-Transfer-Encoding: 7bit

Daniel O'Donnell wrote:

>  is it
> possible/how does one invoke extension files stored on a server rather
> than a local computer?

This is not only possible, providing the editor app behaves itself, as Syd
and Sebastian have confirmed, but extremely useful.

People work on the Anglo-Norman Dictionary and its associated text corpus at
five separate locations, but all access the same core DTD files (from the
Oxford TEI mirror) and the same local extension files (from the project's
own document management server). That way there are no versioning problems
either with the core files or the extensions. We do this at the moment using
epcEdit with no difficulties. It also works fine with Serna, which is where
we may well move for P5-based editing if (a) Serna gets a bit more stable
and (b) epcEdit decides to stay DTD-only.

There are just a few gotchas with this approach, which I'll flag up in case
anyone else encounters them and is puzzled by why things apparently don't
work. The symptom is that you have the correct syntax for specifying your
resource locations, as in Daniel's example, and are using a progam that
supports the fetching of http resources, but you nevertheless aren't getting
the access to remote resources you expect.

1. Most campuses, and some ISP's, operate Web proxies/caches and enforce
their use. If the proxies are "transparent" (i.e. they capture users'
attempts to open connections on port 80 and redirect them via the proxy)
then this isn't a problem -- provided the cache isn't misconfigured (of
which more in 3 below). When an editor (or the catalog resolver that
services it) requests access to a remote resource via http it will be
satisfied as though the user had a direct connection.

2. But if the proxy isn't transparent in the above sense, but either uses
the "autoconfigure" feature of browsers to pick up instructions to send http
connection requests via a port other than 80, or requires proxy settings to
be entered manually,  then apps other than browsers may have trouble accessi
ng resources via http. Under Linux and similar, setting the HTTP_PROXY
environment variable to the full url of the cache should do the trick, since
all well-behaved apps that require Web access should honour this setting. I
don't know if there is a similar trick under Windows, and I try pretty hard
not to find such things out. My solution here was to ask the campus computer
centres involved to open up direct Internet access on port 80 to project
workstations. Since these workstations require a tunnel through the local
firewalls for the document management system to work anyay and so already
needed special entries in the border router tables, these requests were
readily granted.

3. There are fairly well-defined rules about what objects should be cached
and for how long by http proxies. But some ISPs' caches, and all too many
campus ones, have been wilfully misconfigured to flout these rules in the
misguided pursuit of bandwidth saving. Where this has happened, a "stale"
copy of the last version retrieved may remain in the local cache and be
repeatedly retrieved by editing/parsing software on local systems, even when
the original has changed.  Browsers are pretty smart about allowing users to
force cache flushes in such circumstances, but generally speaking the entity
resolvers called by editing and parsing software aren't cache-aware. If
undetected, this stale-copy retention can cause head-banging failures of the
central resource model: e.g. the extension files on the project server have
been modified, but users at one site aren't getting to see the changes.
Rather than arguing with cache administrators on this one, I have provided
users at the affected locations with a desktop icon that runs a simple
script to pull a fresh copy of the DTD files into the cache, from which
epcEdit can then retrieve them. Fortunately there are no project members at
one particular campus I know of whose caches have been misconfigured to
ignore all refresh requests of any kind except those from certain support
staff workstations...

Michael Beddow
=========================================================================
Date:         Wed, 12 Jan 2005 13:16:49 +0100
Reply-To:     Daniele Marotta <marotta@CRIBECU.SNS.IT>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Daniele Marotta <marotta@CRIBECU.SNS.IT>
Subject:      Re: About <front> - table of content - <figure>
MIME-Version: 1.0
Content-Type: text/plain; charset="iso-8859-1"
Content-Transfer-Encoding: 7bit

> Hope this helps.

Thank you very much.

> > I would note that I'm talking about texts regarded as unitary, that
> > is, forming an organic whole, and not as composite.
>
> I'm having a lot of trouble wrapping my mind around this. Maybe
> (alright, likely) I come at reality from too much of an encoder's
> perspective, but sometimes I think that if a work has separate
> prefatory matter for divisions within, that *makes* it composite.
> (Especially if you call them "books" :-)

<quote>
<group> contains the body of a composite text, grouping together a sequence
of
distinct texts (or groups of such texts) which are regarded as a unit for
some purpose, for example the collected works of an author, a sequence
of prose essays, etc.
<quote>

We work on 15th-17th century texts and they aren't a collection
of independent texts, but they are works conceived by the author as unity.
"Book"
is one way (common to the age) of calling a division that today
we usually call "part" or "section". The same prefatory matter of a single
division
is above all (most of time) a rhetorical expedient. For this reason, I have
not used
<group>.


> > <TEI.2>
> >   <teiHeader> <!-- ... --> </teiHeader>
> >   <text>
> >     <front>
> >       <div1 n="1" type="preface"> <!-- ... --> </div1>
> >     </front>
> >     <body>
> >       <div1 n="1" type="book">
> >         <div2 n="1" type="dedication"> <!-- ... --> </div2>
> >         <div2 n="2" type="chapter"> <!-- ... --> </div2>
> >         <!-- ... -->
> >       </div1>
> >       <div1 n="2" type="book">
> >         <div2 n="1" type="dedication"> <!-- ... --> </div2>
> >         <div2 n="2" type="chapter"> <!-- ... --> </div2>
> >         <!-- ... -->
> >       </div1>
> >     </body>
> >   </text>
> > </TEI.2>
>
> > Alternatively, is it correct that all parts of the work are
> > considered as <body> indistinctly?
>
> I don't understand the structure you're asking about, here.

The above-mentioned example results (I apologize for not
reporting it in the foregoing email)
 <TEI.2>
   <teiHeader> <!-- ... --> </teiHeader>
   <text>
     <body>
       <div1 n="1" type="preface"> <!-- ... --> </div1>
       <div1 n="1" type="book">
         <div2 n="1" type="dedication"> <!-- ... --> </div2>
         <div2 n="2" type="chapter"> <!-- ... --> </div2>
         <!-- ... -->
       </div1>
       <div1 n="2" type="book">
         <div2 n="1" type="dedication"> <!-- ... --> </div2>
         <div2 n="2" type="chapter"> <!-- ... --> </div2>
         <!-- ... -->
       </div1>
     </body>
   </text>
 </TEI.2>


Daniele Marotta

--
 ==================================================================
  Daniele Marotta - Computer Research for Cultural Heritage Centre
 ------------------------------------------------------------------
  via della Faggiola, 19 - 56127 Pisa (Italy)
  Phone:  +39 (0)50 509409
  e-mail: marotta@cribecu.sns.it
=========================================================================
Date:         Wed, 12 Jan 2005 13:48:45 +0100
Reply-To:     Roberto Rosselli Del Turco <rosselli@LING.UNIPI.IT>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Roberto Rosselli Del Turco <rosselli@LING.UNIPI.IT>
Subject:      Re: Remote local extensions
Comments: To: Sebastian Rahtz <sebastian.rahtz@COMPUTING-SERVICES.OXFORD.AC.UK>
In-Reply-To:  <41E500E0.50900@computing-services.oxford.ac.uk>
Content-Type: text/plain
Mime-Version: 1.0
Content-Transfer-Encoding: 7bit

Il giorno mer, 12-01-2005 alle 10:50 +0000, Sebastian Rahtz ha scritto:
> Roberto Rosselli Del Turco wrote:
>
> >Speaking of which, how about including some other free XML editors in
> >TEI Knoppix? (Which I'm playing with right now, looks nice)
> >
> >
> show me a good open source XML editor and I will include it. Preferably one
> already available as a Debian package, but not essential. Preferably one
> which
> understands Relax NG and/or W3C Schema.

We should agree on the notion of "good [open source XML editor]" first,
but actually I'd like to put some stress on the "editor" part: at the
moment the user can choose one of three editors, emacs[1], (g)vim and
xedit. They are quite different but have one common feature: they're
very hard to use for the beginner/intermediate user. Since Knoppix runs
a KDE desktop environment, you could easily add:

1. a programmer's text editor: Kate (syntax highlighting, folding, word
wrap, etc.);

2. a more advanced HTML editor: Quanta Plus (all of the above and tag
hinting, autocompletion, don't know if it validates documents as well).

These aren't perfect solutions, of course, but would help in simple XML
editing tasks, until other, more advanced solutions pop up.

If a JRE were available, you could also offer Eclipse (+ XMLBuddy?)
and/or specific XML editors (jedit?).

Seeing that TEI Knoppix still includes lots of Linux stuff, part of
which could be axed at once (Games, Toys), I assume there would be
sufficient space to add these programs.

Ciao

[1] BTW you have three entries for emacs, but I can't spot the
difference between 1. Emacs 21 (X11) (Emacs) and 2. Emacs 21 (X11)
(Emacs 21 (X11)). I'd shorten the list to 1. Emacs 21 (X11) and 2. Emacs
21 (text).

--

Roberto Rosselli Del Turco      roberto.rossellidelturco at unito.it
Dipartimento di Scienze         rosselli at ling.unipi.it
del Linguaggio                  Then spoke the thunder  DA
Universita' di Torino           Datta: what have we given?  (TSE)

  Hige sceal the heardra,     heorte the cenre,
  mod sceal the mare,       the ure maegen litlath.  (Maldon 312-3)
=========================================================================
Date:         Wed, 12 Jan 2005 13:45:44 +0000
Reply-To:     Sebastian Rahtz <sebastian.rahtz@COMPUTING-SERVICES.OXFORD.AC.UK>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Sebastian Rahtz <sebastian.rahtz@COMPUTING-SERVICES.OXFORD.AC.UK>
Subject:      Re: Remote local extensions
Comments: To: Roberto Rosselli Del Turco <rosselli@LING.UNIPI.IT>
In-Reply-To:  <200501121257.j0CCvsl14126@listserv.brown.edu>
MIME-Version: 1.0
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit

Roberto Rosselli Del Turco wrote:

>We should agree on the notion of "good [open source XML editor]" first,
>
>
thats the trick question :-}

>very hard to use for the beginner/intermediate user. Since Knoppix runs
>a KDE desktop environment, you could easily add:
>
>1. a programmer's text editor: Kate (syntax highlighting, folding, word
>wrap, etc.);
>
>
thats easy enough, but it gives you no XML-specific or TEI-specific help,
so why not use Emacs?

>2. a more advanced HTML editor: Quanta Plus (all of the above and tag
>hinting, autocompletion, don't know if it validates documents as well).
>
>
>
but we are not making HTML....

>If a JRE were available, you could also offer Eclipse (+ XMLBuddy?)
>and/or specific XML editors (jedit?).
>
>
>
I have a JRE on there, but do you seriously suggest Eclipse is for
beginning and/or casual users?

If there was an XML editor of the style of XMetal, XMLMind, Serna etc,
which offered rendered views, I'd jump at it. But going between Emacs,
vi, jedit etc
still doesnt take you beyond the world of programmers (who can learn
anything)

>Seeing that TEI Knoppix still includes lots of Linux stuff, part of
>which could be axed at once (Games, Toys), I assume there would be
>sufficient space to add these programs.
>
>
sure, the version on my machine has lost all these and has got
OpenOffice back.

>[1] BTW you have three entries for emacs, but I can't spot the
>difference between 1. Emacs 21 (X11) (Emacs) and 2. Emacs 21 (X11)
>(Emacs 21 (X11)). I'd shorten the list to 1. Emacs 21 (X11) and 2. Emacs
>21 (text).
>
>
I have to yet to understand why this happens...

sebastian
=========================================================================
Date:         Wed, 12 Jan 2005 07:40:37 -0700
Reply-To:     daniel.odonnell@uleth.ca
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Daniel O'Donnell <daniel.odonnell@ULETH.CA>
Organization: Department of English, University of Lethbridge
Subject:      Serna and stable beginning editors
MIME-Version: 1.0
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit

The discussion of better editors brings me back to Serna. I was really
impressed at first but then started having it crash all the time on me
for something to do with the stylesheet library. I went back to emacs.

Is this something others have experienced?
-dan
--
Daniel Paul O'Donnell, PhD
Associate Professor of English
University of Lethbridge
Lethbridge AB T1K 3M4
Tel. (403) 329-2377
Fax. (403) 382-7191
E-mail <daniel.odonnell@uleth.ca>
Home Page <http://people.uleth.ca/~daniel.odonnell/>
The Digital Medievalist Project: <http://www.digitalmedievalist.org/>
=========================================================================
Date:         Wed, 12 Jan 2005 14:56:04 +0000
Reply-To:     Sebastian Rahtz <sebastian.rahtz@COMPUTING-SERVICES.OXFORD.AC.UK>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Sebastian Rahtz <sebastian.rahtz@COMPUTING-SERVICES.OXFORD.AC.UK>
Subject:      Re: Serna and stable beginning editors
Comments: To: daniel.odonnell@uleth.ca
In-Reply-To:  <200501121440.j0CEeWl27913@listserv.brown.edu>
MIME-Version: 1.0
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit

Daniel O'Donnell wrote:

>The discussion of better editors brings me back to Serna. I was really
>impressed at first but then started having it crash all the time on me
>for something to do with the stylesheet library.
>

if this was Serna's delivery of my XSLT, please don't blame Serna
or their editor! those FO stylesheets remain flaky - next on my list
to work on

Sebastian
=========================================================================
Date:         Wed, 12 Jan 2005 15:59:38 +0100
Reply-To:     Katrien Depuydt <depuydt@INL.NL>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Katrien Depuydt <depuydt@INL.NL>
Subject:      rendition / suppied within w-tag
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii; format=flowed
Content-Transfer-Encoding: 7bit

Hi,
We are annotating every wordt in our text corpus with PoS and lemma. We
are using the <w>-tag (attributes: type= for PoS and lemma= for lemma).
Two 'problems':
1. typographical encoding of part of a word form, f.i. "me<hi
rend="italic">n</hi>sen is not allowed within <w>
2. in our texts, words and parts of words supplied by the editor of a
text are encoded by means of the <supplied>-tag, f.i.
<supplied>appel</supplied>flap
<supplied> is not allowed within <w>.

I know I could use <seg>, which would result in an encoding of:
<w type="noun" lemma="mens">me<seg rend="italic">n</seg>sen</w>
<w type="noun"
lemma="appelflap"><seg><supplied>appel</supplied></supplied>flap</w>
However this solution seems rather illogical to us.
Is there a special reason for not allowing supplied or hi within w or is
it an omission?


Sincerely,
Katrien Depuydt

Institute for Dutch Lexicology
Editor Dutch Language Database

P.O. Box 9515
NL-2300 RA Leiden
=========================================================================
Date:         Wed, 12 Jan 2005 15:04:11 +0000
Reply-To:     Lou Burnard <lou.burnard@COMPUTING-SERVICES.OXFORD.AC.UK>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Lou Burnard <lou.burnard@COMPUTING-SERVICES.OXFORD.AC.UK>
Subject:      Re: Serna and stable beginning editors
Comments: To: Sebastian Rahtz <sebastian.rahtz@computing-services.oxford.ac.uk>
In-Reply-To:  <200501121456.j0CEuVl29676@listserv.brown.edu>
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii; format=flowed
Content-Transfer-Encoding: 7bit

Isn't it time that someone in this discussion said "forget about Serna
-- OxyGen is way cooler?"

There, I've said it for them.

L

Sebastian Rahtz wrote:

> Daniel O'Donnell wrote:
>
>
>>The discussion of better editors brings me back to Serna. I was really
>>impressed at first but then started having it crash all the time on me
>>for something to do with the stylesheet library.
>>
>
>
> if this was Serna's delivery of my XSLT, please don't blame Serna
> or their editor! those FO stylesheets remain flaky - next on my list
> to work on
>
> Sebastian
>
=========================================================================
Date:         Wed, 12 Jan 2005 10:41:15 -0500
Reply-To:     Syd_Bauman@brown.edu
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Syd Bauman <Syd_Bauman@BROWN.EDU>
Subject:      Re: Remote local extensions
Comments: cc: psgml-devel@lists.sourceforge.net
In-Reply-To:  <41E500E0.50900@computing-services.oxford.ac.uk>
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit

> That's a problem with emacs, in that it does not follow URLs
> properly. Your syntax is fine, your tool is broken.

I think that's a bit harsh. Following URLs is a (desirable) feature
that Emacs/psgml does not (currently) provide, but it isn't "broken".


> onsgmls, xmllint, rxp, jing, etc all follow URLs as expected
> unless my brain has turned to putty.

I think you're right, onsgmls, xmllint, and rxp will follow a URL.
jing will, too, but I don't think it will perform DTD validation. (On
the other hand, jing has surprised me before with its support of NRL
and Schematron.


> I am not sure whether Emacs _could_ do it, but psgml-in-emacs
> certainly does not

Most certainly Emacs could -- it is possible to resolve a URL in
Emacs (try w3 sometime :-), but someone would have to teach psgml
mode to parse the SYSTEM identifier and call URL resolution code and
deal with errors, etc.

I don't know if there are any plans afoot to do this in psgml, but
I've sent this to the development list, too to find out.
=========================================================================
Date:         Wed, 12 Jan 2005 15:44:50 +0000
Reply-To:     Sebastian Rahtz <sebastian.rahtz@COMPUTING-SERVICES.OXFORD.AC.UK>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Sebastian Rahtz <sebastian.rahtz@COMPUTING-SERVICES.OXFORD.AC.UK>
Subject:      Re: Serna and stable beginning editors
Comments: To: Lou Burnard <lou.burnard@computing-services.oxford.ac.uk>
In-Reply-To:  <41E53C6B.7040701@computing-services.oxford.ac.uk>
MIME-Version: 1.0
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit

Lou Burnard wrote:

> Isn't it time that someone in this discussion said "forget about Serna
> -- OxyGen is way cooler?"
>
> There, I've said it for them.
>
No. It's fish and fowl.

oXygen is a programmers' editor, which shows you raw <>.
Serna renders the XML dynamically using FO stylesheets, and you
edit in the rendered view.


--
Sebastian Rahtz
Information Manager, Oxford University Computing Services
13 Banbury Road, Oxford OX2 6NN. Phone +44 1865 283431

OSS Watch: JISC Open Source Advisory Service
http://www.oss-watch.ac.uk
=========================================================================
Date:         Wed, 12 Jan 2005 15:50:00 +0000
Reply-To:     Sebastian Rahtz <sebastian.rahtz@COMPUTING-SERVICES.OXFORD.AC.UK>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Sebastian Rahtz <sebastian.rahtz@COMPUTING-SERVICES.OXFORD.AC.UK>
Subject:      Re: Remote local extensions
Comments: To: Syd_Bauman@BROWN.EDU
In-Reply-To:  <200501121541.j0CFfil06608@listserv.brown.edu>
MIME-Version: 1.0
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit

Syd Bauman wrote:

>>That's a problem with emacs, in that it does not follow URLs
>>properly. Your syntax is fine, your tool is broken.
>>
>>
>
>I think that's a bit harsh. Following URLs is a (desirable) feature
>that Emacs/psgml does not (currently) provide, but it isn't "broken".
>
>
I don't think its a "desirable" feature, exactly. the system identifier
is a URL, surely? if you can't implement http, you cant really be said
to implement
URLs, I'd say.

>I think you're right, onsgmls, xmllint, and rxp will follow a URL.
>jing will, too, but I don't think it will perform DTD validation. (
>
nothing would surprise me about Jing.....

>Most certainly Emacs could -- it is possible to resolve a URL in
>Emacs (try w3 sometime :-), but someone would have to teach psgml
>mode to parse the SYSTEM identifier and call URL resolution code and
>deal with errors, etc.
>
>
true. I had forgotten w3, so emacs does have the goods. does nxml-mode
use it?

>I don't know if there are any plans afoot to do this in psgml, but
>I've sent this to the development list, too to find out.
>
>
does anyone work on psgml these days? I kind of assumed it
had been dead for years now. Last time I looked, it didn't
even read the encoding declaration in XML files....

--
Sebastian Rahtz
Information Manager, Oxford University Computing Services
13 Banbury Road, Oxford OX2 6NN. Phone +44 1865 283431

OSS Watch: JISC Open Source Advisory Service
http://www.oss-watch.ac.uk
=========================================================================
Date:         Wed, 12 Jan 2005 15:57:19 +0000
Reply-To:     Gabriel BODARD <gabriel.bodard@KCL.AC.UK>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Gabriel BODARD <gabriel.bodard@KCL.AC.UK>
Subject:      Re: rendition / suppied within w-tag
Comments: To: Katrien Depuydt <depuydt@INL.NL>
In-Reply-To:  <41E53B5A.3040303@inl.nl>
MIME-Version: 1.0
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 8bit

The answer is to customise your DTD to allow these elements within <w>. In our
TEI DTD both <hi> and <supplied> (and many other things) are valid within <w>.

All best,

Gabriel.

Quoting Katrien Depuydt <depuydt@INL.NL>:

> Hi,
> We are annotating every wordt in our text corpus with PoS and lemma. We
> are using the <w>-tag (attributes: type= for PoS and lemma= for lemma).
> Two 'problems':
> 1. typographical encoding of part of a word form, f.i. "me<hi
> rend="italic">n</hi>sen is not allowed within <w>
> 2. in our texts, words and parts of words supplied by the editor of a
> text are encoded by means of the <supplied>-tag, f.i.
> <supplied>appel</supplied>flap
> <supplied> is not allowed within <w>.
>
> I know I could use <seg>, which would result in an encoding of:
> <w type="noun" lemma="mens">me<seg rend="italic">n</seg>sen</w>
> <w type="noun"
> lemma="appelflap"><seg><supplied>appel</supplied></supplied>flap</w>
> However this solution seems rather illogical to us.
> Is there a special reason for not allowing supplied or hi within w or is
> it an omission?


--
=======================================
Gabriel BODARD
Inscriptions of Aphrodisias
Institute of Classical Studies Library
Senate House
Malet Street
London WC1E 7HU

Email: gabriel.bodard@kcl.ac.uk
Tel: +44 (0)20 78 62 87 26
Fax: +44 (0)20 78 62 87 22
=======================================
=========================================================================
Date:         Wed, 12 Jan 2005 17:01:10 +0100
Reply-To:     Roberto Rosselli Del Turco <rosselli@LING.UNIPI.IT>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Roberto Rosselli Del Turco <rosselli@LING.UNIPI.IT>
Subject:      Re: Remote local extensions
Comments: To: Sebastian Rahtz <sebastian.rahtz@COMPUTING-SERVICES.OXFORD.AC.UK>
In-Reply-To:  <41E52A08.5060406@computing-services.oxford.ac.uk>
Content-Type: text/plain
Mime-Version: 1.0
Content-Transfer-Encoding: 7bit

Il giorno mer, 12-01-2005 alle 13:45 +0000, Sebastian Rahtz ha scritto:
> Roberto Rosselli Del Turco wrote:
>
> >We should agree on the notion of "good [open source XML editor]" first,
> >
> >
> thats the trick question :-}

Of course :) I believe everyone has his list of "indispensable"
features.

> >very hard to use for the beginner/intermediate user. Since Knoppix runs
> >a KDE desktop environment, you could easily add:
> >
> >1. a programmer's text editor: Kate (syntax highlighting, folding, word
> >wrap, etc.);
> >
> >
> thats easy enough, but it gives you no XML-specific or TEI-specific help,
> so why not use Emacs?

I'm surprised you ask :) Short answer: because Kate is much easier to
use.

Long answer: Emacs is a programmer's editor written for fellow
programmers, powerful and all, but sure isn't a miracle of
user-friendliness. I noticed that proposing a simple editor to my
students they grasp the concept of text mark-up and start experimenting
autonomously very quickly. Now, do you think I could do that with emacs?
Features that help beginnners a lot:

- syntax highlighting
- error highlighting
- valid element/attribute hinting
- document validation

> >2. a more advanced HTML editor: Quanta Plus (all of the above and tag
> >hinting, autocompletion, don't know if it validates documents as well).
> >
> >
> >
> but we are not making HTML....

I agree, but auto-completion/-tag closing look like nice features for
XML editing to me. That said, I don't know KDE applications very well,
so please take a look for yourself.

> >If a JRE were available, you could also offer Eclipse (+ XMLBuddy?)
> >and/or specific XML editors (jedit?).
> >
> >
> >
> I have a JRE on there, but do you seriously suggest Eclipse is for
> beginning and/or casual users?

No, but surely intermediate/advanced users can learn it quickly (Eclipse
+Oxygen looks very nice, BTW).

> If there was an XML editor of the style of XMetal, XMLMind, Serna etc,
> which offered rendered views, I'd jump at it. But going between Emacs,
> vi, jedit etc
> still doesnt take you beyond the world of programmers (who can learn
> anything)

Now we're at the heart of the matter: it's true that at the moment TEI
Knoppix is useful to very expert people like you and all the other TEI
gurus, but think about the potential, it could be a complete environment
for TEI encoding/teaching/learning. This is why it should offer

1. simple text editors like Kate: useful for beginners (or non-TEI
related tasks, I'd hate having to use emacs for editing a system file or
something like that);

2. more powerful editors like jedit and/or Eclipse (+
XMLBuddy/Vex/whatever): for intermediate to advanced users;

3. emacs for "real encoders" :)

Since you already have 3., and could include 1. easily, the real problem
lies with 2., i.e. powerful but easy to use editors. We're back to the
"good open source XML editor" question, not an easy one at the moment, I
admit. I'll also confess that a "free as in beer" solution, i.e. XXE
Standard or XML Buddy, looks acceptable to me.

> >Seeing that TEI Knoppix still includes lots of Linux stuff, part of
> >which could be axed at once (Games, Toys), I assume there would be
> >sufficient space to add these programs.
> >
> >
> sure, the version on my machine has lost all these and has got
> OpenOffice back.

Ah, that's very good news, will help in making TEI Knoppix even more
useful.

Ciao

--

Roberto Rosselli Del Turco      roberto.rossellidelturco at unito.it
Dipartimento di Scienze         rosselli at ling.unipi.it
del Linguaggio                  Then spoke the thunder  DA
Universita' di Torino           Datta: what have we given?  (TSE)

  Hige sceal the heardra,     heorte the cenre,
  mod sceal the mare,       the ure maegen litlath.  (Maldon 312-3)
=========================================================================
Date:         Wed, 12 Jan 2005 11:09:46 -0500
Reply-To:     Syd_Bauman@Brown.edu
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Syd Bauman <Syd_Bauman@BROWN.EDU>
Subject:      Re: About <front> - table of content - <figure>
In-Reply-To:  <003701c4f8a0$97c40bc0$4bd5a8c0@MARCEL>
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit

> We work on 15th-17th century texts and they aren't a collection of
> independent texts, but they are works conceived by the author as
> unity. "Book" is one way (common to the age) of calling a division
> that today we usually call "part" or "section". The same prefatory
> matter of a single division is above all (most of time) a
> rhetorical expedient. For this reason, I have not used <group>.

Hmm ... I'm not sure I know enough about your texts to agree or
disagree, so I'll take your word for it. I realize, though, that I
never asked what is *in* the prefatory matter to a "book" (the
dedication -- is it a single line "Dedicated to the memory of Antonio
Zampolli", or a larger unit with internal structure? If it's just a
paragraph or so it may make sense to put it into an element that is a
member of the divtop class (<argument>, <byline>, <dateline>
<docAuthor>, <docDate>, <epigraph>, <head>, <opener>, <salute>, and
<signed>), or to create a new element for it and make that new
element a member of divtop.


>  <TEI.2>
>    <teiHeader> <!-- ... --> </teiHeader>
>    <text>
>      <body>
>        <div1 n="1" type="preface"> <!-- ... --> </div1>
>        <div1 n="1" type="book">
>          <div2 n="1" type="dedication"> <!-- ... --> </div2>
>          <div2 n="2" type="chapter"> <!-- ... --> </div2>
>          <!-- ... -->
>        </div1>
>        <div1 n="2" type="book">
>          <div2 n="1" type="dedication"> <!-- ... --> </div2>
>          <div2 n="2" type="chapter"> <!-- ... --> </div2>
>          <!-- ... -->
>        </div1>
>      </body>
>    </text>
>  </TEI.2>

I think this is a reasonable encoding, which would be slightly
improved if the first <div1> were inside a <front> before <body>
instead:

  <TEI.2>
    <teiHeader> <!-- ... --> </teiHeader>
    <text>
      <front>
        <div1 n="1" type="preface"> <!-- ... --> </div1>
      </front>
      <body>
        <div1 n="1" type="book">
          <div2 n="1" type="dedication"> <!-- ... --> </div2>
          <div2 n="2" type="chapter"> <!-- ... --> </div2>
          <!-- ... -->
        </div1>
        <div1 n="2" type="book">
          <div2 n="1" type="dedication"> <!-- ... --> </div2>
          <div2 n="2" type="chapter"> <!-- ... --> </div2>
          <!-- ... -->
        </div1>
      </body>
    </text>
  </TEI.2>
=========================================================================
Date:         Wed, 12 Jan 2005 16:14:30 +0000
Reply-To:     Sebastian Rahtz <sebastian.rahtz@COMPUTING-SERVICES.OXFORD.AC.UK>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Sebastian Rahtz <sebastian.rahtz@COMPUTING-SERVICES.OXFORD.AC.UK>
Subject:      Re: Remote local extensions
Comments: To: Roberto Rosselli Del Turco <rosselli@ling.unipi.it>
In-Reply-To:  <1105545670.26062.57.camel@loki.grendelsmere>
MIME-Version: 1.0
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit

Roberto Rosselli Del Turco wrote:

>I'm surprised you ask :) Short answer: because Kate is much easier to
>use.
>
>
I cannot conceive of something easier than Emacs. It does not compute.

> I noticed that proposing a simple editor to my
>students they grasp the concept of text mark-up and start experimenting
>autonomously very quickly. Now, do you think I could do that with emacs?
>
>
er, yes

>Features that help beginnners a lot:
>
>- syntax highlighting
>- error highlighting
>- valid element/attribute hinting
>- document validation
>
>
ah, all the things you get with Emacs nxml-mode, you mean!
Does any programmers editor other than Emacs +nxml do incremental
validation?

>>I have a JRE on there, but do you seriously suggest Eclipse is for
>>beginning and/or casual users?
>>
>>
>
>No, but surely intermediate/advanced users can learn it quickly
>
if they can learn Eclipse, they can learn Emacs. I mean, these are both
tools of professional programmers.

>Now we're at the heart of the matter: it's true that at the moment TEI
>Knoppix is useful to very expert people like you and all the other TEI
>gurus, but think about the potential, it could be a complete environment
>for TEI encoding/teaching/learning.
>
of course, thats my aim

>This is why it should offer
>
>1. simple text editors like Kate: useful for beginners (or non-TEI
>related tasks, I'd hate having to use emacs for editing a system file or
>something like that);
>
>
only experts edit system files anyway!

>2. more powerful editors like jedit and/or Eclipse (+
>XMLBuddy/Vex/whatever): for intermediate to advanced users;
>
>3. emacs for "real encoders" :)
>
>
you'd have to explain in what ways jEdit is different from Emacs.
they both edit angle brackets, no more and no less. I want to
cater for the class of people who dont want to see <> at all

> I'll also confess that a "free as in beer" solution, i.e. XXE
>Standard or XML Buddy, looks acceptable to me.
>
>
to me, the condition  of XXE
"Licensee may not distribute the Software, or part of the Software,
alone or bundled with another product, without written permission from
Licensor."
is not acceptable. I want to make a CD which anyone can use and copy and
change. I don't want to make something which you cannot
copy to your friends without going back to a vendor

XML Buddy is limited to DTDs in the "free beer" version,  and has a
similar clause to the above.
I don't (personally) want to use something which can't do schemas.

>Ah, that's very good news, will help in making TEI Knoppix even more
>useful
>
>
have you tried Scribus, Dia, Gimp and Gnumeric as well...

--
Sebastian Rahtz
Information Manager, Oxford University Computing Services
13 Banbury Road, Oxford OX2 6NN. Phone +44 1865 283431

OSS Watch: JISC Open Source Advisory Service
http://www.oss-watch.ac.uk
=========================================================================
Date:         Wed, 12 Jan 2005 09:23:08 -0700
Reply-To:     daniel.odonnell@uleth.ca
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Daniel O'Donnell <daniel.odonnell@ULETH.CA>
Organization: Department of English, University of Lethbridge
Subject:      Re: Remote local extensions
In-Reply-To:  <200501121550.j0CFo6l07856@listserv.brown.edu>
MIME-Version: 1.0
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit

Sebastian Rahtz wrote:
> Syd Bauman wrote:
>
>
>>>That's a problem with emacs, in that it does not follow URLs
>>>properly. Your syntax is fine, your tool is broken.
>>>
>>>
>>
>>I think that's a bit harsh. Following URLs is a (desirable) feature
>>that Emacs/psgml does not (currently) provide, but it isn't "broken".
>>
>>
>
> I don't think its a "desirable" feature, exactly. the system identifier
> is a URL, surely? if you can't implement http, you cant really be said
> to implement
> URLs, I'd say.

As far as I can tell, emacs is following the doctype URL (I'd miss typed
something when I first put it in and it didn't recognise anything; the
problem vanished when I fixed the typo).

<!DOCTYPE TEI.2 PUBLIC "-//TEI Consortium//DTD TEI P4//EN"
"http://www.tei-c.org/Guidelines/DTD/tei2.dtd" [ ]>

I wish I could say what I'm running under: its the earlier TEI build in
xml-mode.

-dan
--
Daniel Paul O'Donnell, PhD
Associate Professor of English
University of Lethbridge
Lethbridge AB T1K 3M4
Tel. (403) 329-2377
Fax. (403) 382-7191
E-mail <daniel.odonnell@uleth.ca>
Home Page <http://people.uleth.ca/~daniel.odonnell/>
The Digital Medievalist Project: <http://www.digitalmedievalist.org/>
=========================================================================
Date:         Wed, 12 Jan 2005 09:40:30 -0700
Reply-To:     daniel.odonnell@uleth.ca
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Daniel O'Donnell <daniel.odonnell@ULETH.CA>
Organization: Department of English, University of Lethbridge
Subject:      Re: Remote local extensions
In-Reply-To:  <200501121559.j0CFxGl09241@listserv.brown.edu>
MIME-Version: 1.0
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit

Roberto Rosselli Del Turco wrote:
> Il giorno mer, 12-01-2005 alle 13:45 +0000, Sebastian Rahtz ha scritto:
>
>>Roberto Rosselli Del Turco wrote:

>>>
>>>1. a programmer's text editor: Kate (syntax highlighting, folding, word
>>>wrap, etc.);

> Features that help beginnners a lot:
>
> - syntax highlighting
> - error highlighting
> - valid element/attribute hinting
> - document validation
>

> I agree, but auto-completion/-tag closing look like nice features for
> XML editing to me. That said, I don't know KDE applications very well,
> so please take a look for yourself.
>

Roberto,
        Doesn't emacs do this? </ closes whatever tag is open, ^CE suggests the
next element, ^CR tags regions, ^C+ provides an attribute interface. Or
do you mean something else?
        My own experience with emacs is that it was a bugger to set up and run,
but pretty easy to use right away as an SGML (at the time editor). I
accept that it is not the most user friendly environment, especially for
those of us used to GUIs. But I've always found it
-dan
>
> --
>
> Roberto Rosselli Del Turco      roberto.rossellidelturco at unito.it
> Dipartimento di Scienze         rosselli at ling.unipi.it
> del Linguaggio                  Then spoke the thunder  DA
> Universita' di Torino           Datta: what have we given?  (TSE)
>
>   Hige sceal the heardra,     heorte the cenre,
>   mod sceal the mare,       the ure maegen litlath.  (Maldon 312-3)

--
Daniel Paul O'Donnell, PhD
Associate Professor of English
University of Lethbridge
Lethbridge AB T1K 3M4
Tel. (403) 329-2377
Fax. (403) 382-7191
E-mail <daniel.odonnell@uleth.ca>
Home Page <http://people.uleth.ca/~daniel.odonnell/>
The Digital Medievalist Project: <http://www.digitalmedievalist.org/>
=========================================================================
Date:         Wed, 12 Jan 2005 09:50:09 -0700
Reply-To:     daniel.odonnell@uleth.ca
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Daniel O'Donnell <daniel.odonnell@ULETH.CA>
Organization: Department of English, University of Lethbridge
Subject:      Re: rendition / suppied within w-tag
Comments: To: Gabriel BODARD <gabriel.bodard@KCL.AC.UK>
In-Reply-To:  <200501121558.j0CFwCl09033@listserv.brown.edu>
MIME-Version: 1.0
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit

There is a deeper issue going on (take it from one who bothered the list
with this endlessly seven or eight years ago). There are really two
kinds of words in your source text, even though they look the same.
There is a graphic object which you recognise as a word and which has
the features you mention: italics, spacing, hyphenation, etc. And then
there is the linguistic word, which has the other features you mention,
morphology, phonology, orthography.

The TEI w is a linguistic construction not a graphic one. Most of the
time, expanding w to include physical details works just fine. But I
found (in SGML, admittedly), that cluttering up linguistic texts with
graphic information made things less convenient for me when I came to do
things that were focused on the idealised text rather than specific
witnesses. For example, lets say you are looking for identical words
with identical POS across a corpus. If you clutter up you corpus with
accidentals of hyphenation, for example, you may have trouble finding
them all.

None of this is insoluble, of course. I just remember beginning by
thinking "why didn't those morons at the tei allow <corr> in <w>" and
ending up by realising there was a real distinction at work.
-dan


Gabriel BODARD wrote:
> The answer is to customise your DTD to allow these elements within <w>. In our
> TEI DTD both <hi> and <supplied> (and many other things) are valid within <w>.
>
> All best,
>
> Gabriel.
>
> Quoting Katrien Depuydt <depuydt@INL.NL>:
>
>
>>Hi,
>>We are annotating every wordt in our text corpus with PoS and lemma. We
>>are using the <w>-tag (attributes: type= for PoS and lemma= for lemma).
>>Two 'problems':
>>1. typographical encoding of part of a word form, f.i. "me<hi
>>rend="italic">n</hi>sen is not allowed within <w>
>>2. in our texts, words and parts of words supplied by the editor of a
>>text are encoded by means of the <supplied>-tag, f.i.
>><supplied>appel</supplied>flap
>><supplied> is not allowed within <w>.
>>
>>I know I could use <seg>, which would result in an encoding of:
>><w type="noun" lemma="mens">me<seg rend="italic">n</seg>sen</w>
>><w type="noun"
>>lemma="appelflap"><seg><supplied>appel</supplied></supplied>flap</w>
>>However this solution seems rather illogical to us.
>>Is there a special reason for not allowing supplied or hi within w or is
>>it an omission?
>
>
>
> --
> =======================================
> Gabriel BODARD
> Inscriptions of Aphrodisias
> Institute of Classical Studies Library
> Senate House
> Malet Street
> London WC1E 7HU
>
> Email: gabriel.bodard@kcl.ac.uk
> Tel: +44 (0)20 78 62 87 26
> Fax: +44 (0)20 78 62 87 22
> =======================================

--
Daniel Paul O'Donnell, PhD
Associate Professor of English
University of Lethbridge
Lethbridge AB T1K 3M4
Tel. (403) 329-2377
Fax. (403) 382-7191
E-mail <daniel.odonnell@uleth.ca>
Home Page <http://people.uleth.ca/~daniel.odonnell/>
The Digital Medievalist Project: <http://www.digitalmedievalist.org/>
=========================================================================
Date:         Wed, 12 Jan 2005 16:55:58 +0000
Reply-To:     Lou Burnard <lou.burnard@COMPUTING-SERVICES.OXFORD.AC.UK>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Lou Burnard <lou.burnard@COMPUTING-SERVICES.OXFORD.AC.UK>
Subject:      Re: rendition / suppied within w-tag
Comments: To: daniel.odonnell@uleth.ca
In-Reply-To:  <200501121650.j0CGo5l16890@listserv.brown.edu>
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii; format=flowed
Content-Transfer-Encoding: 7bit

I agree with Daniel. He's too modest to say so himself, but that's why
he helped us invent the <choice> element, which is surely a better way
of dealing with this frequently-encountered problem.

Lou

Daniel O'Donnell wrote:

> There is a deeper issue going on (take it from one who bothered the list
> with this endlessly seven or eight years ago). There are really two
> kinds of words in your source text, even though they look the same.
> There is a graphic object which you recognise as a word and which has
> the features you mention: italics, spacing, hyphenation, etc. And then
> there is the linguistic word, which has the other features you mention,
> morphology, phonology, orthography.
>
> The TEI w is a linguistic construction not a graphic one. Most of the
> time, expanding w to include physical details works just fine. But I
> found (in SGML, admittedly), that cluttering up linguistic texts with
> graphic information made things less convenient for me when I came to do
> things that were focused on the idealised text rather than specific
> witnesses. For example, lets say you are looking for identical words
> with identical POS across a corpus. If you clutter up you corpus with
> accidentals of hyphenation, for example, you may have trouble finding
> them all.
>
> None of this is insoluble, of course. I just remember beginning by
> thinking "why didn't those morons at the tei allow <corr> in <w>" and
> ending up by realising there was a real distinction at work.
> -dan
>
>
> Gabriel BODARD wrote:
>
>>The answer is to customise your DTD to allow these elements within <w>. In our
>>TEI DTD both <hi> and <supplied> (and many other things) are valid within <w>.
>>
>>All best,
>>
>>Gabriel.
>>
>>Quoting Katrien Depuydt <depuydt@INL.NL>:
>>
>>
>>
>>>Hi,
>>>We are annotating every wordt in our text corpus with PoS and lemma. We
>>>are using the <w>-tag (attributes: type= for PoS and lemma= for lemma).
>>>Two 'problems':
>>>1. typographical encoding of part of a word form, f.i. "me<hi
>>>rend="italic">n</hi>sen is not allowed within <w>
>>>2. in our texts, words and parts of words supplied by the editor of a
>>>text are encoded by means of the <supplied>-tag, f.i.
>>><supplied>appel</supplied>flap
>>><supplied> is not allowed within <w>.
>>>
>>>I know I could use <seg>, which would result in an encoding of:
>>><w type="noun" lemma="mens">me<seg rend="italic">n</seg>sen</w>
>>><w type="noun"
>>>lemma="appelflap"><seg><supplied>appel</supplied></supplied>flap</w>
>>>However this solution seems rather illogical to us.
>>>Is there a special reason for not allowing supplied or hi within w or is
>>>it an omission?
>>
>>
>>
>>--
>>=======================================
>>Gabriel BODARD
>>Inscriptions of Aphrodisias
>>Institute of Classical Studies Library
>>Senate House
>>Malet Street
>>London WC1E 7HU
>>
>>Email: gabriel.bodard@kcl.ac.uk
>>Tel: +44 (0)20 78 62 87 26
>>Fax: +44 (0)20 78 62 87 22
>>=======================================
>
>
> --
> Daniel Paul O'Donnell, PhD
> Associate Professor of English
> University of Lethbridge
> Lethbridge AB T1K 3M4
> Tel. (403) 329-2377
> Fax. (403) 382-7191
> E-mail <daniel.odonnell@uleth.ca>
> Home Page <http://people.uleth.ca/~daniel.odonnell/>
> The Digital Medievalist Project: <http://www.digitalmedievalist.org/>
>
=========================================================================
Date:         Wed, 12 Jan 2005 18:43:23 +0100
Reply-To:     Roberto Rosselli Del Turco <rosselli@LING.UNIPI.IT>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Roberto Rosselli Del Turco <rosselli@LING.UNIPI.IT>
Subject:      Re: Remote local extensions
In-Reply-To:  <41E552FE.6020002@uleth.ca>
Content-Type: text/plain
Mime-Version: 1.0
Content-Transfer-Encoding: 7bit

Hi Dan,

Il giorno mer, 12-01-2005 alle 09:40 -0700, Daniel O'Donnell ha scritto:
>
> Roberto,
>         Doesn't emacs do this? </ closes whatever tag is open, ^CE suggests the
> next element, ^CR tags regions, ^C+ provides an attribute interface. Or
> do you mean something else?
>         My own experience with emacs is that it was a bugger to set up and run,
> but pretty easy to use right away as an SGML (at the time editor). I
> accept that it is not the most user friendly environment, especially for
> those of us used to GUIs. But I've always found it [effective]

It's not only that (a bugger to set up and run, unfriendly), it's also
painfully unsuited to teach text markup to a newbie: I've seen people
puzzled by notetab, I can only wonder what could happen if I'd expose
them to emacs :)

Ciao

--

Roberto Rosselli Del Turco      roberto.rossellidelturco at unito.it
Dipartimento di Scienze         rosselli at ling.unipi.it
del Linguaggio                  Then spoke the thunder  DA
Universita' di Torino           Datta: what have we given?  (TSE)

  Hige sceal the heardra,     heorte the cenre,
  mod sceal the mare,       the ure maegen litlath.  (Maldon 312-3)
=========================================================================
Date:         Wed, 12 Jan 2005 19:03:04 +0100
Reply-To:     Roberto Rosselli Del Turco <rosselli@LING.UNIPI.IT>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Roberto Rosselli Del Turco <rosselli@LING.UNIPI.IT>
Subject:      Re: Remote local extensions
In-Reply-To:  <41E54CE6.2080001@computing-services.oxford.ac.uk>
Content-Type: text/plain
Mime-Version: 1.0
Content-Transfer-Encoding: 7bit

Il giorno mer, 12-01-2005 alle 16:14 +0000, Sebastian Rahtz ha scritto:
> Roberto Rosselli Del Turco wrote:
>
> >I'm surprised you ask :) Short answer: because Kate is much easier to
> >use.
> >
> >
> I cannot conceive of something easier than Emacs. It does not compute.

Hmm, I hope there's more than a bit of sarcasm here ... :)

But I'm afraid we'll have to agree to disagree, then, and stop here this
already quite off-topic thread. For me emacs is part of the problem
(*my* problem, of course), not of the solution.

> only experts edit system files anyway!

What you really mean here is "only experts *should* edit system files
anyway!", but I was hinting of a secondary use anyway.

> you'd have to explain in what ways jEdit is different from Emacs.
> they both edit angle brackets, no more and no less.

It's not a *feature*, but a *usability* deficit that makes emacs
unsuited for pedagogical purposes.

> I want to
> cater for the class of people who dont want to see <> at all

But this means you see no middle ground, then. Isn't it a bit odd?

> > I'll also confess that a "free as in beer" solution, i.e. XXE
> >Standard or XML Buddy, looks acceptable to me.
> >
> >
> to me, the condition  of XXE
> "Licensee may not distribute the Software, or part of the Software,
> alone or bundled with another product, without written permission from
> Licensor."
> is not acceptable. I want to make a CD which anyone can use and copy and
> change. I don't want to make something which you cannot
> copy to your friends without going back to a vendor
>
> XML Buddy is limited to DTDs in the "free beer" version,  and has a
> similar clause to the above.
> I don't (personally) want to use something which can't do schemas.

Sorry, didn't explain myself well: what I meant was that it can be an
acceptable solution for me, as a single user, but surely not for *you*
for the reasons you list above (I agree with you, btw).

Ciao

--

Roberto Rosselli Del Turco      roberto.rossellidelturco at unito.it
Dipartimento di Scienze         rosselli at ling.unipi.it
del Linguaggio                  Then spoke the thunder  DA
Universita' di Torino           Datta: what have we given?  (TSE)

  Hige sceal the heardra,     heorte the cenre,
  mod sceal the mare,       the ure maegen litlath.  (Maldon 312-3)
=========================================================================
Date:         Wed, 12 Jan 2005 18:47:29 +0000
Reply-To:     Sebastian Rahtz <sebastian.rahtz@COMPUTING-SERVICES.OXFORD.AC.UK>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Sebastian Rahtz <sebastian.rahtz@COMPUTING-SERVICES.OXFORD.AC.UK>
Subject:      Re: Remote local extensions
Comments: To: Roberto Rosselli Del Turco <rosselli@LING.UNIPI.IT>
In-Reply-To:  <200501121802.j0CI2ul25935@listserv.brown.edu>
MIME-Version: 1.0
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit

Roberto Rosselli Del Turco wrote:

>It's not only that (a bugger to set up and run, unfriendly),
>
it depends on your knowledge-base.

> it's also
>painfully unsuited to teach text markup to a newbie: I've seen people
>puzzled by notetab, I can only wonder what could happen if I'd expose
>them to emacs :)
>
>
Some of us have been teaching text markup using TEI, XML, Emacs
for years. I don't recall any death or injury....


--
Sebastian Rahtz
Information Manager, Oxford University Computing Services
13 Banbury Road, Oxford OX2 6NN. Phone +44 1865 283431

OSS Watch: JISC Open Source Advisory Service
http://www.oss-watch.ac.uk
=========================================================================
Date:         Wed, 12 Jan 2005 13:49:39 -0500
Reply-To:     David Sewell <dsewell@VIRGINIA.EDU>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         David Sewell <dsewell@VIRGINIA.EDU>
Subject:      Re: Serna and stable beginning editors
In-Reply-To:  <41E536E5.2010802@uleth.ca>
MIME-Version: 1.0
Content-Type: TEXT/PLAIN; charset=US-ASCII

On Wed, 12 Jan 2005, Daniel O'Donnell wrote:

> The discussion of better editors brings me back to Serna. I was really
> impressed at first but then started having it crash all the time on me
> for something to do with the stylesheet library. I went back to emacs.
>
> Is this something others have experienced?

We evaluated Serna about a year ago and thought it had promise
especially as a beginner's editor, or for use for proofing/editing
mainly of content in tagged documents. I have found it personally
unusable because it cannot properly display at other than 100% zoom in
the OS X version (a limitation, apparently, of the Trolltech Qt engine
it uses, not something Syntext has control over).

This morning I thought I'd check the most recent release. I downloaded
both the 2.1 beta and the 2.0 stable version. Neither of them works
properly on my system (OS X 10.3.7): I get XML parser errors opening the
sample docs, and the icon buttons don't show up on the menubar.

Is anyone else using Serna successfully on OS X?

--
David Sewell, Editorial and Technical Manager
Electronic Imprint, The University of Virginia Press
PO Box 400318, Charlottesville, VA 22904-4318 USA
Courier: 310 Old Ivy Way, Suite 302, Charlottesville VA 22903
Email: dsewell@virginia.edu   Tel: +1 434 924 9973
Web: http://www.ei.virginia.edu/
=========================================================================
Date:         Wed, 12 Jan 2005 18:52:17 +0000
Reply-To:     Sebastian Rahtz <sebastian.rahtz@COMPUTING-SERVICES.OXFORD.AC.UK>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Sebastian Rahtz <sebastian.rahtz@COMPUTING-SERVICES.OXFORD.AC.UK>
Subject:      Re: Remote local extensions
Comments: To: Roberto Rosselli Del Turco <rosselli@LING.UNIPI.IT>
In-Reply-To:  <200501121803.j0CI3Rl26031@listserv.brown.edu>
MIME-Version: 1.0
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit

Roberto Rosselli Del Turco wrote:

>It's not a *feature*, but a *usability* deficit that makes emacs
>unsuited for pedagogical purposes.
>
>
you may be right; but you'd have to justify that with research,
not gut feeling, I am afraid

>
>
>>I want to
>>cater for the class of people who dont want to see <> at all
>>
>>
>
>But this means you see no middle ground, then. Isn't it a bit odd?
>
>
no. to me there are:

 1 text editors (notepad)
 2 programmers editors (emacs, jedit, oxygen)
 3 wysiwyg xml editors (xmetal, serna, xmlmind)
 4 word-processors (word, OO)

I don't distinguish really between the ones in category 2, they all have
good and bad points, and it's very much down to personal taste
and other uses you make of the tool.

--
Sebastian Rahtz
Information Manager, Oxford University Computing Services
13 Banbury Road, Oxford OX2 6NN. Phone +44 1865 283431

OSS Watch: JISC Open Source Advisory Service
http://www.oss-watch.ac.uk
=========================================================================
Date:         Wed, 12 Jan 2005 23:03:07 +0000
Reply-To:     Sebastian Rahtz <sebastian.rahtz@COMPUTING-SERVICES.OXFORD.AC.UK>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Sebastian Rahtz <sebastian.rahtz@COMPUTING-SERVICES.OXFORD.AC.UK>
Subject:      xml editors, eclipse
MIME-Version: 1.0
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit

Does anyone on this list actually use Eclipse for editing TEI XML files,
with an open source plugin? If so, can you bring me up to speed on such
a thing.

Yes, I know oXygen and XML Buddy are Eclipse plugins, but thats not
what I want

--
Sebastian Rahtz
Information Manager, Oxford University Computing Services
13 Banbury Road, Oxford OX2 6NN. Phone +44 1865 283431

OSS Watch: JISC Open Source Advisory Service
http://www.oss-watch.ac.uk
=========================================================================
Date:         Wed, 12 Jan 2005 21:54:01 -0500
Reply-To:     Francois Lachance <lachance@ORIGIN.CHASS.UTORONTO.CA>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Francois Lachance <lachance@ORIGIN.CHASS.UTORONTO.CA>
Subject:      Pedagogical Purpose and Emacs was Re: [TEI-L] Remote local
              extensions
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit

I want to address some of the pedagogical considerations raised by Roberto
Rosselli in recent postings.

I want to address one particular assumption about the best pedagogical
environment to teach and learn about markup. I am not entirely sure but I
believe Roberto is arguing that the best environment is supplied by
providing a single software tool for both writing and rendering.


It was his mention of HTML that prompted my recollections of days before
Netscape Composer or Macromedia Dreamweaver or Microsoft bought Frontpage.
In those days, HTML was taught and learnt with at least two tools: a text
editor for hand coding and a browser for viewing the results. Preferably
several different browsers. Great lesson in separating content from
presentation. And with online validation such as that offered by the W3
consortitium, students were able to locate and correct errors.

There was no such easily available pairing of free tools for SGML. Though
for a while Soft Quad's Panaroma browser looked promising for extending
the user base for viewing of SGML files.

For XML, one can work with a browser with a validating parser. There are a
number of free Unicode capable text editors.

I stress the pedagogical value of students consciously moving from
application to another.  In particular if one is switching between
applications used for rendering what was written with the other.

The other assumption in Roberto's remarks was the learning curve for
Emacs. Those with some experience with the reveal codes functionality of a
wordprocessing package such as WordPerfect find it perhaps more easy to
adapt to the Emacs interface of minibuffer, mode line, buffer and drop
down menus. For users that come to Emacs from Microsoft Word, the drop
down menus are familiar and so too the mode line (in Word there is usually
a status line at the bottom of the window). The minibuffer poses a bit of
a challenge. Users quickly understand its role and purpose when provided
analogies to dialogue boxes, error warnings and to the assistants that pop
up in Windows. Indeed as Bob Ducharme writes fetchingly about the
minibuffer: "You and Emacs enter informatioon there to provide details
about what each of you is doing (or trying to do). Emacs puts messages
there to tell you things like the number of replacements a
search-and-replace operation performed; you use the minibuffer as a
command line when necessary and enter text in response to any questions
Emacs asks you -- for example, whether to save an edited file when
quitting." [Bob Ducharme "Editing SGML Documents with the Emacs Text
Editor, Chapter 2 from _SGML CD_ (Prentice Hall, Charles F. Goldfarb
Series on Open Information Management, ISBN 0-13-475740-8) 1998 p. 5]

Of course it is often argued that the pedagogical goal is not to learn
about Emacs but to learn about text encoding or markup. I, myself, tend
not to view the matter dichotomously. For example, Bob Ducharme's
explanations for fill paragraph (M-q) and for fill element (C-c C-q) are a
wonderful way for introducing students to considerations of white space
treatment, a particularly intricate consideration in processing XML.

From a teacher's persepctive there are three questions: What are the
pedagogical objectives? What are the tools at hand? What learning
experiences can be created? The questions are equally relevant for the
training of in-house taggers as well as the education of sophisticated
content modellers.

From a learners perspective, there is only one question. What skill or
knowlege can I take away and apply again or elsewhere? It is a question
that translates simply into "What can I share?"

It is entirely possible that Roberto did not intend any of the assumptions
attributed above to him. Nevertheless I am very grateful to him for having
provided me with the occassion for projecting them onto the exchange he
has conducted. It has helped me enormously with devising an approach to
the minibuffer does not rely on command line analogies. That said, it is
time to C-x C-c

Thank you.


--
Francois Lachance, Scholar-at-large
http://www.chass.utoronto.ca/~lachance

A calendar is like a map. And just as maps have insets, calendars in the
21st century might have 'moments' expressed in flat local time fanning out
into "great circles" expressed in earth revolution time.
=========================================================================
Date:         Wed, 12 Jan 2005 23:20:31 -0700
Reply-To:     daniel.odonnell@uleth.ca
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Daniel O'Donnell <daniel.odonnell@ULETH.CA>
Organization: Department of English, University of Lethbridge
Subject:      Editors and medium-tech people
MIME-Version: 1.0
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit

I'm not sure Roberto's point is being understood properly. As I
understand it, and we have discussed this a number of times, the basic
point is that all things being equal, emacs is an unfriendly way for
people raised on GUIs and without programming experience to begin with
or use at the intermediate level.

Although I don't think I agree 100% with roberto about the need for an
"intermediate" editor--it seems to me that medium tech students and
researchers want to mess around in the code the way emacs encourages--it
is true that firing up emacs is not quite as easy as firing up
wordperfect. And that one could wish for improvements to emacs to make
it less intimidating to students who are just beginning to find their
way. I think even its most ardent fans would admit that it wouldn't be
ruined by some more work on cosmetics, intuitiveness, and userfriendliness.

I've always thought that students learning a language should hand code
small projects so they know how the markup works and can have the joy of
the thing working right in the end in firefox (bad students would be
assigned IE as the test browser for their standards based work as
punishment). The next step, I've always thought, is learning to be
comfortable with (or at least how to use) a tool like emacs. But I must
confess, I don't know that much about the other browsers mentioned.

Pretty tools like Serna, seem to me to be something stable projects give
employees: they are for use once the experimentation is over. Perhaps
they would also be useful in very controlled circumstances to ensure
quick success in certain basic procedures.

So in the end, for me, a perfect world would have the following:
1) Free, good quality, craft brewed ale.
2) Year round california weather with skiing and hockey nearby.
3) A Emacs manual that was easier to find one's way around in with an
interface to match.

Thats my increasingly valuable 2 cents CAD.

-dan


--
Daniel Paul O'Donnell, PhD
Associate Professor of English
University of Lethbridge
Lethbridge AB T1K 3M4
Tel. (403) 329-2377
Fax. (403) 382-7191
E-mail <daniel.odonnell@uleth.ca>
Home Page <http://people.uleth.ca/~daniel.odonnell/>
The Digital Medievalist Project: <http://www.digitalmedievalist.org/>
=========================================================================
Date:         Thu, 13 Jan 2005 09:59:06 +0100
Reply-To:     Katrien Depuydt <depuydt@INL.NL>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Katrien Depuydt <depuydt@INL.NL>
Subject:      Re: rendition / suppied within w-tag
In-Reply-To:  <41E5569E.4010408@computing-services.oxford.ac.uk>
MIME-Version: 1.0
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit

Using the element choice would indeed work well if you are making your
own editions, which we are not. We do not always have the necessary
information to represent the two options. More than often we only have
the expanded form of an abbreviated token, and not the form in which it
was represented.
 From our point of view, splitting a token in a linguistic and a graphic
unit does not make sense if the only difference is that within the
graphic unit typographical encoding is allowed and within the linguistic
unit it is not.
On the other hand,  'supplied' does not indicate linguistic information.
For a historical linguist a form without the supplied encoding is not
identical to a form with the supplied tag, since the content of the
supplied-tag is never certain:: f.i. <supplied>dog</supplied>hter vs..
<supplied>doug</supplied>ter.
Choice would only make sense if we were to supply a normalised form to
every token in the corpus, and we do not intend to do so.

Katrien


Katrien Depuydt

Institute for Dutch Lexicology
Editor Dutch Language Database

P.O. Box 9515
NL-2300 RA Leiden



Lou Burnard wrote:

> I agree with Daniel. He's too modest to say so himself, but that's why
> he helped us invent the <choice> element, which is surely a better way
> of dealing with this frequently-encountered problem.
>
> Lou
>
> Daniel O'Donnell wrote:
>
>> There is a deeper issue going on (take it from one who bothered the list
>> with this endlessly seven or eight years ago). There are really two
>> kinds of words in your source text, even though they look the same.
>> There is a graphic object which you recognise as a word and which has
>> the features you mention: italics, spacing, hyphenation, etc. And then
>> there is the linguistic word, which has the other features you mention,
>> morphology, phonology, orthography.
>>
>> The TEI w is a linguistic construction not a graphic one. Most of the
>> time, expanding w to include physical details works just fine. But I
>> found (in SGML, admittedly), that cluttering up linguistic texts with
>> graphic information made things less convenient for me when I came to do
>> things that were focused on the idealised text rather than specific
>> witnesses. For example, lets say you are looking for identical words
>> with identical POS across a corpus. If you clutter up you corpus with
>> accidentals of hyphenation, for example, you may have trouble finding
>> them all.
>>
>> None of this is insoluble, of course. I just remember beginning by
>> thinking "why didn't those morons at the tei allow <corr> in <w>" and
>> ending up by realising there was a real distinction at work.
>> -dan
>>
>>
>> Gabriel BODARD wrote:
>>
>>> The answer is to customise your DTD to allow these elements within
>>> <w>. In our
>>> TEI DTD both <hi> and <supplied> (and many other things) are valid
>>> within <w>.
>>>
>>> All best,
>>>
>>> Gabriel.
>>>
>>> Quoting Katrien Depuydt <depuydt@INL.NL>:
>>>
>>>
>>>
>>>> Hi,
>>>> We are annotating every wordt in our text corpus with PoS and
>>>> lemma. We
>>>> are using the <w>-tag (attributes: type= for PoS and lemma= for
>>>> lemma).
>>>> Two 'problems':
>>>> 1. typographical encoding of part of a word form, f.i. "me<hi
>>>> rend="italic">n</hi>sen is not allowed within <w>
>>>> 2. in our texts, words and parts of words supplied by the editor of a
>>>> text are encoded by means of the <supplied>-tag, f.i.
>>>> <supplied>appel</supplied>flap
>>>> <supplied> is not allowed within <w>.
>>>>
>>>> I know I could use <seg>, which would result in an encoding of:
>>>> <w type="noun" lemma="mens">me<seg rend="italic">n</seg>sen</w>
>>>> <w type="noun"
>>>> lemma="appelflap"><seg><supplied>appel</supplied></supplied>flap</w>
>>>> However this solution seems rather illogical to us.
>>>> Is there a special reason for not allowing supplied or hi within w
>>>> or is
>>>> it an omission?
>>>
>>>
>>>
>>>
>>> --
>>> =======================================
>>> Gabriel BODARD
>>> Inscriptions of Aphrodisias
>>> Institute of Classical Studies Library
>>> Senate House
>>> Malet Street
>>> London WC1E 7HU
>>>
>>> Email: gabriel.bodard@kcl.ac.uk
>>> Tel: +44 (0)20 78 62 87 26
>>> Fax: +44 (0)20 78 62 87 22
>>> =======================================
>>
>>
>>
>> --
>> Daniel Paul O'Donnell, PhD
>> Associate Professor of English
>> University of Lethbridge
>> Lethbridge AB T1K 3M4
>> Tel. (403) 329-2377
>> Fax. (403) 382-7191
>> E-mail <daniel.odonnell@uleth.ca>
>> Home Page <http://people.uleth.ca/~daniel.odonnell/>
>> The Digital Medievalist Project: <http://www.digitalmedievalist.org/>
>>
=========================================================================
Date:         Thu, 13 Jan 2005 09:07:20 +0000
Reply-To:     Sebastian Rahtz <sebastian.rahtz@COMPUTING-SERVICES.OXFORD.AC.UK>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Sebastian Rahtz <sebastian.rahtz@COMPUTING-SERVICES.OXFORD.AC.UK>
Subject:      Re: Editors and medium-tech people
Comments: To: daniel.odonnell@uleth.ca
In-Reply-To:  <200501130620.j0D6KPl04455@listserv.brown.edu>
MIME-Version: 1.0
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit

Daniel O'Donnell wrote:

> emacs is an unfriendly way for
>people raised on GUIs and without programming experience to begin with
>or use at the intermediate level.
>
>
s/emacs/text editors/

>So in the end, for me, a perfect world would have the following:
>1) Free, good quality, craft brewed ale.
>2) Year round california weather with skiing and hockey nearby.
>3) A Emacs manual that was easier to find one's way around in with an
>interface to match.
>
>
I've used Emacs for 20 years now and have never read through
the manual or any books about it :-}

sebastian
=========================================================================
Date:         Thu, 13 Jan 2005 09:29:51 +0000
Reply-To:     Lou Burnard <lou.burnard@COMPUTING-SERVICES.OXFORD.AC.UK>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Lou Burnard <lou.burnard@COMPUTING-SERVICES.OXFORD.AC.UK>
Subject:      Re: Editors and medium-tech people
In-Reply-To:  <200501130907.j0D97pl16781@listserv.brown.edu>
MIME-Version: 1.0
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit

It's not true that emacs doesnt have any user-level documentation. It
comes with a built in tutorial of extreme simplicity, which spends
almost the entire first lesson telling you several different ways of
moving the cursor round the screen. The problem, if any, is that it
comes with *too much* documentation, just as its interface contains *too
many* options -- some people are just bewildered when faced with a huge
range of unfamiliar options, most of which they have never thought about
wanting to use.  But that's probably true of all software of any usefulness.

I think the only problem with emacs is one of perception, if truth were
told, and people's lack of experience with non-wimpy interfaces of course.

lou


 Sebastian Rahtz wrote:l

>Daniel O'Donnell wrote:
>
>
>
>>emacs is an unfriendly way for
>>people raised on GUIs and without programming experience to begin with
>>or use at the intermediate level.
>>
>>
>>
>>
>s/emacs/text editors/
>
>
>
>>So in the end, for me, a perfect world would have the following:
>>1) Free, good quality, craft brewed ale.
>>2) Year round california weather with skiing and hockey nearby.
>>3) A Emacs manual that was easier to find one's way around in with an
>>interface to match.
>>
>>
>>
>>
>I've used Emacs for 20 years now and have never read through
>the manual or any books about it :-}
>
>sebastian
>
>
>
>
=========================================================================
Date:         Thu, 13 Jan 2005 08:18:57 -0700
Reply-To:     daniel.odonnell@uleth.ca
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Daniel O'Donnell <daniel.odonnell@ULETH.CA>
Organization: Department of English, University of Lethbridge
Subject:      Re: Editors and medium-tech people
Comments: To: Lou Burnard <lou.burnard@COMPUTING-SERVICES.OXFORD.AC.UK>
In-Reply-To:  <200501130929.j0D9Trl19002@listserv.brown.edu>
MIME-Version: 1.0
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit

Lou Burnard wrote:
> It's not true that emacs doesnt have any user-level documentation. It
> comes with a built in tutorial of extreme simplicity, which spends
> almost the entire first lesson telling you several different ways of
> moving the cursor round the screen. The problem, if any, is that it
> comes with *too much* documentation, just as its interface contains *too
> many* options -- some people are just bewildered when faced with a huge
> range of unfamiliar options, most of which they have never thought about
> wanting to use.  But that's probably true of all software of any usefulness.

This is of course true, but usefulness is often a trade off for
userfriendliness.
>
> I think the only problem with emacs is one of perception, if truth were
> told, and people's lack of experience with non-wimpy interfaces of course.

Well in the end de gustibus, I imagine. I'm a fan of emacs and use it
for everything but straight text prep, but remember how intimidating it
was in the beginning and still avoid adding new modes and the like. What
is appealing to people who are very interested in markup and the like is
not necessarily appealing to those who are a little bit interested or
want to use it as an means to something else. I still think Roberto's
point that it can be intimidating to a general student audience is correct.

-dan
>
> lou
>
>
>  Sebastian Rahtz wrote:l
>
>
>>Daniel O'Donnell wrote:
>>
>>
>>
>>
>>>emacs is an unfriendly way for
>>>people raised on GUIs and without programming experience to begin with
>>>or use at the intermediate level.
>>>
>>>
>>>
>>>
>>
>>s/emacs/text editors/
>>
>>
>>
>>
>>>So in the end, for me, a perfect world would have the following:
>>>1) Free, good quality, craft brewed ale.
>>>2) Year round california weather with skiing and hockey nearby.
>>>3) A Emacs manual that was easier to find one's way around in with an
>>>interface to match.
>>>
>>>
>>>
>>>
>>
>>I've used Emacs for 20 years now and have never read through
>>the manual or any books about it :-}
>>
>>sebastian
>>
>>
>>
>>

--
Daniel Paul O'Donnell, PhD
Associate Professor of English
University of Lethbridge
Lethbridge AB T1K 3M4
Tel. (403) 329-2377
Fax. (403) 382-7191
E-mail <daniel.odonnell@uleth.ca>
Home Page <http://people.uleth.ca/~daniel.odonnell/>
The Digital Medievalist Project: <http://www.digitalmedievalist.org/>
=========================================================================
Date:         Fri, 14 Jan 2005 10:21:04 -0600
Reply-To:     Molly Dolan <molly.dolan@gmail.com>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Molly Dolan <molly.dolan@GMAIL.COM>
Subject:      University of Illinois Offers Advanced Degree and Fellowships in
              Digital Librarianship
Comments: To: diglib@infoserv.inist.fr, web4lib@sunsite3.berkeley.edu,
          asis-l@asis.org, jesse@listserv.utk.edu
Mime-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 8bit

Apologies for cross-posting.
************************************************
University of Illinois Offers Advanced Degree and
Fellowships in Digital Librarianship

URBANA-CHAMPAIGN, ILâ€”Beginning in the 2005â€“2006 school year, the
Graduate School of Library and Information Science (GSLIS) at the
University of Illinois at Urbana-Champaign will offer a structured
Certificate of Advanced Study (CAS) in Digital Libraries. Five
one-year, non-renewable fellowships will also be available to CAS and
MS degree students wishing to focus on digital libraries. The program
aims to give students a thorough and technically focused background in
digital libraries that will enable them to serve as designers,
decision-makers, and creators of digital collections.

Students may choose to enroll in the CAS program either on campus at
Urbana-Champaign or at a distance via GSLIS's LEEP online education
option. The core courses for the program will be offered via LEEP,
while elective courses may be completed via LEEP or on campus, as
offered. By making use of the LEEP option, GSLIS will be able to offer
classes taught by distinguished practitioners from other institutions
in the field of digital librarianship.

The CAS degree is a program of advanced course work intended for those
who hold a master's degree in library and information science or a
related field. Librarians, information scientists, and others in
information management can enroll in the program to refresh and update
their skills and gain greater specialization in digital librarianship
and related issues. To earn the degree, students will be required to
complete 40 hours of course work, including 8 hours focusing on an
individual project related to digital libraries.

Students may focus their studies in one of many directions, including
theory and implementation, information organization and access tools,
learning environments, community information exchange, and more.
Students will gain advanced-level knowledge of digital asset
management, information and collection modeling, design of
human-centered, digitally mediated information services, and
information policy. The program assumes existing MS-level knowledge of
Library and Information Science, including basic information
organization, indexing and cataloging, information needs and uses,
reference and user services, and the role of libraries in society.

With support from the Institute of Museum and Library Services (IMLS),
GSLIS will be recruiting and placing a total of five fellows to pursue
digital librarianship studies in the 2005â€“2006 academic year, and
another five in 2006â€“2007. To apply for the fellowships, students must
apply for either the CAS degree program in Digital Libraries, or the
MS degree program in Library and Information Science. MS students
should indicate on their applications that they have an interest in
digital libraries. After being accepted to the program, students will
be encouraged to write an essay explaining their interest and goals in
the study of digital librarianship. Students who are offered and
accept the fellowship positions will be required to fulfill their
fellowship requirements at the Urbana-Champaign campus.

GSLIS, the number-one ranked LIS degree program by U.S. News and World
Report, will be the first in the nation to offer an advanced degree
targeted at professionals in the growing field of digital
librarianship. The program will be conducted in close partnership with
the University's world-renowned libraries, including Grainger
Engineering Library Information Center, which is home to
groundbreaking research in digital libraries and metadata harvesting.

Additional information about applying to the program can be found at
http://www.lis.uiuc.edu/gslis/degrees/cas_dl.html; information about
digital projects of the University Library can be found at
http://www.library.uiuc.edu/digproj/digprojt.html.

Contact for questions regarding the degree programs and fellowships:
Linda C. Smith, Associate Dean, lcsmith@uiuc.edu.
=========================================================================
Date:         Fri, 14 Jan 2005 12:37:53 -0500
Reply-To:     Wendell Piez <wapiez@MULBERRYTECH.COM>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Wendell Piez <wapiez@MULBERRYTECH.COM>
Subject:      Re: Editors and medium-tech people
In-Reply-To:  <41E63A48.8000604@computing-services.oxford.ac.uk>
Mime-Version: 1.0
Content-Type: text/plain; charset="us-ascii"; format=flowed

At 04:07 AM 1/13/2005, Sebastian wrote:
>I've used Emacs for 20 years now and have never read through
>the manual or any books about it :-}

I think this admission is very revealing. Partly by what Sebastian doesn't
tell us about how he learned. He and other power-users might say more about
this. Particularly of interest in this context would be to get a sense of
proportionally how many Emacs users learned with other Emacs users at their
elbow, say in an office, classroom or lab, versus those who taught
themselves in more isolated settings.

Personally, whenever I tried, I found Emacs difficult to learn -- from
installation and maintenance through to operating it. As such, it is a fine
illustration of the way computers used to be -- both powerful for those in
the know, and opaque and inaccessible to those who aren't yet, but who want
to be. I don't think GUIs have done well in the marketplace for no reason
at all. They may be badly or well designed (we all know GUIs of both kinds)
-- but at least when they're done right they have a transparency that lends
them to an autodidactic approach. (Here I disagree with Sebastian -- it's
not text editors in general: most are way easier to learn than Emacs.)

(Training in XML, which by nature is different from learning how to operate
an interface, does pose interesting challenges in this respect. I'm quite
sympathetic, accordingly, to what Francois has said in this thread -- while
differing from him as to whether Emacs is somehow better for demonstrating
the separation of format from content than, say at the very low end,
TextPad, with external processorts for your XML chores, plus your browser.
If anything, this is even more down-and-dirty, which is pedagogically useful.)

Emacs may be great if you have an Emacs guru to hold your hand for a few
days at the beginning, and perhaps thereafter at odd moments. But if you're
trying to fly solo ... at least in my case, I wasn't so unhappy with other
tools (which I was actually able to figure out without having to memorize
obscure command-key sequences -- BTW I found vi the same way) that it ever
seemed worth making the switch. (I even did have an Emacs guru down the
hall, for a time -- but he was too busy using it, and writing modes for it,
to really help, while we both had work to get done. He did let me keep
"Programming in Emacs-LISP" on my bookshelf for a while so I could feel
guilty and envious while working on other stuff.)

If the aim of the CD is to help the lone wolves -- I wouldn't put my $0.02
on Emacs. It's like saying "baking is easy! all you have to do is grind the
flour...." In university settings, it is easy to forget that not everyone
has a flour mill in the next room.

So, has anyone managed to teach *themselves* Emacs, with the manuals and
online help only, from installation through mode-configuration through XML
parsing to schema and stylesheet development? I'm sure there are cases, but
how many others have tried and concluded it wasn't worth the trouble, as
compared to alternatives (if only because they "weren't smart enough")?
Consider how efficient, prompt and effective a help system is that takes
the form of an experienced, knowledgeable and sympathetic user sitting at
the console next to yours. Do not underestimate the importance of such help
systems for learning -- if only because they continually send the message
that It Can Be Done.

As for editors for medium-tech people -- I still think there's a fine
market opportunity for a company that wants to distribute a free,
platform-independent starter-editor that works more like structured editors
(XMetaL etc.) than free-form text editors with tools support (which are
also a must-have). XMetaL itself (which isn't free) and Altova Authentic
(which is, though it comes with other strings) are almost there -- but are
both locked into Windows. Particularly if the free version were crippleware
(say, you'd have to upgrade to the next level to get out of TEI-Lite), I
think this is a viable business proposition. But I'm not in the software
business.

When getting medium-tech people started with XML, these days I show them
how to use a GUI plain-text editor (It would probably be BBEdit on Mac, any
of several on Windows) with external tools, and perhaps demonstrate oXygen
as a great value for the money, once you are able to take advantage of its
smorgasbord of features. Of course this doesn't solve the problem for the CD.

Cheers,
Wendell


======================================================================
Wendell Piez                            mailto:wapiez@mulberrytech.com
Mulberry Technologies, Inc.                http://www.mulberrytech.com
17 West Jefferson Street                    Direct Phone: 301/315-9635
Suite 207                                          Phone: 301/315-9631
Rockville, MD  20850                                 Fax: 301/315-8285
----------------------------------------------------------------------
   Mulberry Technologies: A Consultancy Specializing in SGML and XML
======================================================================
=========================================================================
Date:         Fri, 14 Jan 2005 11:53:19 -0700
Reply-To:     daniel.odonnell@uleth.ca
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Daniel O'Donnell <daniel.odonnell@ULETH.CA>
Organization: Department of English, University of Lethbridge
Subject:      Re: Editors and medium-tech people
Comments: To: Wendell Piez <wapiez@MULBERRYTECH.COM>
In-Reply-To:  <200501141748.j0EHmRl23846@listserv.brown.edu>
MIME-Version: 1.0
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit

Wendell Piez wrote:
>
> So, has anyone managed to teach *themselves* Emacs, with the manuals and
> online help only, from installation through mode-configuration through XML
> parsing to schema and stylesheet development?

Not to brag, but yeah, I did that. I haven't got schema development down
and after eight years I still can't the spelling to work, but I think I
do most user- (as opposed to developer) things: I can write, name, save,
and edit macros, validate things, even build forms in the form mode.

I've had two prompts in my work with emacs: David Megginson recommended
it to me in 1997, when I was asking about SGML editing tools, but that
was the extent of his involvement. Roberto, who started this thread
anyway, showed me how to do stylesheets, but not on emacs. Later, I
discovered my father has been using it for years.

So apart from showing how smart I must be, the reason for picking up
this thread is to emphasise what I think is the middle ground here. Like
Sebastian and Lou, I use emacs a lot and like it as a tool. But like
Roberto and Wendell, I'm aware that there is some room for improvement.
I turn to new modes in Emacs only as a last resort. Generally I like to
stick to what I already know on it. I think Lou's point about the
documentation is interesting. I'd say emacs is the only program for
which I ever read instructions for anything other than detail-
trouble-shooting. That may be a sign of the problem. It is not something
one starts up and instantly understands.

I consider myself to be pretty firmly medium tech. Even experienced
medium tech users can take a while to get stuff going. When my father
set up his last notebook over Christmas a year ago, it took him a week
to get his emacs installation up and running with everything going the
way he wanted to. That's a pretty serious time investment, although he
was hobbying rather than working on it solidly. He's very happy with the
results, but not many programs nowadays require that kind of investment.
I dropped Serna when it crashed a couple of times. I certainly didn't
sit down and try to figure out why.

All this being said, I would like to say that the tei-emacs is very
good. It requires much less work than used to be involved when I'd get
my copy from wherever.

So I like emacs--perhaps even have an affection for it; think it is a
very handy and useful tool, but, like hammers without rubber grips,
could perhaps be improved a little on the consumer end of things. But
then perhaps I should go learn to do that and fix it myself?
-dan
--
Daniel Paul O'Donnell, PhD
Associate Professor of English
University of Lethbridge
Lethbridge AB T1K 3M4
Tel. (403) 329-2377
Fax. (403) 382-7191
E-mail <daniel.odonnell@uleth.ca>
Home Page <http://people.uleth.ca/~daniel.odonnell/>
The Digital Medievalist Project: <http://www.digitalmedievalist.org/>
=========================================================================
Date:         Fri, 14 Jan 2005 19:37:03 +0000
Reply-To:     Sebastian Rahtz <sebastian.rahtz@COMPUTING-SERVICES.OXFORD.AC.UK>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Sebastian Rahtz <sebastian.rahtz@COMPUTING-SERVICES.OXFORD.AC.UK>
Subject:      Re: Editors and medium-tech people
Comments: To: daniel.odonnell@uleth.ca
In-Reply-To:  <200501141853.j0EIrBl01412@listserv.brown.edu>
MIME-Version: 1.0
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit

Daniel O'Donnell wrote:

>
>When my father
>set up his last notebook over Christmas a year ago, it took him a week
>to get his emacs installation up and running with everything going the
>way he wanted to. That's a pretty serious time investment, although he
>was hobbying rather than working on it solidly.
>
>
to me, that says what an important tool emacs is, and how efficient
and productive a good setup can. I bet your father uses TeX, too!

setting up some simple text editor only takes 5 minutes, because
after 5 minutes you have exhausted its possibilities.

For an example, consider the fact that I used emacs to
alphabetically sort all the templates in an XSLT file; and to
a search and replace using regular expressions across
all my XSLT files in several directories. Things like the latter
are not obscure luxuries, they are daily bread and butter.
Can I do them in oXygen?

--
Sebastian Rahtz
Information Manager, Oxford University Computing Services
13 Banbury Road, Oxford OX2 6NN. Phone +44 1865 283431

OSS Watch: JISC Open Source Advisory Service
http://www.oss-watch.ac.uk
=========================================================================
Date:         Fri, 14 Jan 2005 19:37:15 +0000
Reply-To:     Sebastian Rahtz <sebastian.rahtz@COMPUTING-SERVICES.OXFORD.AC.UK>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Sebastian Rahtz <sebastian.rahtz@COMPUTING-SERVICES.OXFORD.AC.UK>
Subject:      Re: Editors and medium-tech people
Comments: To: daniel.odonnell@uleth.ca
In-Reply-To:  <200501141853.j0EIrBl01412@listserv.brown.edu>
MIME-Version: 1.0
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit

Daniel O'Donnell wrote:

>
>When my father
>set up his last notebook over Christmas a year ago, it took him a week
>to get his emacs installation up and running with everything going the
>way he wanted to. That's a pretty serious time investment, although he
>was hobbying rather than working on it solidly.
>
>
to me, that says what an important tool emacs is, and how efficient
and productive a good setup can. I bet your father uses TeX, too!

setting up some simple text editor only takes 5 minutes, because
after 5 minutes you have exhausted its possibilities.

For an example, consider the fact that I use emacs to
alphabetically sort all the templates in an XSLT file; and to
a search and replace using regular expressions across
all my XSLT files in several directories. Things like the latter
are not obscure luxuries, they are daily bread and butter.
Can I do them in oXygen?

--
Sebastian Rahtz
Information Manager, Oxford University Computing Services
13 Banbury Road, Oxford OX2 6NN. Phone +44 1865 283431

OSS Watch: JISC Open Source Advisory Service
http://www.oss-watch.ac.uk
=========================================================================
Date:         Fri, 14 Jan 2005 19:52:46 +0000
Reply-To:     Sebastian Rahtz <sebastian.rahtz@COMPUTING-SERVICES.OXFORD.AC.UK>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Sebastian Rahtz <sebastian.rahtz@COMPUTING-SERVICES.OXFORD.AC.UK>
Subject:      Re: Editors and medium-tech people
Comments: To: Wendell Piez <wapiez@MULBERRYTECH.COM>
In-Reply-To:  <200501141748.j0EHmRl23846@listserv.brown.edu>
MIME-Version: 1.0
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit

Wendell Piez wrote:

>
>Emacs may be great if you have an Emacs guru to hold your hand for a few
>days at the beginning, and perhaps thereafter at odd moments. But if you're
>trying to fly solo ... at least in my case, I wasn't so unhappy with other
>tools (which I was actually able to figure out without having to memorize
>obscure command-key sequences -- BTW I found vi the same way)
>
I learnt Emacs in 1985 or so because I wanted a screen editor that
understood mice,
multiple windows, menus, multiple files etc.  You know, that GUI stuff,
went with the lovely X Windows system we were using on those nice Suns.
The alternative was vi, which I love with a passion still, but
didnt have the GUI. Back then,
what choice did we have? Stupid word-processors like Word
(yes, it was rubbish back then too),
and simple text editors under Windows which simply didn't have
the power or reliability (some of you remember them, too, the ones
which couldn't load a file bigger than 64k).

Learn my myself? as opposed to what? you suck it and see,
and work until you understand it.

>If the aim of the CD is to help the lone wolves -- I wouldn't put my $0.02
>on Emacs. It's like saying "baking is easy! all you have to do is grind the
>flour...." In university settings, it is easy to forget that not everyone
>has a flour mill in the next room.
>
>
can I reiterate, Emacs is on that CD because it is very powerful,
is open source, and can be made to work well with XML,
especially schemas.  I say again, tell me the better editors
to put on there. Show me how to configure Eclipse or JEdit.

>As for editors for medium-tech people -- I still think there's a fine
>market opportunity for a company that wants to distribute a free,
>platform-independent starter-editor that works more like structured editors
>
>
I don't want a starter editor, or a crippled editor, or a demo,
or anything like that. I want a real, production editor, open source.
No compromises.

I'm happy to teach people using oXygen, because its a fine product,
and I think some of the people we teach will find it just the
tool they need, at a good price. But I also want a 100% open
source serious toolkit for other purposes - for instance,
to give away to communities with _no_ software budget

>When getting medium-tech people started with XML, these days I show them
>how to use a GUI plain-text editor (It would probably be BBEdit on Mac, any
>of several on Windows) with external tools, and perhaps demonstrate oXygen
>as a great value for the money, once you are able to take advantage of its
>smorgasbord of features. Of course this doesn't solve the problem for the CD.
>
>
>
and, I argue, does the student a disservice. You teach them using a
simple plain text editor, and put them off markup for life,
because it makes entering XML so hard.

--
Sebastian Rahtz
Information Manager, Oxford University Computing Services
13 Banbury Road, Oxford OX2 6NN. Phone +44 1865 283431

OSS Watch: JISC Open Source Advisory Service
http://www.oss-watch.ac.uk
=========================================================================
Date:         Fri, 14 Jan 2005 15:15:03 -0500
Reply-To:     "Carole E. Mah" <Carole_Mah@BROWN.EDU>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         "Carole E. Mah" <Carole_Mah@BROWN.EDU>
Subject:      Re: Editors and medium-tech people
Comments: cc: TEI-L@LISTSERV.BROWN.ED
In-Reply-To:  <41E8230E.1080507@computing-services.oxford.ac.uk>
MIME-Version: 1.0
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit

I'm not sure I see what's so tough about ramping up with emacs. In my
first few days with it (circa 1989), I got by fine only knowing a few
basic things that were easy enough to learn -- scroll up and down,
forward or back a word or line, add an XML element, validate. You can be
pretty productive only knowing those very few commands, very quickly.
Furthermore I helped teach many humanities students how to use it, and
only a few of them had mental blocks memorizing keystrokes (and for
them, we wrote cheat sheets). Most adapted fine, and the alternative at
the time (Author/Editor) was repugnant and clunky.

-c

--
Carole_Mah@brown.edu
Senior Programmer Analyst
Computing & Information Services
=========================================================================
Date:         Fri, 14 Jan 2005 15:37:09 -0500
Reply-To:     Francois Lachance <lachance@ORIGIN.CHASS.UTORONTO.CA>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Francois Lachance <lachance@ORIGIN.CHASS.UTORONTO.CA>
Subject:      Re: Editors and medium-tech people
In-Reply-To:  <no.id> from "lachance" at Jan 14, 2005 02:16:22 PM
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit

Just testing another assumption...

        Teaching with text editors versus Emacs

Am I correct in assuming the pedagogues were not advocating that students
stay with one set of tools throughout their apprenticeship? There is
pedagogical value in keying text and markup and then validating. It is an
exercise not a recommendation for production. It is also an excercise
that makes students truly appreciate the features of Emacs.


Though Emacs is not pure command line, this article may be of interest to
both those considering modifications for user-friendliness or considering
developing tutorials or tip sheets:

The Command Line - The Best Newbie Interface?
</quote>This essay describes the surprising results of a brief trial with
a group of new computer users about the relative ease of the command line
interface versus the GUIs now omnipresent in computer interfaces. It comes
from practical experience I have of teaching computing to complete
beginners or newbies as computer power-users often term them.</quote?
http://www.osnews.com/story.php?news_id=6282



-- Francois Lachance, Scholar-at-large
http://www.chass.utoronto.ca/~lachance

A calendar is like a map. And just as maps have insets, calendars in the
21st century might have 'moments' expressed in flat local time fanning out
into "great circles" expressed in earth revolution time.
=========================================================================
Date:         Fri, 14 Jan 2005 20:56:28 +0000
Reply-To:     Peter Heslin <public@HESLIN.ECLIPSE.CO.UK>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Peter Heslin <public@HESLIN.ECLIPSE.CO.UK>
Subject:      Re: Editors and medium-tech people

On 2005-01-14, Wendell Piez <wapiez@MULBERRYTECH.COM> wrote:
>  Personally, whenever I tried, I found Emacs difficult to learn -- from
>  installation and maintenance through to operating it.

This is an entirely reasonable perspective, but it's also true that
recent versions of Emacs have become much more newbie-friendly, and
the next version will be more so; e.g it will come with cua-mode
pre-installed, which allows you to select, copy, and paste text in the
way Windows users expect.

Nevertheless, much more could be done.  I have been working on a
beginner-friendly Emacs configuration that I am planning on
distributing.  It will be targeted at non-programmers, and it will
include nxml-mode and the TEI schemata.  I hope that I will be able to
make Emacs behave out of the box more or less just as an average
computer user expects an application to behave -- at least for the
most common editing tasks.

I have most of the work done, and hope to have it finished in a few
months, but I might wait until the next version of Emacs (21.4) is
released, which should be soon, since things will work better and look
nicer under the forthcoming version.

Emacs still has a steep learning curve, but with the right
configuration it can be made much more accessible -- and certainly
accessible to "medium-tech" people.  It's just that typically, it has
expected the user to configure it and to install extra packages.
TEI-Emacs addresses the latter issue, and I hope to address the former.

Peter
=========================================================================
Date:         Fri, 14 Jan 2005 16:07:21 -0500
Reply-To:     "Paul F. Schaffner" <pfs@UMICH.EDU>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         "Paul F. Schaffner" <pfs@UMICH.EDU>
Subject:      Re: Editors and medium-tech people
Comments: To: Sebastian Rahtz <sebastian.rahtz@COMPUTING-SERVICES.OXFORD.AC.UK>
In-Reply-To:  <41E8230E.1080507@computing-services.oxford.ac.uk>
MIME-Version: 1.0
Content-Type: TEXT/PLAIN; charset=US-ASCII

Sebastian wrote:

> For an example, consider the fact that I use emacs to
> alphabetically sort all the templates in an XSLT file; and to
> a search and replace using regular expressions across
> all my XSLT files in several directories. Things like the latter
> are not obscure luxuries, they are daily bread and butter.
> Can I do them in oXygen?

No, but you can in TextPad.

> [Doing markup with text editors] does the student a disservice.
> You teach them using a simple plain text editor, and put
> them off markup for life, because it makes entering XML so hard.

I run a high-volume production shop which employs about
ten full-time editors at the moment; probably another
twenty have passed through on their way to other work.
We do not require that anyone use any particular tool,
and encourage people to find ones they like (we'll even
pay for them)--but we do assume that everyone will have access to
at least two editors: XMetaL and TextPad, which are installed
by default on every workstation. Almost everyone ends up
gravitating to one application or the other, and using
it for 95%+ of their work. Over the years, I've found that about
25% of the people end up using XMetaL almost exclusively;
about 75%  end up using TextPad almost exclusively. I think
the latter group would say that the (regexp) string-manipulation power,
simplicity and transparency of the plain-text editor more than
make up for any supposed difficulty of entering markup. They
have certainly not been put off markup for life, or I hope not.

(Perhaps it is significant that we are mostly revising
markup, sometimes globally, sometimes locally, rather than
entering markup from scratch. And perhaps TextPad doesn't
qualify as a 'simple' text editor?)

Carole Mah wrote:

> The alternative [to Emacs] at the time (Author/Editor) was
> repugnant and clunky.

I started my markup life in 1995 with the same choice, drew the same
conclusions--but was still very glad to abandon Emacs when I could,
almost as glad as I was to abandon Author/Editor. It's
been years since I dared even offer it as a option to my editors.

None of this addresses what belongs on an open-source
distribution, of course, except insofar as it suggests that
you'll never please everybody and might as well not try to!

pfs
--------------------------------------------------------------------
Paul Schaffner | pfs@umich.edu | http://www-personal.umich.edu/~pfs/
316 Hatcher Library N, Univ. of Michigan, Ann Arbor MI 48109-1205
--------------------------------------------------------------------
=========================================================================
Date:         Fri, 14 Jan 2005 21:14:12 +0000
Reply-To:     Sebastian Rahtz <sebastian.rahtz@COMPUTING-SERVICES.OXFORD.AC.UK>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Sebastian Rahtz <sebastian.rahtz@COMPUTING-SERVICES.OXFORD.AC.UK>
Subject:      Re: Editors and medium-tech people
Comments: To: "Paul F. Schaffner" <pfs@umich.edu>
In-Reply-To:  <Pine.SOL.4.58.0501141602060.29166@zektor.gpcc.itd.umich.edu>
MIME-Version: 1.0
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit

Paul F. Schaffner wrote:

>pay for them)--but we do assume that everyone will have access to
>at least two editors: XMetaL and TextPad, which are installed
>by default on every workstation.
>
when did you last review this setup? do you consider
other choices? If you pay people to work hard, and give them
a choice of reasonable tools (as I am sure Textpad and XMetaL are,
though you presumably make them suffer under an insecure,
buggy and slow operating system), of course they'll learn one
or the other and be happy.

>None of this addresses what belongs on an open-source
>distribution, of course, except insofar as it suggests that
>you'll never please everybody and might as well not try to!
>
>
nonetheless, I do have to find _something_ to offer folks......

PS I enjoyed Sharon Creech, Paul ...

--
Sebastian Rahtz
Information Manager, Oxford University Computing Services
13 Banbury Road, Oxford OX2 6NN. Phone +44 1865 283431

OSS Watch: JISC Open Source Advisory Service
http://www.oss-watch.ac.uk
=========================================================================
Date:         Fri, 14 Jan 2005 16:10:32 -0500
Reply-To:     Wendell Piez <wapiez@MULBERRYTECH.COM>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Wendell Piez <wapiez@MULBERRYTECH.COM>
Subject:      Re: Editors and medium-tech people
Comments: To: Sebastian Rahtz <sebastian.rahtz@computing-services.oxford.ac.uk>
In-Reply-To:  <41E8230E.1080507@computing-services.oxford.ac.uk>
Mime-Version: 1.0
Content-Type: text/plain; charset="us-ascii"; format=flowed

Dear Sebastian,

I'm afraid you may have taken my post to be an argument that Emacs
shouldn't be on the CD, or that some other tool should. But I didn't say
any of that.

My aim was rather to stress, perhaps to dramatize, that the argument "it
was good enough for me back in the cave in 1985! it should be good enough
for you!" just doesn't wash. The circumstances in which we learned our
craft -- the lean machines on which we learned discipline, the ingenious
software with its Procrustean idiosyncracies, the lack of supposedly "good
enough" alternatives, the cameraderie with like-minded others that somehow
managed to make Procrustes bearable -- are simply not available to
everyone, even to most or many of those we want to reach.

As for the "real [full-featured], open source editor, no compromises" -- it
would be wonderful if that existed. Assuming by "no compromises" we mean to
include that it should be easy to run and learn as well as easy to dance
with once you've climbed the heights. Maybe in time, if we keep working:
we've made amazing strides in just a few years.

But for now, the Celestial City is still some ways off. Sorry for the bad news.

Regards,
Wendell


======================================================================
Wendell Piez                            mailto:wapiez@mulberrytech.com
Mulberry Technologies, Inc.                http://www.mulberrytech.com
17 West Jefferson Street                    Direct Phone: 301/315-9635
Suite 207                                          Phone: 301/315-9631
Rockville, MD  20850                                 Fax: 301/315-8285
----------------------------------------------------------------------
   Mulberry Technologies: A Consultancy Specializing in SGML and XML
======================================================================
=========================================================================
Date:         Fri, 14 Jan 2005 21:34:34 +0000
Reply-To:     Sebastian Rahtz <sebastian.rahtz@COMPUTING-SERVICES.OXFORD.AC.UK>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Sebastian Rahtz <sebastian.rahtz@COMPUTING-SERVICES.OXFORD.AC.UK>
Subject:      Re: Editors and medium-tech people
Comments: To: Wendell Piez <wapiez@mulberrytech.com>
In-Reply-To:  <6.1.2.0.0.20050114155013.031a3728@earthlink.net>
MIME-Version: 1.0
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit

Wendell Piez wrote:

> wash. The circumstances in which we learned our craft -- the lean
> machines on which we learned

> discipline, the ingenious software with its Procrustean idiosyncracies
>
I still don't get it.  Emacs _never_ seem hard to me, I didn't use it
despite being Procrustean.
I was using a modern powerful machine (Sun, Unix, X Windows, _not_ a
clunky old mainframe) and I found
this brilliant intuitive powerful editor, and I loved it. This was not
the "look what I can with in 32k on
this amazing microprccessor" days.

> As for the "real [full-featured], open source editor, no compromises"
> -- it would be wonderful if that existed.

it does. it's called Eclipse, jEdit, Emacs etc. If I can work out how to
use it. The rest of y'all
have XML Spy, XMetal, oXygen, whatever - but they aren't any easier to
pick up, in
my experience. All these programs are complicated.

>
> But for now, the Celestial City is still some ways off. Sorry for the
> bad news.
>
I am a lot more optimistic than you. I think my open source platform is
already _better_  than the closed source alternatives.

--
Sebastian Rahtz
Information Manager, Oxford University Computing Services
13 Banbury Road, Oxford OX2 6NN. Phone +44 1865 283431

OSS Watch: JISC Open Source Advisory Service
http://www.oss-watch.ac.uk
=========================================================================
Date:         Fri, 14 Jan 2005 16:40:36 -0500
Reply-To:     "Carole E. Mah" <Carole_Mah@BROWN.EDU>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         "Carole E. Mah" <Carole_Mah@BROWN.EDU>
Subject:      Re: Editors and medium-tech people
Comments: To: Sebastian Rahtz <sebastian.rahtz@COMPUTING-SERVICES.OXFORD.AC.UK>
In-Reply-To:  <41E83AEA.4080306@computing-services.oxford.ac.uk>
MIME-Version: 1.0
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit

Sebastian Rahtz wrote:

> I still don't get it.  Emacs _never_ seem hard to me, I didn't use it
> despite being Procrustean.
> I was using a modern powerful machine (Sun, Unix, X Windows, _not_ a
> clunky old mainframe) and I found
> this brilliant intuitive powerful editor, and I loved it. This was not
> the "look what I can with in 32k on
> this amazing microprccessor" days.
ervice
> http://www.oss-watch.ac.uk

I agree. Emacs is not hard to learn -- and I've taught it to completely
non-tech people, humanities undergrads, for example, who don't have much
trouble, especially with the common availability of XWindows/XFree86.

Of course emacs should be on the CD.

-c


--
Carole_Mah@brown.edu
Senior Programmer Analyst
Computing & Information Services
=========================================================================
Date:         Fri, 14 Jan 2005 16:22:26 -0500
Reply-To:     Wendell Piez <wapiez@MULBERRYTECH.COM>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Wendell Piez <wapiez@MULBERRYTECH.COM>
Subject:      Re: Editors and medium-tech people
In-Reply-To:  <41E81F5F.7060708@computing-services.oxford.ac.uk>
Mime-Version: 1.0
Content-Type: text/plain; charset="us-ascii"; format=flowed

At 02:37 PM 1/14/2005, you wrote:
>For an example, consider the fact that I used emacs to
>alphabetically sort all the templates in an XSLT file; and to
>a search and replace using regular expressions across
>all my XSLT files in several directories. Things like the latter
>are not obscure luxuries, they are daily bread and butter.
>Can I do them in oXygen?

The first: no, but you can write a transform to do it. (Also they're very
good about responding to feature requests: they even have a development
budget.)

The second: yes.

But what's the point? oXygen isn't freeware (which is how they get their
development budget), and hence fails the acid test.

Cheers,
Wendell


======================================================================
Wendell Piez                            mailto:wapiez@mulberrytech.com
Mulberry Technologies, Inc.                http://www.mulberrytech.com
17 West Jefferson Street                    Direct Phone: 301/315-9635
Suite 207                                          Phone: 301/315-9631
Rockville, MD  20850                                 Fax: 301/315-8285
----------------------------------------------------------------------
   Mulberry Technologies: A Consultancy Specializing in SGML and XML
======================================================================
=========================================================================
Date:         Fri, 14 Jan 2005 16:54:27 -0500
Reply-To:     Wendell Piez <wapiez@MULBERRYTECH.COM>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Wendell Piez <wapiez@MULBERRYTECH.COM>
Subject:      Re: Editors and medium-tech people
Comments: To: Francois Lachance <lachance@ORIGIN.CHASS.UTORONTO.CA>
In-Reply-To:  <200501142037.PAA05318@origin.chass.utoronto.ca>
Mime-Version: 1.0
Content-Type: text/plain; charset="us-ascii"; format=flowed

Thanks again, Francois,

At 03:37 PM 1/14/2005, Francois Lachance wrote:
>Am I correct in assuming the pedagogues were not advocating that students
>stay with one set of tools throughout their apprenticeship?

I can't speak for anyone else, but part of what I am trying to urge is
precisely that they should not! Indeed, I think that's one of the most
important lessons we have to teach -- that one need not, and should not,
stay locked in one carriage, no matter how well upholstered it may be.

Part of the reason is precisely that you get stuck in the mud so quickly
when forced by circumstances to proceed another way. (And it can be quite
comical watching people reflexively trying to use Emacs keyboarding in
other environments! :-)

Sorry to make fun of all you Emaximizers, at the risk of spoiling yours.
(And Emacs is way fun, I hear.) Think of it as the return of the repressed. :->

Cheers,
Wendell


======================================================================
Wendell Piez                            mailto:wapiez@mulberrytech.com
Mulberry Technologies, Inc.                http://www.mulberrytech.com
17 West Jefferson Street                    Direct Phone: 301/315-9635
Suite 207                                          Phone: 301/315-9631
Rockville, MD  20850                                 Fax: 301/315-8285
----------------------------------------------------------------------
   Mulberry Technologies: A Consultancy Specializing in SGML and XML
======================================================================
=========================================================================
Date:         Fri, 14 Jan 2005 17:00:54 -0500
Reply-To:     Wendell Piez <wapiez@MULBERRYTECH.COM>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Wendell Piez <wapiez@MULBERRYTECH.COM>
Subject:      Re: Editors and medium-tech people
Comments: To: Peter Heslin <public@HESLIN.ECLIPSE.CO.UK>
In-Reply-To:  <cs9bls$ljc$1@sea.gmane.org>
Mime-Version: 1.0
Content-Type: text/plain; charset="us-ascii"; format=flowed

Peter,

This is awesome. It could get us much closer to that Celestial City.

At 03:56 PM 1/14/2005, you wrote:
>This is an entirely reasonable perspective, but it's also true that
>recent versions of Emacs have become much more newbie-friendly, and
>the next version will be more so; e.g it will come with cua-mode
>pre-installed, which allows you to select, copy, and paste text in the
>way Windows users expect.

Ironically, ctrl-c, ctrl-x, ctrl-v, ctrl-z are part of what I have no
problem with. They're practically ubiquitous in text editors these days.

>It's just that typically, it has
>expected the user to configure it and to install extra packages.

That's been the worst part in my experience. I once had two esteemed markup
gurus wrangling horribly with each other over how Emacs should be installed
on my machine, so I could try it and see how great it was. Two
co-religionists arguing over environment variables! Embarrassing for all of
us. If the experiment had been successful, I might be arguing the other
side of this debate.

>TEI-Emacs addresses the latter issue, and I hope to address the former.

It's good news and I'm sure Sebastian is listening.

Cheers,
Wendell


======================================================================
Wendell Piez                            mailto:wapiez@mulberrytech.com
Mulberry Technologies, Inc.                http://www.mulberrytech.com
17 West Jefferson Street                    Direct Phone: 301/315-9635
Suite 207                                          Phone: 301/315-9631
Rockville, MD  20850                                 Fax: 301/315-8285
----------------------------------------------------------------------
   Mulberry Technologies: A Consultancy Specializing in SGML and XML
======================================================================
=========================================================================
Date:         Fri, 14 Jan 2005 15:21:40 -0700
Reply-To:     daniel.odonnell@uleth.ca
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Daniel O'Donnell <daniel.odonnell@ULETH.CA>
Organization: Department of English, University of Lethbridge
Subject:      TAN: Those damn emacs codes (was: Re: Editors and medium-tech
              people)
Comments: To: Wendell Piez <wapiez@MULBERRYTECH.COM>
In-Reply-To:  <200501142212.j0EMChl29453@listserv.brown.edu>
MIME-Version: 1.0
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit

I think to be honest we're all pretty more pushing against open doors.
Easy to setup, intuitive gui-based superpowerful and modifiable software
is great. And the various solutions we've all be discussing have aspects
of that ideal. And life goes on.

For my last 2 cents worth:

The emacs sequence I have trouble with is Save current buffer: Cx-Cs. I
do that by habit for save in all programs and have to keep an eye out I
don't accidentally cut data out of something. Mostly its not a problem,
but its been really bad the last little while while I've been doing a
lot in Open Office's spread sheet. I keep deleting cell contents before
saving the sheet.

An interesting discussion.
-dan


Wendell Piez wrote:
> Peter,
>
> This is awesome. It could get us much closer to that Celestial City.
>
> At 03:56 PM 1/14/2005, you wrote:
>
>>This is an entirely reasonable perspective, but it's also true that
>>recent versions of Emacs have become much more newbie-friendly, and
>>the next version will be more so; e.g it will come with cua-mode
>>pre-installed, which allows you to select, copy, and paste text in the
>>way Windows users expect.
>
>
> Ironically, ctrl-c, ctrl-x, ctrl-v, ctrl-z are part of what I have no
> problem with. They're practically ubiquitous in text editors these days.
>
>
>>It's just that typically, it has
>>expected the user to configure it and to install extra packages.
>
>
> That's been the worst part in my experience. I once had two esteemed markup
> gurus wrangling horribly with each other over how Emacs should be installed
> on my machine, so I could try it and see how great it was. Two
> co-religionists arguing over environment variables! Embarrassing for all of
> us. If the experiment had been successful, I might be arguing the other
> side of this debate.
>
>
>>TEI-Emacs addresses the latter issue, and I hope to address the former.
>
>
> It's good news and I'm sure Sebastian is listening.
>
> Cheers,
> Wendell
>
>
> ======================================================================
> Wendell Piez                            mailto:wapiez@mulberrytech.com
> Mulberry Technologies, Inc.                http://www.mulberrytech.com
> 17 West Jefferson Street                    Direct Phone: 301/315-9635
> Suite 207                                          Phone: 301/315-9631
> Rockville, MD  20850                                 Fax: 301/315-8285
> ----------------------------------------------------------------------
>    Mulberry Technologies: A Consultancy Specializing in SGML and XML
> ======================================================================

--
Daniel Paul O'Donnell, PhD
Associate Professor of English
University of Lethbridge
Lethbridge AB T1K 3M4
Tel. (403) 329-2377
Fax. (403) 382-7191
E-mail <daniel.odonnell@uleth.ca>
Home Page <http://people.uleth.ca/~daniel.odonnell/>
The Digital Medievalist Project: <http://www.digitalmedievalist.org/>
=========================================================================
Date:         Fri, 14 Jan 2005 22:39:21 +0000
Reply-To:     Peter Heslin <public@HESLIN.ECLIPSE.CO.UK>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Peter Heslin <public@HESLIN.ECLIPSE.CO.UK>
Subject:      Re: TAN: Those damn emacs codes (was: Re: Editors and medium-tech
              people)

On 2005-01-14, Daniel O'Donnell <daniel.odonnell@uleth.ca> wrote:
>  The emacs sequence I have trouble with is Save current buffer:
>  Cx-Cs.

In the Emacs configuration I'm developing, I am trying to eliminate
chords (keystroke sequences) for most common editing tasks.  At the
moment I have an "extreme" configuration that binds safe-buffer to
Ctrl-s, which is "save file" in many (most?) applications, and I also
have a different, less extreme configuration that binds it to F1,
leaving Ctrl-s free for its default meaning of isearch-forward.

I'm still not sure whether to make the "extreme" configuration the
default or not.  Easier to get started with, but harder to interface
with the rest of the Emacs world, where Ctrl-s stands for "search",
rather than "save".

Peter
=========================================================================
Date:         Fri, 14 Jan 2005 20:04:27 -0700
Reply-To:     daniel.odonnell@uleth.ca
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Daniel O'Donnell <daniel.odonnell@ULETH.CA>
Organization: Department of English, University of Lethbridge
Subject:      including TEI subsets in an xsl:output
MIME-Version: 1.0
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit

I'm sure I should be able to see this somewhere, but either I'm too
tired or it doesn't come up in any of the references I've looked at:

How does one get xslt to produce a doctype with the tei internal dtd
subset entities included? I.e. I want to produce a tei doctype of the
following form:

<!DOCTYPE TEI.2
   PUBLIC "-//TEI P4//DTD Main Document Type//EN"
   "c:/tei-emacs/xml/dtds/tei/tei2.dtd" [
<!ENTITY % TEI.XML 'INCLUDE'>

<!-- BASE TAG SET DECLARATION (TEI P4 3.2-3.3) -->
<!ENTITY % TEI.verse 'INCLUDE' >

<!-- ADDITIONAL TAG SET DECLARATION (TEI P4 3.2-3.3) -->
<!ENTITY % TEI.transcr 'INCLUDE' >
<!ENTITY % TEI.textcrit 'INCLUDE' >
<!ENTITY % TEI.linking 'INCLUDE' >
<!ENTITY % TEI.analysis 'INCLUDE' >
<!ENTITY % TEI.figures 'INCLUDE' >

<!-- USER DEFINED TAG SET DECLARATIONS (TEI P4 3.2.4 User-Defined Tag
Sets) -->
<!ENTITY % TEI.extensions.ent SYSTEM "../extensions/extensions.ent">
<!ENTITY % TEI.extensions.dtd SYSTEM "../extensions/extensions.dtd">


]>

Using the xsl:output (or other appropriate xsl element.

I can produce

<!DOCTYPE TEI.2
   PUBLIC "-//TEI P4//DTD Main Document Type//EN"
   "c:/tei-emacs/xml/dtds/tei/tei2.dtd"/>

Using the following xsl

<xsl:output
   method="xml"
   encoding="UTF-8"
   doctype-public="-//TEI P4//DTD Main Document Type//EN"
   doctype-system="c:/tei-emacs/xml/dtds/tei/tei2.dtd"/>

But I can't get the entities (let alone the comments) in nohow. I've
gone through the xslt standard and examples in Tidwell and the XML
bible. I've checked my terminology in P4 and the XML standard. I would
imagine there is an xsl:output attribute that handles this, but unless
it is staring me in the face and I'm over looking it, I can't see what
it is.

Suggestions?

-dan

--
Daniel Paul O'Donnell, PhD
Associate Professor of English
University of Lethbridge
Lethbridge AB T1K 3M4
Tel. (403) 329-2377
Fax. (403) 382-7191
E-mail <daniel.odonnell@uleth.ca>
Home Page <http://people.uleth.ca/~daniel.odonnell/>
The Digital Medievalist Project: <http://www.digitalmedievalist.org/>
=========================================================================
Date:         Sat, 15 Jan 2005 14:42:08 +0900
Reply-To:     Christian Wittern <wittern@KANJI.ZINBUN.KYOTO-U.AC.JP>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Christian Wittern <wittern@KANJI.ZINBUN.KYOTO-U.AC.JP>
Subject:      Re: Editors and medium-tech people
Comments: To: Wendell Piez <wapiez@MULBERRYTECH.COM>
In-Reply-To:  <6.1.2.0.0.20050113185306.03289ae0@earthlink.net> (Wendell Piez's
              message of "Fri, 14 Jan 2005 12:37:53 -0500")
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii

It looks like its the time of the year where threads wander off and
off and never come back.  And today I have enough other pressing
business so that I can use an excuse to join in...

Wendell Piez <wapiez@MULBERRYTECH.COM> writes:

> At 04:07 AM 1/13/2005, Sebastian wrote:
>>I've used Emacs for 20 years now and have never read through
>>the manual or any books about it :-}
>
> I think this admission is very revealing. Partly by what Sebastian doesn't
> tell us about how he learned. He and other power-users might say more about
> this. Particularly of interest in this context would be to get a sense of
> proportionally how many Emacs users learned with other Emacs users at their
> elbow, say in an office, classroom or lab, versus those who taught
> themselves in more isolated settings.
>
>
> So, has anyone managed to teach *themselves* Emacs, with the manuals and
> online help only, from installation through mode-configuration through XML
> parsing to schema and stylesheet development?

That's what I did, but it was a long story.  I first heard of / tried
Emacs in the early 90's, probably 92 or 93.  Since then I have
regularily tried / given up on it for various reasons, most of them
related to the fact that it was difficult to do East-Asian
multilingual processing with Emacs the way I think it should be done
(using Unicode, that is). Around 2000 I was finally convinced that
Emacs developed to a state where this could be done (although even
today I would not claim it is easy) and started using it.  Mind you,
no expert I knew of within earshot or anywhere I could reach, but
Usenet was in reach and I used it extensively.  Thanks to all kind
souls on comp.emacs etc. I managed to get up and running with it.  The
first weeks were really hard; I had a list of the most frequently used
commands beside my desk and had to browse through it and try to figure
out how they would call search-and-replace or moving the insertion
point to the beginning of the file.  A few weeks into it, I started
actually being productive and it did not take long until I switched
most of the daily tasks, including email reading, text writing file
management to specialized emacs buffers.  Only a few months later did
I teach XML using Emacs for the first time and I have done it regularily
since then.

The pedagogic objective here is to me not just teaching the concepts
related to Markup and text processing, but also getting the students
out of the narrow mindset and conceptual tunnel of using badly
designed GUI tools.  Some find this very hard and never quite recover
from the first shock, but most are pleased to have such a powerful
tool at their disposal.  And yes, you can get by with Emacs keystrokes
at more and more places out there, including bash, Mozilla & friends,
GNOME etc.  And no, I do not think it would be helpful to have the
keystrokes adapted to make the transition from ctrl-c ctrl-v easier.
It seems much more efficient in the long run to get used to the
standard keystrokes (although on Mac OS X this means that whenever I
want to copy something with M-w, the window gets closed :-(; this will
make life in Emacsland much easier in the long run.

Back to work then,

All the best,

Christian

--

 Christian Wittern
 Institute for Research in Humanities, Kyoto University
 47 Higashiogura-cho, Kitashirakawa, Sakyo-ku, Kyoto 606-8265, JAPAN
=========================================================================
Date:         Sat, 15 Jan 2005 09:36:18 +0000
Reply-To:     Sebastian Rahtz <sebastian.rahtz@COMPUTING-SERVICES.OXFORD.AC.UK>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Sebastian Rahtz <sebastian.rahtz@COMPUTING-SERVICES.OXFORD.AC.UK>
Subject:      Re: including TEI subsets in an xsl:output
Comments: To: daniel.odonnell@uleth.ca
In-Reply-To:  <200501150304.j0F34gl20678@listserv.brown.edu>
MIME-Version: 1.0
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit

Daniel O'Donnell wrote:

>How does one get xslt to produce a doctype with the tei internal dtd
>subset entities included? I.e. I want to produce a tei doctype of the
>following form:
>
><!DOCTYPE TEI.2
>   PUBLIC "-//TEI P4//DTD Main Document Type//EN"
>   "c:/tei-emacs/xml/dtds/tei/tei2.dtd" [
><!ENTITY % TEI.XML 'INCLUDE'>
>
>
<xsl:text disable-output-escaping="yes">&lt;!DOCTYPE ... [ &lt;! ENTITY
.... &gt; </xsl:text>

its dirty, and has disadvantages, but its the only way you can do it

--
Sebastian Rahtz
Information Manager, Oxford University Computing Services
13 Banbury Road, Oxford OX2 6NN. Phone +44 1865 283431

OSS Watch: JISC Open Source Advisory Service
http://www.oss-watch.ac.uk
=========================================================================
Date:         Sat, 15 Jan 2005 10:05:09 -0000
Reply-To:     Michael Beddow <mbteil-2@mbeddow.net>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Michael Beddow <mbteil-2@MBEDDOW.NET>
Subject:      Re: including TEI subsets in an xsl:output
MIME-Version: 1.0
Content-Type: text/plain; charset="iso-8859-1"
Content-Transfer-Encoding: 7bit

> How does one get xslt to produce a doctype with the tei internal dtd
> subset entities included?

To do that you have to use a facility that XSLTers speak of only with shifty
gaze and shuffling feet, it at all. Those of a delicate disposition might
like to skip the next line

the disable-output-escaping attribute on <xsl:text>

There, I said it.

To see a practical example, grab Sebastian's OpenOffice filters from
http://www.tei-c.org/Software/teioo/ and look at his sheet called
oo-to-teioucs.xsl, the first part of the first (master) template) up to but
not including the part where he puts the opening <TEI.2> tag into the
output. He's pulling the actual entity declarations out of the OO source
document, which isn't applicable to your case, but what matters is the
"packaging" of the declarations in a syntax that has to be smuggled past the
XSLT serialiser, so you should be able to adapt this technique to your
needs.

That said, the reason why people don't talk about d-o-e is that it appears
to offer an easy way out for certain other problems that learners of XSLT
encounter, but if they take that way out, they end up working against the
language and the processor rather than learning how to master it. However,
there are some rare circumstances where d-o-e is the only way, and writing
out things that the XSLT specifiers decided there was no need to support
(the imminent death of DTD's and general entities being even in those days
the subject of considerably exaggerated reporting) is one of them.

Michael Beddow
=========================================================================
Date:         Sat, 15 Jan 2005 14:35:21 -0500
Reply-To:     Francois Lachance <lachance@ORIGIN.CHASS.UTORONTO.CA>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Francois Lachance <lachance@ORIGIN.CHASS.UTORONTO.CA>
Subject:      Re: including TEI subsets in an xsl:output
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit

Would any of the TEI-list participants know if any of the extensions to
the XSLT processors such as Saxon offer such functionality? If they don't
exist would writing an extension to control doctype declaration output be
a little project that computer science students might take on?

Given as Michael put it

> there are some rare circumstances where d-o-e is the only way, and writing
> out things that the XSLT specifiers decided there was no need to support
> (the imminent death of DTD's and general entities being even in those days
> the subject of considerably exaggerated reporting) is one of them.


--
Francois Lachance, Scholar-at-large
http://www.chass.utoronto.ca/~lachance

A calendar is like a map. And just as maps have insets, calendars in the
21st century might have 'moments' expressed in flat local time fanning out
into "great circles" expressed in earth revolution time.
=========================================================================
Date:         Sat, 15 Jan 2005 19:40:12 +0000
Reply-To:     Lou Burnard <lou.burnard@COMPUTING-SERVICES.OXFORD.AC.UK>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Lou Burnard <lou.burnard@COMPUTING-SERVICES.OXFORD.AC.UK>
Subject:      editorialDecl content model
MIME-Version: 1.0
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit

Warning! This message is about content models in TEI DTDs (and schemas)
for P5. It may be unsuitable for patients with low-geek-talk tolerance
or on an emacs-free diet!

I have just noticed something weird  about the content model for
editorialDecl. In every edition since P3, it has been defined as ((p+) |
(  (correction|normalization|quotation|
hyphenation|interpretation|segmentation|stdVals)+, p*))

The intention of this was presumably to allow editorialDecl to contain
*either* plain paras of prose, *or* one or more of the more specialized
elements in the alternation above (nowadays they'd be in a class, of
course), but with the curious wrinkle that paragraphs could also be
interspersed between  the more specialised elements (henceforth MSEs).
So you could have
<correction/><correction/><p/><normalization/>, for example.

Leaving aside for the moment whether or not this promiscuity is a good
thing, the curious thing I have now noticed is that one of its less
desirable side effects is to make it very easy indeed to make the
content model non-detrministic. If, for example, you decide to simplify
the TEI scheme, the chances are that you will want to axe the MSEs
completely. But if you just remove them from the content model, you will
wind up with (p+|p*) which is decidedly not comme il faut.

Wondering why the content model is that way, rather than  say
(p|(&mse;))+ I can only assume it is because the TEI editors of the time
wanted to support both paragraphs-only and  mse-only  models, but with
the option of  paragraphs floating about within them.  This sort of
wishywashy shillyshallying has been the source of many subsequent
headaches and (as I bear 50% of the responsibility ) I plan to atone for
it by clearing this one up. Removing the trailing optional paragraphs is
obvious and easy. But what I can't decide is whether the correct model
should be
(a) The laid-back (p| %tei.editorial;)+   or
(b) The stalinist   (p+ | (%tei.editorial;)+)

Does anyone care? Method (a) will break fewer existing documents. In
fact, come to think of it, it won't break any documents at all, which
method (b) definitely will. On the other hand, method (b) is more
consistent with decisions taken elsewhere, e.g. in the manuscripts module.
=========================================================================
Date:         Sat, 15 Jan 2005 20:09:13 +0000
Reply-To:     Sebastian Rahtz <sebastian.rahtz@COMPUTING-SERVICES.OXFORD.AC.UK>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Sebastian Rahtz <sebastian.rahtz@COMPUTING-SERVICES.OXFORD.AC.UK>
Subject:      Re: including TEI subsets in an xsl:output
Comments: To: Francois Lachance <lachance@ORIGIN.CHASS.UTORONTO.CA>
In-Reply-To:  <200501151924.j0FJOpl01783@listserv.brown.edu>
MIME-Version: 1.0
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit

Francois Lachance wrote:

>Would any of the TEI-list participants know if any of the extensions to
>the XSLT processors such as Saxon offer such functionality?
>
I believe not.

>If they don't
>exist would writing an extension to control doctype declaration output be
>a little project that computer science students might take on?
>
>
If you have one to spare, quite possibly. but since it _can_ be done
with D-O-E, is it worth the effort? I know D-O-E is evil in general,
but this seems a benign use of it.

--
Sebastian Rahtz
Information Manager, Oxford University Computing Services
13 Banbury Road, Oxford OX2 6NN. Phone +44 1865 283431

OSS Watch: JISC Open Source Advisory Service
http://www.oss-watch.ac.uk
=========================================================================
Date:         Sat, 15 Jan 2005 23:20:26 -0500
Reply-To:     Francois Lachance <lachance@ORIGIN.CHASS.UTORONTO.CA>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Francois Lachance <lachance@ORIGIN.CHASS.UTORONTO.CA>
Subject:      Extensions was (Re: including TEI subsets in an xsl:ouput)
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit

I do regret if I gave offense. I did not mean to suggest that the very
fine solution offered in the XSLT files created by Sebastian ought to be
replaced by extensions to an XSLT processor. No doubt under the spell of
the Emacs power to the max thread, I was merely suggesting a worthy and
manageable project for a budding developer or group of developers.

I am grateful to Michael Beddow's reference to the XSLT files created by
Sebastian. It has given me the idea to modify my past practice. My
processing being very modest in scale, I imported a template that
contained the doctype declaration and the entity declaration wrapped in a
CDATA section. By adapting Sebastian's more modular approach, I can
contemplate xsl:text elements with d-o-e as useful for managing lists of
file names for NDATA (e.g. image and audio files).

Recalling Michael's remarks about XML and the postulated shrinking away of
the state of the DTD was useful in reviewing the influence of XML parsers
on the output of the XSLT function unparsed-entity-uri().  Depending upon
the parser, if the system identifier is a relative URI it may or may not
be expanded. Of course under P5, the introduction of a "URL" attribute
offers greater control over the handling of references to unparsed data, a
solution born I believe from collective experience with P4 extensions.

P5 beckons. But the leap form DTDs to Schemata??


> >Would any of the TEI-list participants know if any of the extensions to
> >the XSLT processors such as Saxon offer such functionality?
> >
> I believe not.
>
> >If they don't
> >exist would writing an extension to control doctype declaration output be
> >a little project that computer science students might take on?


> If you have one to spare, quite possibly. but since it _can_ be done
> with D-O-E, is it worth the effort? I know D-O-E is evil in general,
> but this seems a benign use of it.
>
> --
> Sebastian Rahtz
> Information Manager, Oxford University Computing Services
> 13 Banbury Road, Oxford OX2 6NN. Phone +44 1865 283431
>
> OSS Watch: JISC Open Source Advisory Service
> http://www.oss-watch.ac.uk


--
Francois Lachance, Scholar-at-large
http://www.chass.utoronto.ca/~lachance

A calendar is like a map. And just as maps have insets, calendars in the
21st century might have 'moments' expressed in flat local time fanning out
into "great circles" expressed in earth revolution time.
=========================================================================
Date:         Sun, 16 Jan 2005 06:10:12 -0500
Reply-To:     Patrick.Durusau@sbl-site.org
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Patrick Durusau <pdurusau@EMORY.EDU>
Subject:      Re: editorialDecl content model
Comments: To: Lou Burnard <lou.burnard@COMPUTING-SERVICES.OXFORD.AC.UK>
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii; format=flowed
Content-Transfer-Encoding: 7bit

Lou,

Interesting question.

Lou Burnard wrote:
> Warning! This message is about content models in TEI DTDs (and schemas)
> for P5. It may be unsuitable for patients with low-geek-talk tolerance
> or on an emacs-free diet!
>
<snip>

> Wondering why the content model is that way, rather than  say
> (p|(&mse;))+ I can only assume it is because the TEI editors of the time
> wanted to support both paragraphs-only and  mse-only  models, but with
> the option of  paragraphs floating about within them.  This sort of
> wishywashy shillyshallying has been the source of many subsequent
> headaches and (as I bear 50% of the responsibility ) I plan to atone for
> it by clearing this one up. Removing the trailing optional paragraphs is
> obvious and easy. But what I can't decide is whether the correct model
> should be
> (a) The laid-back (p| %tei.editorial;)+   or
> (b) The stalinist   (p+ | (%tei.editorial;)+)
>
> Does anyone care? Method (a) will break fewer existing documents. In
> fact, come to think of it, it won't break any documents at all, which
> method (b) definitely will. On the other hand, method (b) is more
> consistent with decisions taken elsewhere, e.g. in the manuscripts module.
>

Seems to me that (b) presents the user with a choice of being completely
unconstrained, p+, or following the slightly more structured form of
tei.editorial. (I say slightly more structured as the content model for
all the components of tei.editorial is tei.paragraph.)

Well, actually there is the third option of extending the content model
of tei.editorial to add elements for editorial decisions thought to have
been overlooked by the editors.

I really don't see any advantage to allowing users to mix a minimally
contstrained set of elements for editorial principles with paragraph
elements.

Actually, option (a) is an ad hoc means of extending the content model
of tei.editorial without making the necessary declarations.

That is to say that I can use the elements of tei.editorial and when I
wish to have additional elements, for practices I think have been
overlooked, I simply toss in some p elements. But there is no way for
you to know what editorial practices are described in those p elements
short of reading them.

I don't mind having the option for p elements only. It would be useful
for first pass encoding where someone else will be entering the more
precise elements at a later stage.

Bottom line, I would go with (b).

Hope you are having a great day!

Patrick

--
Patrick Durusau
Director of Research and Development
Society of Biblical Literature
Patrick.Durusau@sbl-site.org
Chair, V1 - Text Processing: Office and Publishing Systems Interface
Co-Editor, ISO 13250, Topic Maps -- Reference Model

Topic Maps: Human, not artificial, intelligence at work!
=========================================================================
Date:         Sun, 16 Jan 2005 12:48:38 -0500
Reply-To:     Francois Lachance <lachance@ORIGIN.CHASS.UTORONTO.CA>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Francois Lachance <lachance@ORIGIN.CHASS.UTORONTO.CA>
Subject:      editorialDecl content model
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit

Lou et al.,

<Wink> Warning: Emacs is not mentioned in the response below. I
undertstand that mention of Emacs was optional and repeatable but not
required.  </wink>

> I have just noticed something weird  about the content model for
> editorialDecl. In every edition since P3, it has been defined as ((p+) |
> (  (correction|normalization|quotation|
> hyphenation|interpretation|segmentation|stdVals)+, p*))
>
> The intention of this was presumably to allow editorialDecl to contain
> *either* plain paras of prose, *or* one or more of the more specialized
> elements in the alternation above (nowadays they'd be in a class, of
> course), but with the curious wrinkle that paragraphs could also be
> interspersed between  the more specialised elements (henceforth MSEs).
> So you could have
> <correction/><correction/><p/><normalization/>, for example.

**********

The report on the curious wrinkle suggests that there are two questions at
play: that of the repeatability of the more specialized elements and that
of interspersed paragraphs. There may be only one:
<correction/><correction/><p/><normalization/> is not valid
<correction/><correction/><normalization/> is valid

Could it be that the intention was to have paragraphs _or_ the more
specialized elements followed by none or some optional paragraphs? I ask
this question because of the head/body design of so many of the TEI
content groups. I also ask this because of the parser responses to
validation usings the current content model for editorialDecl.

Not valid, paragraphs before the more specialized elements (if they are
present):
<p/><quotation/>

Not valid, paragraphs before and following the more specialized elements:
<p/><quotation/><p/>

And for similar reasons the interstitial paragraphs do not validate, that
is unnested parapraphs between the more specialized elements:
<quotation/><p/><p/><hyphenation/>
The parser reads any number of <p/> between the more specialized elements
as occuring before the subsquent more specialized element and declares it
invalid.

What is valid is the case of one or more of the more specialized elements
followed by one or more paragraphs:
<quotation/><hyphenation/><p/><p/>

The occurence indicator (that plus sign) on the content group for the
specialized elements produces some interesting result. It allows  user  to
encode one or more of the specialized elements. And to encode more than
one occurence of the same more specialized element.
<quotation/><quotation/><hyphenation/><p/><p/>

"Eek!", you say.

Just get rid of the plus sign? That poses a quandry. In the case where
there is no occurence indicator on that particular content group, a user
could only encode one of the more specialized elements since the elements
in that particular content group are separated by the "or" connector
("|").

The presence of an occurence indicator indicating one or more of the
elements may be present in a valid document instance along with the
connector meaning only one of the alternatives can be used seems to
translate an intention whereby the encoder could create a valid document
instance using the more specialized elements in a mix and match fashion,
that is choosing whatever combination suits their purpose. For example, a
user can encode <quotation> and <hyphenation> without <interpretation> and
without <normalization>. Furthermore  the order of appearance of the more
specialized elements is not fixed by the DTD, <hyphenation> can appear
before <quotation> in a valid document instance.

But what of the repeatability of any of the more specialized elements?
SGML does allow permit the DTD writer to restrict repeatability.

<!ELEMENT editorialDecl
((correction?, normalization?, quotation?, hyphenation?, interpretation?,
segmentation?, stdVals?), p*))
>Compared with the current P4 content model, hat is lost in this content
model is the flexibility in positioning.  If <segmentation> and
<correction> are both present, the must respect the sequence written in
the DTD. The change from the "or" connector ("|") to the "sequence"
connector (",") and the elimination of the  (p+) content group from the
element declaration are necessary to avoid an ambiguous declaration. It
allows all the current P4 element declaration allows and restricts
positioning and repeatability of the more specialized elements.

Now, the very interesting question. Was it the intent of the editors to
allow multiple instances of the same more specialized elements within an
<editorialDecl> element? From the internal evidence of the DTD, I would
argue, yes. The DTD allows from more than one <editorialDecl> element to
be present in a valid document instance. Very handy for recording the
editiorial practices of different editors. I would be on surer ground if
the attribute list declaration for the <editorialDecl> element contained a
"resp" attribute. It doesn't. And neither do the more specialized
elements. If the "resp" attribute were declared, I could see that the
repeatability was intended to allow a space for recording different
practices. Of course, linking mechanisms are available and encoders can
link the elements in question to the appropriate child of a <respStmt>
element.

Granted imagining a use case is not a guarantee of reconstructed intent.
However it is a test of the soundness of the content model. I would
therefore like to suggest that P5 retain the content model currently
present in P4 (in the interests of minimizing breakage) and that an
inheritable "resp" attribute be declared for <editorialDecl>.

 --
Francois Lachance, Scholar-at-large http://www.chass.utoronto.ca/~lachance

A calendar is like a map. And just as maps have insets, calendars in the
21st century might have 'moments' expressed in flat local time fanning out
into "great circles" expressed in earth revolution time.
=========================================================================
Date:         Sun, 16 Jan 2005 17:46:04 +0000
Reply-To:     Lou Burnard <lou.burnard@COMPUTING-SERVICES.OXFORD.AC.UK>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Lou Burnard <lou.burnard@COMPUTING-SERVICES.OXFORD.AC.UK>
Subject:      Re: editorialDecl content model
Comments: To: Francois Lachance <lachance@ORIGIN.CHASS.UTORONTO.CA>
In-Reply-To:  <200501161738.j0GHc9l20726@listserv.brown.edu>
MIME-Version: 1.0
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit

The repeatability of the specialized elements is there  because of the
(very real) need to support more than one policy of a particular kind
e.g. in a corpus where sets of texts were encoded by different groups of
people. The specialized elements are all members of the "declarable"
class, for the same purpose. See the discussion at 23.3.2 in P4

Your examples nicely demonstrate that, whatever the trailing p* was
intended to achieve, it doesn't do much of it!

 Francois Lachance wrote:

>Lou et al.,
>
><Wink> Warning: Emacs is not mentioned in the response below. I
>undertstand that mention of Emacs was optional and repeatable but not
>required.  </wink>
>
>
>
>>I have just noticed something weird  about the content model for
>>editorialDecl. In every edition since P3, it has been defined as ((p+) |
>>(  (correction|normalization|quotation|
>>hyphenation|interpretation|segmentation|stdVals)+, p*))
>>
>>T
>>
=========================================================================
Date:         Sun, 16 Jan 2005 14:01:23 -0500
Reply-To:     Syd_Bauman@Brown.edu
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Syd Bauman <Syd_Bauman@BROWN.EDU>
Subject:      Re: editorialDecl content model
In-Reply-To:  <41E9719C.4010205@computing-services.oxford.ac.uk>
MIME-Version: 1.0
Content-Type: multipart/mixed; boundary="uxf9lv745n"
Content-Transfer-Encoding: 7bit

--uxf9lv745n
Content-Type: text/plain; charset=us-ascii
Content-Description: message body text
Content-Transfer-Encoding: 7bit

DTD content model of <editorialDecl> with whitespace for readability:
   (
      (p+)
    |
      (
        ( correction | normalization | quotation | hyphenation
          | interpretation | segmentation | stdVals )+,
        p*
      )
   )

Lou, you're concerned about the "curious wrinkle" that paragraphs can
be interspersed between MSEs. I humbly submit that this is simply not
the case -- <p> elements can not be interspersed with MSEs using this
content model.

Test case attached below as an appendix.


> If, for example, you decide to simplify the TEI scheme, the chances
> are that you will want to axe the MSEs completely. But if you just
> remove them from the content model, you will wind up with (p+|p*)
> which is decidedly not comme il faut.

Yes, if when customizing a TEI DTD you were to remove all of the
MSEs, you would also have to redeclare <editorialDecl> itself if you
were using DTDs. (This is not a problem for P5 when it is used with
RelaxNG, which permits "(p+|p*)"; the problem is that the software
that generates DTDs for us is not smart enough to reduce "(p+|p*)" to
"(p+)"; don't know about W3C XML Schemas yet.)


> Wondering why the content model is that way, rather than say
> (p|(&mse;))+ ...

*This* content model *does* permit <p> in between MSEs.


> ... I can only assume it is because the TEI editors of the time
> wanted to support both paragraphs-only and mse-only models, but
> with the option of paragraphs floating about within them.

The reasoning as explained to me circa 1995 (IIRC) was to provide
both paragraph-only and MSE models, with the realization that the TEI
could not possibly predict all of the more specialized types of
information encoders would want to record. Thus if an encoder were
using the MSE approach, but wanted to discuss a topic not covered by
the TEI pre-made MSEs, she could tack a <p> on after the MSEs.


> Removing the trailing optional paragraphs is obvious and easy.

Perhaps, but I don't think it is a good idea, unless their
functionality is somehow replaced.[1]


> But what I can't decide is whether the correct model should be
> (a) The laid-back (p| %tei.editorial;)+

Evil. It permits <p> to be interspersed among the MSEs, which should
not happen, IMHO.


> (b) The stalinist   (p+ | (%tei.editorial;)+)

Preferable to (a), but worse than the current content model.


> Method (a) ... won't break any documents at all, which method (b)
> definitely will.

It will only break documents that have trailing <p>s after MSEs.


> On the other hand, method (b) is more consistent with decisions
> taken elsewhere, e.g. in the manuscripts module.

And is simply, I would suggest, better practice in the recording of
structured information.


Note
----
[1] Having a trailing element "<otherEdDec>" (or some such) to
    contain the <p>s would be one such solution.

Appendix
--------
This attached file demonstrates that <p>s are not permitted to
intersperse with MSEs against standard, current, vanilla TEI P4 DTD.


--uxf9lv745n
Content-Type: text/xml
Content-Description: test of <editorialDecl> -- WARNING: this file is invalid
Content-Disposition: inline;
        filename="edDecT.xml"
Content-Transfer-Encoding: 7bit

<?xml version="1.0" encoding="UTF-8" ?>
<!DOCTYPE encodingDesc SYSTEM "http://www.tei-c.org/P4X/DTD/tei2.dtd" [
  <!ENTITY % TEI.XML     'INCLUDE' >
  <!ENTITY % TEI.prose   'INCLUDE' >
]>
<encodingDesc>

  <editorialDecl n="valid">
    <!-- series of <p>s -->
    <p>...</p>
    <p>...</p>
    <p>...</p>
  </editorialDecl>

  <editorialDecl n="valid">
    <!-- series of MSEs (any order OK) -->
    <correction>
      <p>...</p>
    </correction>
    <correction default="YES">
      <p>...</p>
    </correction>
    <hyphenation>
      <p>...</p>
    </hyphenation>
    <normalization>
      <p>...</p>
    </normalization>
  </editorialDecl>

  <editorialDecl n="valid">
    <!-- series of MSEs (any order OK), with trailing <p>s -->
    <correction>
      <p>...</p>
    </correction>
    <correction default="YES">
      <p>...</p>
    </correction>
    <hyphenation>
      <p>...</p>
    </hyphenation>
    <normalization>
      <p>...</p>
    </normalization>
    <p>...</p>
    <p>...</p>
  </editorialDecl>

  <editorialDecl n="INVALID">
    <!-- MSEs with interspersed <p>s -->
    <correction>
      <p>...</p>
    </correction>
    <correction>
      <p>...</p>
    </correction>
    <p>...</p>
    <normalization>
      <p>...</p>
    </normalization>
  </editorialDecl>

</encodingDesc>

--uxf9lv745n--
=========================================================================
Date:         Sun, 16 Jan 2005 14:21:32 -0500
Reply-To:     Francois Lachance <lachance@ORIGIN.CHASS.UTORONTO.CA>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Francois Lachance <lachance@ORIGIN.CHASS.UTORONTO.CA>
Subject:      Re: editorialDecl content model
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit

Ah the trailing paragraph... or what could be called the "addendum"
paragraph.

Indeed its presence in an <editorialDecl> element, doesn't do much from
the perspective of machine processing of Declarable Elements. The
Guidelines at 5.3.3 are indeed silent about the purpose of one or more <p>
elements following at least one or more of the declarable elements.

It is conceivable that such <p> elements provide information for the human
reader. One use case might indeed be to explain which combinations of
repeated declarable elements are at work for what puroposes.

If the DTD were modified to eliminate its use, then encoders
wishing to annotate some aspect of the <editorialDecl> element would
have to do so outside that element and create a link (or alternatively
use comments). A machine processing the declarable elements could be
instructed to simply ignore the additional <p> elements that follow?

I note in passing that if the DTD were modified so that "ID" and "DEFAULT"
attributes were required on all declarable elements (yes this is verbose
for single instances of any given declarable element), the one aspect of
the declarable elements mechanism that validation by DTD could not check
is the value of the "DEFAULT" attribute (i.e. one and only one "y"
value for the encoded alterntives). Hello Schemata!



> The repeatability of the specialized elements is there  because of the
> (very real) need to support more than one policy of a particular kind
> e.g. in a corpus where sets of texts were encoded by different groups of
> people. The specialized elements are all members of the "declarable"
> class, for the same purpose. See the discussion at 23.3.2 in P4
>
> Your examples nicely demonstrate that, whatever the trailing p* was
> intended to achieve, it doesn't do much of it!

I don't think my original post speculated as to what content may or may
not be contained by the containers nor how such contained content could,
should or would be related to the content contained in other containers.
I was reading the content model in terms of the relations between
containers. I was thinking of the head and body pattern evident in many of
the TEI elements. Although I did not explicity state it, I implied that a
certain analogy exists between the head-body pattern and the content model
for <editoiralDecl> which forces a choice between <p> elements only or
declarable elements followed by <p> elements. It can be headless (all <p>
elements>, all head (all declarable elements), or with head and body
(declarable elements followed by <p> elements).


--
Francois Lachance, Scholar-at-large
http://www.chass.utoronto.ca/~lachance

A calendar is like a map. And just as maps have insets, calendars in the
21st century might have 'moments' expressed in flat local time fanning out
into "great circles" expressed in earth revolution time.
=========================================================================
Date:         Sun, 16 Jan 2005 19:27:53 +0000
Reply-To:     Lou Burnard <lou.burnard@COMPUTING-SERVICES.OXFORD.AC.UK>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Lou Burnard <lou.burnard@COMPUTING-SERVICES.OXFORD.AC.UK>
Subject:      Re: editorialDecl content model
Comments: To: Syd_Bauman@BROWN.EDU
In-Reply-To:  <200501161901.j0GJ1cl25426@listserv.brown.edu>
MIME-Version: 1.0
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit

Thanks for the correction, Syd. You are right: I had  misread or
misremembered the effect (if not the intention) of the trailing p*.
However,  I still think it should go. If its purpose is to enable the
addition of new unforeseen MSEs, then the best way to do it is to add a
new element to the class (which I have, by the way, now defined); though
an alternative  better way would also be to allow (as you suggest) some
other element -- say <note> -- to be used along with the other MSEs.

The consensus being apparently against intertwingling of ps and MSEs,
I've now changed the content model (in P5) to
<rng:choice>
  <rng:oneOrMore><rng:ref name="p"/></rng:oneOrMore>
  <rng:oneOrMore><rng:ref name="tei.policy"/></rng:oneOrMore>
</rng:choice>
where the new class tei.policy contains the <normalisation> etc.
elements as before.
We could add <note> to this class, perhaps, or define a new element for
the purpose I suppose.

Syd Bauman wrote:

>--uxf9lv745n
>Content-Type: text/plain; charset=us-ascii
>Content-Description: message body text
>Content-Transfer-Encoding: 7bit
>
>DTD content model of <editorialDecl> with whitespace for readability:
>   (
>      (p+)
>    |
>      (
>        ( correction | normalization | quotation | hyphenation
>          | interpretation | segmentation | stdVals )+,
>        p*
>      )
>   )
>
>Lou, you're concerned about the "curious wrinkle" that paragraphs can
>be interspersed between MSEs. I humbly submit that this is simply not
>the case -- <p> elements can not be interspersed with MSEs using this
>content model.
>
>Test case attached below as an appendix.
>
>
>
>
>>If, for example, you decide to simplify the TEI scheme, the chances
>>are that you will want to axe the MSEs completely. But if you just
>>remove them from the content model, you will wind up with (p+|p*)
>>which is decidedly not comme il faut.
>>
>>
>
>Yes, if when customizing a TEI DTD you were to remove all of the
>MSEs, you would also have to redeclare <editorialDecl> itself if you
>were using DTDs. (This is not a problem for P5 when it is used with
>RelaxNG, which permits "(p+|p*)"; the problem is that the software
>that generates DTDs for us is not smart enough to reduce "(p+|p*)" to
>"(p+)"; don't know about W3C XML Schemas yet.)
>
>
>
>
>>Wondering why the content model is that way, rather than say
>>(p|(&mse;))+ ...
>>
>>
>
>*This* content model *does* permit <p> in between MSEs.
>
>
>
>
>>... I can only assume it is because the TEI editors of the time
>>wanted to support both paragraphs-only and mse-only models, but
>>with the option of paragraphs floating about within them.
>>
>>
>
>The reasoning as explained to me circa 1995 (IIRC) was to provide
>both paragraph-only and MSE models, with the realization that the TEI
>could not possibly predict all of the more specialized types of
>information encoders would want to record. Thus if an encoder were
>using the MSE approach, but wanted to discuss a topic not covered by
>the TEI pre-made MSEs, she could tack a <p> on after the MSEs.
>
>
>
>
>>Removing the trailing optional paragraphs is obvious and easy.
>>
>>
>
>Perhaps, but I don't think it is a good idea, unless their
>functionality is somehow replaced.[1]
>
>
>
>
>>But what I can't decide is whether the correct model should be
>>(a) The laid-back (p| %tei.editorial;)+
>>
>>
>
>Evil. It permits <p> to be interspersed among the MSEs, which should
>not happen, IMHO.
>
>
>
>
>>(b) The stalinist   (p+ | (%tei.editorial;)+)
>>
>>
>
>Preferable to (a), but worse than the current content model.
>
>
>
>
>>Method (a) ... won't break any documents at all, which method (b)
>>definitely will.
>>
>>
>
>It will only break documents that have trailing <p>s after MSEs.
>
>
>
>
>>On the other hand, method (b) is more consistent with decisions
>>taken elsewhere, e.g. in the manuscripts module.
>>
>>
>
>And is simply, I would suggest, better practice in the recording of
>structured information.
>
>
>Note
>----
>[1] Having a trailing element "<otherEdDec>" (or some such) to
>    contain the <p>s would be one such solution.
>
>Appendix
>
>
=========================================================================
Date:         Mon, 17 Jan 2005 11:25:14 +0000
Reply-To:     Peter Flynn <pflynn@UCC.IE>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Peter Flynn <pflynn@UCC.IE>
Organization: University College Cork
Subject:      Re: Editors and medium-tech people
In-Reply-To:  <6.1.2.0.0.20050113185306.03289ae0@earthlink.net>
Content-Type: text/plain
Mime-Version: 1.0
Content-Transfer-Encoding: 7bit

On Fri, 2005-01-14 at 17:37, Wendell Piez wrote:
> At 04:07 AM 1/13/2005, Sebastian wrote:
> >I've used Emacs for 20 years now and have never read through
> >the manual or any books about it :-}
>
> I think this admission is very revealing. Partly by what Sebastian doesn't
> tell us about how he learned. He and other power-users might say more about
> this. Particularly of interest in this context would be to get a sense of
> proportionally how many Emacs users learned with other Emacs users at their
> elbow, say in an office, classroom or lab, versus those who taught
> themselves in more isolated settings.

I learned Emacs in the late 80s and early 90s when returning to Unix
systems after a brief flirtation with DOS. I didn't find it particularly
difficult to install, as I was using SunOS and I downloaded binaries
and stuck with the default or "expected" directories for everything.
Even OEmacs, which ran on DOS, was basically an unzip operation and a
little file-moving. The knowledge of how to do this was pretty much
expected from computer users in those days who had probably grown up
on command-lines. Getting it working on VMS, however, proved to be so
hard I gave up :-)

> Personally, whenever I tried, I found Emacs difficult to learn -- from
> installation and maintenance through to operating it.

Learning the basic keystrokes was not a problem: there is a limited
subset of what a new user wants to do, and at that time we hadn't yet
acquired the current "foreknowledge" of what a GUI expects the user
to know (^C, ^V, ^X, etc). But the documentation sucked, as it expected
the user to be a programmer or CS student, so I had to write my own
version when I came to teach other users. Getting across the concept
that this is not a typographic editor was not hard, but most of our
users were editing markup at a very deep level, where a typographic
editor (A/E at the time) was more of a hindrance than a benefit. Most
of them switched between A/E (for transcribing actual texts) and Emacs
(for editing the detail of the markup).

> them to an autodidactic approach. (Here I disagree with Sebastian -- it's
> not text editors in general: most are way easier to learn than Emacs.)

That's because a large part of the "learning" has been done for you
before you start, by learning the operations which drive the surrounding
GUI (WIMPS, for example). It's only very recently that it has become
possible in some typographic editors to select a word by double-click
without including the trailing space, a "feature" which leads the
newcomer to all sorts of interesting paradoxes like "what exactly *is*
an italic space?" as in <title>Ulysses </title>

> Emacs may be great if you have an Emacs guru to hold your hand for a few
> days at the beginning, and perhaps thereafter at odd moments.

Doing almost anything completely new without access to some degree of
support is going to cause pain. I would have great sympathy for anyone
who *has* to learn Emacs purely from a document, but certainly over the
last decade this has become far less relevant with the accessibility of
network-based help (this list, for example).

> As for editors for medium-tech people -- I still think there's a fine
> market opportunity for a company that wants to distribute a free,
> platform-independent starter-editor that works more like structured editors
> (XMetaL etc.) than free-form text editors with tools support (which are
> also a must-have). XMetaL itself (which isn't free) and Altova Authentic
> (which is, though it comes with other strings) are almost there -- but are
> both locked into Windows. Particularly if the free version were crippleware
> (say, you'd have to upgrade to the next level to get out of TEI-Lite), I
> think this is a viable business proposition. But I'm not in the software
> business.

I agree there is a vacancy for such software. I think companies don't
see this because their (much more lucrative) market is the e-commerce
[ab]use of XML. Text document editing is an area in which the default
paradigm (Word) has engendered a specific mind-set and a set of user
expectations which conflict with the requirements of editing structured
text, especially in a rigorous framework such as XML (whence the topic
of my PhD). XMetaL and Authentic are indeed close, but both suffer from
a number of modal difficulties which confuse the user, and from the
blind compulsion to produce Instant Textual Gratification[tm] (aka
WYSIWYG) which has bedevilled all the other attempts to date. Until
we know how users have acquired the assorted curious beliefs with which
they approach the editing of structured text, and what those beliefs
really are, we cannot hope to build an interface which will handle them.

> When getting medium-tech people started with XML, these days I show them
> how to use a GUI plain-text editor (It would probably be BBEdit on Mac, any
> of several on Windows) with external tools, and perhaps demonstrate oXygen
> as a great value for the money, once you are able to take advantage of its
> smorgasbord of features.

I also show them a plaintext (non-XML) editor, and immediately afterward
show them Emacs, as an example of plaintext-with-XML, and then follow
that with any of the WYSIAYFWG editors. Most of them immediately see the
benefits of a typographical interface with markup display turned off,
for editing the text itself. Once they grasp the fact that formatting
the XML encoding is not the same thing as producing a typographically
formatted rendition, they also see that editing the markup in Emacs is
significantly easier that doing the same in the typographical editors.

But this doesn't help the fact that to do so, they have to learn Emacs.

[Incidentally, in the earlier stages of my research I dissected the
interfaces of some 20 XML editors, and found that almost every one of
them provided the identical set of about 50 markup-based operations.
Perhaps unsurprising, given that these operations can be deduced to
be required in order to enable or ease the editing of markup to
conformance with SGML/XML, but instructive that "all XML editors have
the same set of markup-editing features" no matter what the marketing
or proselytisation blurb says. Among the very few missing features
was the oddity that Emacs/psgml/xxml has a "split element" command
but no "join-element-to-preceding-of-the-same-type" command.]

///Peter
=========================================================================
Date:         Mon, 17 Jan 2005 10:09:23 -0500
Reply-To:     Syd_Bauman@Brown.edu
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Syd Bauman <Syd_Bauman@BROWN.EDU>
Subject:      Re: editorialDecl content model
In-Reply-To:  <41EAC039.2080108@computing-services.oxford.ac.uk>
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit

> The consensus being apparently against intertwingling of ps and
> MSEs, I've now changed the content model (in P5) to
> <rng:choice>
>   <rng:oneOrMore><rng:ref name="p"/></rng:oneOrMore>
>   <rng:oneOrMore><rng:ref name="tei.policy"/></rng:oneOrMore>
> </rng:choice>
> where the new class tei.policy contains the <normalisation> etc.
> elements as before. We could add <note> to this class, perhaps, or
> define a new element for the purpose I suppose.

I'm of a mixed mind on this. On the one hand, if the purpose of the
<note> is to replace (and I daresay improve upon) the functionality
of the trailing <p>s in P4, and if we presume that if we find there
are lots of people who want a trailing <note type="blort"> in the
<editorialDecl> that is evidence that a new <blort> element should be
created for the tei.policy class, then trailing <note>s seems to make
the most sense, either grouped with MSEs as with P4:

<rng:choice>
  <rng:oneOrMore><rng:ref name="p"/></rng:oneOrMore>
  <rng:group>
    <rng:oneOrMore><rng:ref name="tei.policy"/></rng:oneOrMore>
    <rng:zeroOrMore><rng:ref name="note"/></rng:zeroOrMore>
  </rng:group>
</rng:choice>

or permitted whether MSEs or series of <p> is used:

<rng:choice>
  <rng:oneOrMore><rng:ref name="p"/></rng:oneOrMore>
  <rng:oneOrMore><rng:ref name="tei.policy"/></rng:oneOrMore>
</rng:choice>
<rng:zeroOrMore><rng:ref name="note"/></rng:zeroOrMore>

However, because <note> happens to be the all-purpose annotation
element, I actually think it should be in some global class that is
allowed anywhere, anyway.

So perhaps I'm leaning towards a new element that is more specific
than <note>, but more general than any of the current tei.policy
elements. With a type=, of course. Perhaps "<policy>". (Then the
question arises, should the <p>s in, say, <samplingDecl> remain <p>
or become <policy>?)
=========================================================================
Date:         Mon, 17 Jan 2005 08:34:33 -0700
Reply-To:     daniel.odonnell@uleth.ca
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Daniel O'Donnell <daniel.odonnell@ULETH.CA>
Organization: Department of English, University of Lethbridge
Subject:      Mixed content and tei
MIME-Version: 1.0
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit

Hi all,
        I have a question that came up on the xsl list in response to a
question of mine.
        I'd been asking about sorting for a list and gave them the following
fragment:

 >><list>
 >>   <item>head-a
 >>     <list>
 >>       <item>subfield1-a
 >>         <list>
 >>           <item>subfield2-a, <seg type="locater">locater1</item>
 >>         </list>
 >>       </item>
 >>       <item>subfield1-b
 >>         <list>
 >>           <item>subfield2-g, <seg type="locater">locater2</item></item>
 >>           <item>subfield2-h, <seg type="locater">locater3</item></item>
 >>         </list>
 >>       </item>
 >>     </list>
 >>   </item>
 >>   <item>head-b
 >>     <list>
 >>       <item>subfield1-x, <seg type="locater">locater4</seg></item>
 >>     </list>
 >>   </item>
 >>   <item>head-c
 >>   </item>
 >></list>


One of the people who responded noted that he found my use of mixed
content on item to be "strange".

Is it? I confess in SGML, I always liked to avoid mixed content, but I'm
not aware of any prohibition against the above (or even suggestion that
it is not good practice. Am I wrong?
-dan
--
Daniel Paul O'Donnell, PhD
Associate Professor of English
University of Lethbridge
Lethbridge AB T1K 3M4
Tel. (403) 329-2377
Fax. (403) 382-7191
E-mail <daniel.odonnell@uleth.ca>
Home Page <http://people.uleth.ca/~daniel.odonnell/>
The Digital Medievalist Project: <http://www.digitalmedievalist.org/>
=========================================================================
Date:         Mon, 17 Jan 2005 12:08:17 -0500
Reply-To:     Francois Lachance <lachance@ORIGIN.CHASS.UTORONTO.CA>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Francois Lachance <lachance@ORIGIN.CHASS.UTORONTO.CA>
Subject:      Re: editorialDecl content model
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit

In watching the discussion between Syd and Lou, I wonder about the
relationship between a content model and an ontology. That is between an
ontology and its possible representations. I ask because I believe that
XPATH has perhaps made more widespread the discourse of children,
siblings, ancestors, etc. and that this influences what may be termed the
tension at the core of information interchange between the fetishization
of machine processing and the desire to provide affordances for human
readers.

I ask because I'm not convinced that a new element is needed in the case
of <p> elements as children of the <editorialDecl> with declarable
elements as siblings. My thinking on this is influenced by a rereading of
Section 23 of the Guidelines as suggested by Lou.

As children of an <editorialDecl> those so-called "trailing" <p> elements
can be linked through the "decls" attribute to a relevant portion of the
document instance. That is where the functionality resides: in the
linking, not in the name of the element. The generic container is already
there in the content model.

The declarable elements mechanism reminds me of the feature structure
system. It works by way of matrices. That is how one exploits the finesse
of the mechanism for representing combinations.

The declarable elements mechanism covers three cases:

        all <p> elements as children of a <editorialDecl> element

        all declarable elements as children of a <editorialDecl> element

        declarable elements as children followed by <p> elements of a
        <editorialDecl> element

As well the content model provides for the presence of more than one
<editorialDecl> element in a document instance.

That is a pretty elegant mechanism. Why break it?

        in the case of all <p> elements
        only one "decls" attribute to reference <editorialDecl>

        in the case of all declarable elements
        one "decls" attribute to reference <editorialDecl>
        plus "decls" attribute to reference each of the declarable
        elements

        in the case of declarable elements plus <p> elements
        one "decls" attribute to reference <editorialDecl>
        plus "decls" attribute to reference each of the declarable
        [same as all declarable elements]
        [the <p> elements serve in a sense as an expansion slot]


Function and ontology: when is what a <p> element does what a <p> element
is?



> > The consensus being apparently against intertwingling of ps and
> > MSEs, I've now changed the content model (in P5) to
> > <rng:choice>
> >   <rng:oneOrMore><rng:ref name="p"/></rng:oneOrMore>
> >   <rng:oneOrMore><rng:ref name="tei.policy"/></rng:oneOrMore>
> > </rng:choice>
> > where the new class tei.policy contains the <normalisation> etc.
> > elements as before. We could add <note> to this class, perhaps, or
> > define a new element for the purpose I suppose.
>
> I'm of a mixed mind on this. On the one hand, if the purpose of the
> <note> is to replace (and I daresay improve upon) the functionality
> of the trailing <p>s in P4, and if we presume that if we find there
> are lots of people who want a trailing <note type="blort"> in the
> <editorialDecl> that is evidence that a new <blort> element should be
> created for the tei.policy class, then trailing <note>s seems to make
> the most sense, either grouped with MSEs as with P4:
>
> <rng:choice>
>   <rng:oneOrMore><rng:ref name="p"/></rng:oneOrMore>
>   <rng:group>
>     <rng:oneOrMore><rng:ref name="tei.policy"/></rng:oneOrMore>
>     <rng:zeroOrMore><rng:ref name="note"/></rng:zeroOrMore>
>   </rng:group>
> </rng:choice>
>
> or permitted whether MSEs or series of <p> is used:
>
> <rng:choice>
>   <rng:oneOrMore><rng:ref name="p"/></rng:oneOrMore>
>   <rng:oneOrMore><rng:ref name="tei.policy"/></rng:oneOrMore>
> </rng:choice>
> <rng:zeroOrMore><rng:ref name="note"/></rng:zeroOrMore>
>
> However, because <note> happens to be the all-purpose annotation
> element, I actually think it should be in some global class that is
> allowed anywhere, anyway.
>
> So perhaps I'm leaning towards a new element that is more specific
> than <note>, but more general than any of the current tei.policy
> elements. With a type=, of course. Perhaps "<policy>". (Then the
> question arises, should the <p>s in, say, <samplingDecl> remain <p>
> or become <policy>?)
>


--
Francois Lachance, Scholar-at-large
http://www.chass.utoronto.ca/~lachance

A calendar is like a map. And just as maps have insets, calendars in the
21st century might have 'moments' expressed in flat local time fanning out
into "great circles" expressed in earth revolution time.
=========================================================================
Date:         Mon, 17 Jan 2005 17:13:26 +0000
Reply-To:     Lou Burnard <lou.burnard@COMPUTING-SERVICES.OXFORD.AC.UK>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Lou Burnard <lou.burnard@COMPUTING-SERVICES.OXFORD.AC.UK>
Subject:      Re: Mixed content and tei
Comments: To: daniel.odonnell@uleth.ca
In-Reply-To:  <200501171535.j0HFZLl27843@listserv.brown.edu>
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii; format=flowed
Content-Transfer-Encoding: 7bit

I think many people would say that mixed content like this is not best
practice, even though it is permitted by the TEI content models. It
makes processing more complex and error prone: whitespace rules can come
and bite you when you least expect them to.

Moreover, thinking about the floating bit of text you've called
"head-a", "subfield-a" etc below, it seems to me that it isn't just
prose content of the item. It performs the same function for the rest of
the <item> as <head> does for an enclosing <div>. The mechanism provided
in the TEI for this kind of thing is the gloss type list. So I would
rather tag your example
<list type="gloss">
  <label>head-a</label>
   <item>
    <list type="gloss">
      <label>subfield1-a</label>
      <item> subfield2-a, <ptr target="#locater1"/></item>
    </list>
   </item>
   <label>subfield1-b</label>
   <item>
     <list>
     <item>subfield2-g, <ptr target="#locater2"/></item>
     <item>subfield2-h, <ptr target="#locater3"/></item>
     </list>
    </item>
etc.

But I may have completely missed your point here -- that's the trouble
with too much abstraction. Note that your example is not wellformed:
I've taken the liberty of turning your <seg type="locater"> into a plain
old P5-style pointer, since I assume that's what it is meant.


Daniel O'Donnell wrote:

> Hi all,
>         I have a question that came up on the xsl list in response to a
> question of mine.
>         I'd been asking about sorting for a list and gave them the following
> fragment:
>
>  >><list>
>  >>   <item>head-a
>  >>     <list>
>  >>       <item>subfield1-a
>  >>         <list>
>  >>           <item>subfield2-a, <seg type="locater">locater1</item>
>  >>         </list>
>  >>       </item>
>  >>       <item>subfield1-b
>  >>         <list>
>  >>           <item>subfield2-g, <seg type="locater">locater2</item></item>
>  >>           <item>subfield2-h, <seg type="locater">locater3</item></item>
>  >>         </list>
>  >>       </item>
>  >>     </list>
>  >>   </item>
>  >>   <item>head-b
>  >>     <list>
>  >>       <item>subfield1-x, <seg type="locater">locater4</seg></item>
>  >>     </list>
>  >>   </item>
>  >>   <item>head-c
>  >>   </item>
>  >></list>
>
>
> One of the people who responded noted that he found my use of mixed
> content on item to be "strange".
>
> Is it? I confess in SGML, I always liked to avoid mixed content, but I'm
> not aware of any prohibition against the above (or even suggestion that
> it is not good practice. Am I wrong?
> -dan
> --
> Daniel Paul O'Donnell, PhD
> Associate Professor of English
> University of Lethbridge
> Lethbridge AB T1K 3M4
> Tel. (403) 329-2377
> Fax. (403) 382-7191
> E-mail <daniel.odonnell@uleth.ca>
> Home Page <http://people.uleth.ca/~daniel.odonnell/>
> The Digital Medievalist Project: <http://www.digitalmedievalist.org/>
>
=========================================================================
Date:         Mon, 17 Jan 2005 10:25:57 -0700
Reply-To:     daniel.odonnell@uleth.ca
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Daniel O'Donnell <daniel.odonnell@ULETH.CA>
Organization: Department of English, University of Lethbridge
Subject:      Re: Mixed content and tei
Comments: To: Lou Burnard <lou.burnard@COMPUTING-SERVICES.OXFORD.AC.UK>
In-Reply-To:  <200501171713.j0HHDml06460@listserv.brown.edu>
MIME-Version: 1.0
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit

Lou Burnard wrote:
> I think many people would say that mixed content like this is not best
> practice, even though it is permitted by the TEI content models. It
> makes processing more complex and error prone: whitespace rules can come
> and bite you when you least expect them to.

Good. I've always preferred tagging everything for exactly these
reasons. Glad to know I wasn't being stupid.

>
> Moreover, thinking about the floating bit of text you've called
> "head-a", "subfield-a" etc below, it seems to me that it isn't just
> prose content of the item. It performs the same function for the rest of
> the <item> as <head> does for an enclosing <div>. The mechanism provided
> in the TEI for this kind of thing is the gloss type list. So I would
> rather tag your example

Good observation. The list is actually supposed to be an index with up
to three levels. For this reason the only change I'd make to your
suggestion would be to label the subfield2s as <label> as well.

> <list type="gloss">
>   <label>head-a</label>
>    <item>
>     <list type="gloss">
>       <label>subfield1-a</label>
>       <item> subfield2-a, <ptr target="#locater1"/></item>
>     </list>
>    </item>
>    <label>subfield1-b</label>
>    <item>
>      <list>
>      <item>subfield2-g, <ptr target="#locater2"/></item>
>      <item>subfield2-h, <ptr target="#locater3"/></item>
>      </list>
>     </item>
> etc.
>


> But I may have completely missed your point here -- that's the trouble
> with too much abstraction. Note that your example is not wellformed:
> I've taken the liberty of turning your <seg type="locater"> into a plain
> old P5-style pointer, since I assume that's what it is meant.

Yes it was a typos. Thanks.
>
>
> Daniel O'Donnell wrote:
>
>
>>Hi all,
>>        I have a question that came up on the xsl list in response to a
>>question of mine.
>>        I'd been asking about sorting for a list and gave them the following
>>fragment:
>>
>> >><list>
>> >>   <item>head-a
>> >>     <list>
>> >>       <item>subfield1-a
>> >>         <list>
>> >>           <item>subfield2-a, <seg type="locater">locater1</item>
>> >>         </list>
>> >>       </item>
>> >>       <item>subfield1-b
>> >>         <list>
>> >>           <item>subfield2-g, <seg type="locater">locater2</item></item>
>> >>           <item>subfield2-h, <seg type="locater">locater3</item></item>
>> >>         </list>
>> >>       </item>
>> >>     </list>
>> >>   </item>
>> >>   <item>head-b
>> >>     <list>
>> >>       <item>subfield1-x, <seg type="locater">locater4</seg></item>
>> >>     </list>
>> >>   </item>
>> >>   <item>head-c
>> >>   </item>
>> >></list>
>>
>>
>>One of the people who responded noted that he found my use of mixed
>>content on item to be "strange".
>>
>>Is it? I confess in SGML, I always liked to avoid mixed content, but I'm
>>not aware of any prohibition against the above (or even suggestion that
>>it is not good practice. Am I wrong?
>>-dan
>>--
>>Daniel Paul O'Donnell, PhD
>>Associate Professor of English
>>University of Lethbridge
>>Lethbridge AB T1K 3M4
>>Tel. (403) 329-2377
>>Fax. (403) 382-7191
>>E-mail <daniel.odonnell@uleth.ca>
>>Home Page <http://people.uleth.ca/~daniel.odonnell/>
>>The Digital Medievalist Project: <http://www.digitalmedievalist.org/>
>>

--
Daniel Paul O'Donnell, PhD
Associate Professor of English
University of Lethbridge
Lethbridge AB T1K 3M4
Tel. (403) 329-2377
Fax. (403) 382-7191
E-mail <daniel.odonnell@uleth.ca>
Home Page <http://people.uleth.ca/~daniel.odonnell/>
The Digital Medievalist Project: <http://www.digitalmedievalist.org/>
=========================================================================
Date:         Tue, 18 Jan 2005 11:45:51 +1300
Reply-To:     Conal Tuohy <Conal.Tuohy@VUW.AC.NZ>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Conal Tuohy <Conal.Tuohy@VUW.AC.NZ>
Subject:      Re: Editors and medium-tech people
MIME-Version: 1.0
Content-Type: text/plain; charset="iso-8859-1"
Content-Transfer-Encoding: 8bit

Peter Flynn wrote:

> [Incidentally, in the earlier stages of my research I dissected the
> interfaces of some 20 XML editors, and found that almost every one of
> them provided the identical set of about 50 markup-based operations.
> Perhaps unsurprising, given that these operations can be deduced to
> be required in order to enable or ease the editing of markup to
> conformance with SGML/XML, but instructive that "all XML editors have
> the same set of markup-editing features" no matter what the marketing
> or proselytisation blurb says. Among the very few missing features
> was the oddity that Emacs/psgml/xxml has a "split element" command
> but no "join-element-to-preceding-of-the-same-type" command.]

That's very interesting. Is your research published anywhere? Is this part of your PhD thesis?

To chime in on the "text editors" thread:

I only recently picked up emacs for the first time, and I didn't really take to it, although it has some neat features which I did like. I think because of its venerable history it has a rather dated and inconsistent UI. The default keyboard shortcuts are all "wrong" for my fingers, which have long ago learnt other shortcuts. I would often search when I meant to save, or I'd select some text with the mouse, and press the backspace key, or press [esc] when I wanted to cancel out of something. This kind of thing is hugely annoying because it's a subconscious thing that's hard to control - I know what I'm doing wrong, but my fingers have other ideas. I'm sure it's possible to reconfigure it to behave more as I'd expect, and I'm sure I could learn to use it effectively with enough practice, but instead I've taken up using JEdit for my XML markup.

JEdit has XML validation and tag completion, etc. Incidentally there's also a nice plug-in for XPath searching; where for instance you can search for "//figure[count(.//name)>1]" to find <figure> elements containing more than 1 <name> element. Because JEdit is Java, it has a better integration with the OS's UI conventions, which I appreciate. I haven't written any plugins (yet), but if I had to I'd be able to do so more easily in Java than in Lisp, where my skills are pretty minimal.

My 2c.

Con
=========================================================================
Date:         Mon, 17 Jan 2005 21:42:52 -0500
Reply-To:     David Sewell <dsewell@VIRGINIA.EDU>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         David Sewell <dsewell@VIRGINIA.EDU>
Subject:      Schema for back-of-the-book indexes (Was: Re: [TEI-L] Mixed
              content and tei)
In-Reply-To:  <41EBF525.507@uleth.ca>
MIME-Version: 1.0
Content-Type: TEXT/PLAIN; charset=US-ASCII; format=flowed

On Mon, 17 Jan 2005, Daniel O'Donnell wrote:

> Good observation. The list is actually supposed to be an index with up
> to three levels. For this reason the only change I'd make to your
> suggestion would be to label the subfield2s as <label> as well.

The TEI Guidelines don't offer anything really well tailored to marking
up a back-of-the-book index. Coincidentally, I've been working on a
special-purpose schema for indexes. When finished, it will be used for
repurposing a large number of existing b-o-t-b indexes essentially by
turning them into metadata used to point into TEI versions of the
original volumes. So I'm much less concerned with preserving the format
and appearance of the print index than with preserving all the data it
contains.

I'm developing this as a Relax NG schema. It can be converted to a W3C
schema but not to a DTD (and there wouldn't be much point because the
assumption is you want to use data type checking as a validation
control when converting indexes).

Work in progress is viewable here:

         http://lister.ei.virginia.edu/~drs2n/Index-draft/

It's probably reasonably close to being able to handle the various
components of indexes as defined in the Chicago Manual, though my
original intent wasn't to produce a universally applicable schema.

DS

--
David Sewell, Editorial and Technical Manager
Electronic Imprint, The University of Virginia Press
PO Box 400318, Charlottesville, VA 22904-4318 USA
Courier: 310 Old Ivy Way, Suite 302, Charlottesville VA 22903
Email: dsewell@virginia.edu   Tel: +1 434 924 9973
=========================================================================
Date:         Tue, 18 Jan 2005 01:20:58 -0500
Reply-To:     Jelks Cabaniss <jelks@JELKS.NU>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Jelks Cabaniss <jelks@JELKS.NU>
Subject:      Re: Editors and medium-tech people
In-Reply-To:  <802926B6AB8533408C33ADBCA3EE5C2AAD997D@coso.staff.vuw.ac.nz>
MIME-Version: 1.0
Content-Type: text/plain; charset="iso-8859-1"
Content-Transfer-Encoding: 8bit

Conal Tuohy wrote:
> I only recently picked up emacs for the first time, and I didn't
> really take to it, although it has some neat features which I did
> like. I think because of its venerable history it has a rather dated
> and inconsistent UI. The default keyboard shortcuts are all "wrong"
> for my fingers, which have long ago learnt other shortcuts. I would
> often search when I meant to save, or I'd select some text with the
> mouse, and press the backspace key, or press [esc] when I wanted to
> cancel out of something. This kind of thing is hugely annoying
> because it's a subconscious thing that's hard to control - I know
> what I'm doing wrong, but my fingers have other ideas.

That's it.  I have to wonder if Emacs -- at least in the default key
bindings -- will be in use 10 years from now by those just now cutting their
teeth in the programming/text editing/markup world.

Many folks became accustomed to the WordStar keys in the early 80's, first
in the CP/M world, later in MS-DOS.  Unless you were in a University Unix
setting in those days (and most of those I knew then only had vi), you were
using a microcomputer with a text editor and/or word processor that used the
WordStar key bindings.  WordPerfect mostly did away that by the 90's in the
word processing world, but the WordStar keys still reigned for
programming/text editing.  Then slowly but surely, the "CUA" paradigm began
to take hold.  Staring with the Mac, then Windows, then the Unixen -- Ctrl+S
(Cmd-S on the Mac) meant "Save", no matter what app you were in.  Same for
Ctrl+X, Ctrl+C, and Ctrl+V -- Copy, Cut, Paste.

Some of those that grew up with the old key bindings still use them, but I
doubt their children do.  For them, whether Mac, Win, Gnome, KDE -- by
default Ctrl+X (or Cmd-X) means "Cut", Ctrl+C means "Copy", and it's a hard
sell to tell them "use those for every app except your editor".

CUA won.

Can newer Emacsen do CUA with a switch on installation?  If so, does it
reconfigure the help?

Earlier, Sebastian wrote:
> For an example, consider the fact that I use emacs to
> alphabetically sort all the templates in an XSLT file; and to
> a search and replace using regular expressions across
> all my XSLT files in several directories. Things like the latter
> are not obscure luxuries, they are daily bread and butter.
> Can I do them in oXygen?

I don't know about oXygen, which I've used only minimally (they do seem
receptive to suggestions).  But from within NoteTab Pro -- a simple Windows
text editor -- you can indeed do regexp search & replace on multiple files;
you would have to write a small "clip" to handle the XSLT template sorting.
(The downside of NoteTab is the current version is still UTF-*-impaired.)  I
imagine you could do these with any programmer's editor worth its salt --
pure "XML editors" seem to be a mixed (and emerging) bag.

Then again, maybe those young bucks will have no problem being
multi-fingual...

^X, ^C

/Jelks
=========================================================================
Date:         Tue, 18 Jan 2005 09:36:05 +0000
Reply-To:     Peter Flynn <pflynn@UCC.IE>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Peter Flynn <pflynn@UCC.IE>
Organization: University College Cork
Subject:      Re: Editors and medium-tech people
In-Reply-To:  <802926B6AB8533408C33ADBCA3EE5C2AAD997D@coso.staff.vuw.ac.nz>
Content-Type: text/plain
Mime-Version: 1.0
Content-Transfer-Encoding: 7bit

On Tue, 2005-01-18 at 11:45, Conal Tuohy wrote:

> That's very interesting. Is your research published anywhere?

I was due to present some of it at a conference but funding failed;
but it's really only a research note on interim results, not a
fully-formed publication.

> Is this part of your PhD thesis?

Yep. I need to revisit some of the editors, and re-do some new ones
to replace those which have since died and gone to the great DTD in
the sky (or the great Schema down below :-).

> I only recently picked up emacs for the first time, and I didn't
> really take to it, although it has some neat features which I did
> like. I think because of its venerable history it has a rather dated
> and inconsistent UI. The default keyboard shortcuts are all "wrong"
> for my fingers, which have long ago learnt other shortcuts. I would
> often search when I meant to save, or I'd select some text with the
> mouse, and press the backspace key, or press [esc] when I wanted to
> cancel out of something. This kind of thing is hugely annoying because
> it's a subconscious thing that's hard to control - I know what I'm
> doing wrong, but my fingers have other ideas. I'm sure it's possible
> to reconfigure it to behave more as I'd expect, and I'm sure I could
> learn to use it effectively with enough practice, but instead I've
> taken up using JEdit for my XML markup.

As far as I know that has all been fixed by a mode which reimplements
the conventional (Windows) controls in place of the original ones.
Didn't Sebastian mention this the other day?

I think the notable feature of Emacs usage is that people who use it
for one thing tend to start using it for others. I use it for all
editing, whether XML, SGML, LaTeX, plaintext, XSLT, C, shells,
scripts, config files, etc, so it's a permanent feature on the screen.
It can also open files by FTP across the net, and it has email and
news built in, if you're so minded. I'd be interested to know whether
new users (who come to Emacs for TEI or other XML) end up using it for
other tasks, or if they go away with the idea that it is "just" an
XML editor.

///Peter
=========================================================================
Date:         Tue, 18 Jan 2005 15:32:00 +0000
Reply-To:     Lou Burnard <lou.burnard@COMPUTING-SERVICES.OXFORD.AC.UK>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Lou Burnard <lou.burnard@COMPUTING-SERVICES.OXFORD.AC.UK>
Subject:      TEI  P5 0.1.1 available from Sourceforge
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii; format=flowed
Content-Transfer-Encoding: 7bit

As promised at last year's members' meeting, all TEI P5 source files
have now moved to the CVS repository on the  TEI Sourceforge site at
tei.sf.org

The result of this move is that anyone wishing to see exactly what work
is going on anywhere in the development of TEI P5 has only to view the
repository.  All future updating of the source files will be carried out
using the tools provided by Sourceforge. (for an an excellent
introduction to these tools, see
http://sourceforge.net/docman/display_doc.php?docid=14033&group_id=1)

There is a web interface to the repository at
http://cvs.sourceforge.net/viewcvs.py/tei/P5/ (but this is
not updated in real time). For  more advanced CVS documentation, and
indeed documentation on all sorts of Sourceforge topics, click on "Site
  Docs" under "SF.net Resources" from the left-hand column.

In addition, we plan to start making "snapshot" releases of TEI P5
available as complete archives on a regular basis. Each snapshot release
will be numbered, and will be available as a download from the SF
site at http://sourceforge.net/project/showfiles.php?group_id=106328.
Each release will contain
(a) the complete ODD source
(b) a complete HTML version of the Guidelines
(c) a complete suite of TEI schema modules in RNC and DTD forms
(d) a suite of test routines and examples

The first such release will be available shortly and will constitute the
first test version of TEI P5. Numbered P5.0.1.1 it will comprise four
distinct archives:

*  tei-p5-source-0.1.1.zip (containing the ODD source files)
*  tei-p5-schema-0.1.1.zip (containing the schema files only)
*  tei-p5-doc-0.1.1.zip (currently containing the HTML version)
*  tei-p5-test-0.1.1.zip (containing the test suite and scripts)

These archives will join the existing archives for the TEI stylesheets
(now at release 4.2.3), and for the I18N package (at 1.2)

These components will also be made available as debian packages, for
convenience of linux and OS/X users (visit
http://tei.oucs.ox.ac.uk/teideb/ for information) and we are also
investigating how best hope to make them available as MSI packages for
MS-Windows in the near future. This should simplify maintenance of your
local TEI processing system.

The TEI web site will continue to reference the most recent complete
release at http://www.tei-c.org/P5 and to explain in more detail
how you can start experimenting with TEI P5 and its associated
software.

There is still a long way to go before we have a full release of TEI P5,
but these releases mark a significant stage in the journey.
=========================================================================
Date:         Tue, 18 Jan 2005 18:56:51 +0200
Reply-To:     George Cristian Bina <george@OXYGENXML.COM>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         George Cristian Bina <george@OXYGENXML.COM>
Subject:      [ANN] oXygen XML Editor 5.1
MIME-Version: 1.0
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit

Hi everybody,

I would like to thank you for your feedback on <oXygen/> 5.1 beta, that
helped correcting a few problems in the final release and some other
remarks went on our bugzilla for the next versions.
I will not list here the new 5.1 features as I already posted them some
time ago. If you want to see the complete feature list you can find that at
http://www.oxygenxml.com/index.html#new-version
There are also a few video demonstrations of some of the new features,
they are linked from the above page.

We set up a special promotion for TEI users for 1 month, entering the
coupon code
tei-oxygen
in the ordering process will result in a 15% discount applied to the end
user price.

Best Regards,
George
---------------------------------------------------------------------
George Cristian Bina
<oXygen/> XML Editor, Schema Editor and XSLT Editor/Debugger
http://www.oxygenxml.com
=========================================================================
Date:         Wed, 19 Jan 2005 11:19:21 -0500
Reply-To:     MacKenzie Stewart <mstewart@WELLESLEY.EDU>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         MacKenzie Stewart <mstewart@WELLESLEY.EDU>
Subject:      Implemented TEI-MS?
MIME-Version: 1.0
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 8bit

Dear colleagues:

I am wondering if anyone has implemented the TEI-MS (encoding for
descriptions of western medieval and renaissance manuscripts)
 as described at
http://sunsite.berkeley.edu/Scriptorium/technical/description_dtd.html

Thanks,
Mac Stewart
______________________________________________________________

MacKenzie Stewart, Digital Library Specialist,
Digital Technologies Group,  Library, Information Services,
Wellesley College, Wellesley, MA  02481

email: mstewart@wellesley.edu   ph.  781-283-2906    fax  781-283-3690
______________________________________________________________
=========================================================================
Date:         Wed, 19 Jan 2005 16:43:34 +0000
Reply-To:     Lou Burnard <lou.burnard@COMPUTING-SERVICES.OXFORD.AC.UK>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Lou Burnard <lou.burnard@COMPUTING-SERVICES.OXFORD.AC.UK>
Subject:      Re: Implemented TEI-MS?
Comments: To: MacKenzie Stewart <mstewart@WELLESLEY.EDU>
In-Reply-To:  <200501191629.j0JGTPl24044@listserv.brown.edu>
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii; format=flowed
Content-Transfer-Encoding: 7bit

The DTD described at that site contributed a great deal to the current
TEI proposals, as you might suppose, along with the MASTER project. But
I am not aware of any substantial collections of records which have been
encoded using it, other than (presumably) partners in the Scriptorium
project.

It would be an interesting project to produce XSLT transforms which
generated current P5 conformant records  from records conforming to this
and the MASTER dtds: indeed Matthew Driscoll and I have (coincidentally)
been discussing this very topic.


MacKenzie Stewart wrote:

> Dear colleagues:
>
> I am wondering if anyone has implemented the TEI-MS (encoding for
> descriptions of western medieval and renaissance manuscripts)
>  as described at
> http://sunsite.berkeley.edu/Scriptorium/technical/description_dtd.html
>
> Thanks,
> Mac Stewart
> ______________________________________________________________
>
> MacKenzie Stewart, Digital Library Specialist,
> Digital Technologies Group,  Library, Information Services,
> Wellesley College, Wellesley, MA  02481
>
> email: mstewart@wellesley.edu   ph.  781-283-2906    fax  781-283-3690
> ______________________________________________________________
>
=========================================================================
Date:         Thu, 20 Jan 2005 10:07:37 +0000
Reply-To:     James.Cummings@ota.ahds.ac.uk
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         James Cummings <James.Cummings@OTA.AHDS.AC.UK>
Organization: Oxford Text Archive
Subject:      XML and TEI Course.
MIME-Version: 1.0
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit

Oxford University Computing Services is pleased to announce that we will
again be running a detailed practical course on using TEI and XML during
February. Course details are available at:
http://www.oucs.ox.ac.uk/courses/detail.xsp?code=TWDA

The course comprises four 3 hour sessions, running on Thursday mornings
throughout February. This is a non-residential course, primarily
intended for members of the University of Oxford, but any TEI
enthusiasts who would like to attend any of the sessions would also be
welcome. There is a small charge for each session (about 3 GBP), to
cover costs of teaching materials, etc. If you are interested, please
send an email to courses@oucs.ox.ac.uk, quoting this email and stating
which session/s you would like to attend.

The course is likely to be of particular interest to text encoding
projects and will cover most aspects of creating and using
TEI-conformant textual resources. It will be taught by Lou Burnard,
Sebastian Rahtz and James Cummings.

Course Description

     The TEI (www.tei-c.org) provides guidelines for the long-term
preservation of electronic data, and a means of supporting effective
usage of such data in many subject areas. It is the encoding scheme of
choice for the production of critical and scholarly editions of literary
texts, for scholarly reference works and large linguistic corpora, and
for the management and production of detailed metadata associated with
electronic text and cultural heritage collections of many types. This
course will show how to do markup using the TEI and XML, and how to
process the results. The four sessions of the course will be arranged as
follows:

  1. Introduction to text markup and the TEI Guidelines
  2. Going further with the TEI DTD, and defining the subset of the TEI
        which you want to use
  3. Processing TEI documents; this will provide an introduction to
        writing programs in the most widely-used language for processing
        XML, XSLT
4. Going further with XSLT, using the family of stylesheets maintained
        by the TEI

Attendees are encouraged to bring their own material and talk about
specific problems.

-James

--
Dr James Cummings, Oxford Text Archive, University of Oxford
James dot Cummings at oucs dot ox dot ac dot uk
=========================================================================
Date:         Thu, 20 Jan 2005 15:19:48 -0700
Reply-To:     daniel.odonnell@uleth.ca
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Daniel O'Donnell <daniel.odonnell@ULETH.CA>
Organization: Department of English, University of Lethbridge
Subject:      How does one add type to a.global (as modification to P4,
              not something in P5)
MIME-Version: 1.0
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit

I have a question I can't find in the mailing archive and can't get a
cookbook-type answer from the P4 guidelines:

How would I add type to the a.global list? Neither of the two methods I
can think of seem to work:

<!ATTLIST global [or a.global or x.global or % global or %global or %
a.global etc.)  url CDATA #IMPLIED >

or

(in extensions.ent)
  <!ENTITY % global (or any of the above) 'IGNORE'>

(in extensions.dtd)
<!ENTITY % a.global '
       %a.terminology;
       %a.linking;
       %a.analysis;
       id ID #IMPLIED
       type CDATA #IMPLIED
       n CDATA #IMPLIED
       lang IDREF %INHERITED;
       rend CDATA #IMPLIED'>

-dan
--
Daniel Paul O'Donnell, PhD
Associate Professor of English
University of Lethbridge
Lethbridge AB T1K 3M4
Tel. (403) 329-2377
Fax. (403) 382-7191
E-mail <daniel.odonnell@uleth.ca>
Home Page <http://people.uleth.ca/~daniel.odonnell/>
The Digital Medievalist Project: <http://www.digitalmedievalist.org/>
=========================================================================
Date:         Fri, 21 Jan 2005 10:06:46 -0000
Reply-To:     Michael Beddow <mbteil-2@mbeddow.net>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Michael Beddow <mbteil-2@MBEDDOW.NET>
Subject:      Re: How does one add type to a.global (as modification to P4,
              not something in P5)
MIME-Version: 1.0
Content-Type: text/plain; charset="iso-8859-1"
Content-Transfer-Encoding: 7bit

> I have a question I can't find in the mailing archive and can't get a
> cookbook-type answer from the P4 guidelines:
>

That's because a customisation at this very general level this is something
of a culinary speciality and is liable to explode the restaurant.

> How would I add type to the a.global list?

With some difficulty or with shameless guile. I'd advise the latter.

> <!ENTITY % a.global '
>        %a.terminology;
>        %a.linking;
>        %a.analysis;
>        id ID #IMPLIED
>        type CDATA #IMPLIED
>        n CDATA #IMPLIED
>        lang IDREF %INHERITED;
>        rend CDATA #IMPLIED'>

This won't work as it stands, because it references parameter entries that
haven't been declared at the point your extension files are processed. You
have to get tricksy with dummy definitions of those entities, or leave them
out (which may have various knock-on effects). The shamelessly guileful way
is to forget trying to redefine %a.global, and hijack one of those
pre-existent parameter entities instead. %a.analysis might be a potential
candidate for redeclaration.

But although I am sure you have a good specific reason for wanting a global
type attribute, the reasons why a standard availability of a global type
would be a Bad Thing have been often rehearsed on this list. I think the
earliest detailed statement of the case is by Robin Cover at

http://listserv.brown.edu/archives/cgi-bin/wa?A2=ind9601&L=tei-l&P=R1230&D=0&H=0&O=T&T=1

(some of the technicalities referred to in that posting are, of course,
addressed to SGML, but the core points are still valid). Once every year or
so, someone says "Hey, let's have a global "type" attribute, followed by a
few "me too"s; then the argument against is again rehearsed (but then
apparently forgotten till next time). I did notice that the most recent crop
of requests (attempting to get the global "type" into P5) were left without
a response, but I doubt whether this signifies that the editors or the
Council have had a change of mind/heart on this issue.

Michael Beddow
=========================================================================
Date:         Fri, 21 Jan 2005 12:21:41 +0000
Reply-To:     Lou Burnard <lou.burnard@COMPUTING-SERVICES.OXFORD.AC.UK>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Lou Burnard <lou.burnard@COMPUTING-SERVICES.OXFORD.AC.UK>
Subject:      Re: How does one add type to a.global (as modification to P4,
              not something in P5)
Comments: To: Michael Beddow <mbteil-2@mbeddow.net>
In-Reply-To:  <200501211006.j0LA6xf05391@listserv.brown.edu>
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii; format=flowed
Content-Transfer-Encoding: 7bit

Michael Beddow wrote:

>
>
>>How would I add type to the a.global list?
>
>
> With some difficulty or with shameless guile. I'd advise the latter.
>
>
>><!ENTITY % a.global '
>>       %a.terminology;
>>       %a.linking;
>>       %a.analysis;
>>       id ID #IMPLIED
>>       type CDATA #IMPLIED
>>       n CDATA #IMPLIED
>>       lang IDREF %INHERITED;
>>       rend CDATA #IMPLIED'>
>
>
> This won't work as it stands, because it references parameter entries that
> haven't been declared at the point your extension files are processed.  You
 > ave to get tricksy with dummy definitions of those entities, or leave
them
> out (which may have various knock-on effects). The shamelessly guileful way
> is to forget trying to redefine %a.global, and hijack one of those
> pre-existent parameter entities instead. %a.analysis might be a potential
> candidate for redeclaration.

This is not the only reason it won't work of course. TYPE is explicitly
defined for several elements in the P4 DTD, so you would either have to
remove their reference to "a.global" or their existing TYPE attribute as
well.

>
> But although I am sure you have a good specific reason for wanting a global
> type attribute, the reasons why a standard availability of a global type
> would be a Bad Thing have been often rehearsed on this list. I think the
> earliest detailed statement of the case is by Robin Cover at
>
> http://listserv.brown.edu/archives/cgi-bin/wa?A2=ind9601&L=tei-l&P=R1230&D=0&H=0&O=T&T=1
>
> (some of the technicalities referred to in that posting are, of course,
> addressed to SGML, but the core points are still valid). Once every year or
> so, someone says "Hey, let's have a global "type" attribute, followed by a
> few "me too"s; then the argument against is again rehearsed (but then
> apparently forgotten till next time).

Thank you, Michael. It certainly ought to be added to the FAQ. In my
experience, when people say "TYPE should be global" what they usually
mean is "I want to make a distinction which the TEI doesn't currently
make amongst different kinds of <blort>" (where <blort> is something
that the TEI currently does identify as existing) This is a perfectly
reasonable requirement but making TYPE global is a very blunt instrument
to achieve it. At P5 you could meet this need either by
defining a new element and adding it to whatever class <blort> is a
member of; or by just adding <blort> to the typed class (assuming it's
not already a member thereof).  In my optinion, members of the typed
class should be "generic" style elements like <seg> or <milestone> --
with even less semantic weight than usual--  rather than specific ones
like <w> or <lb>. Otherwise, why don't we just say <element
type="blort"> and have done?[1]  (ok, I know <w> is a typed element and
<milestone> isn't: but you catch my drift...)


I did notice that the most recent crop
> of requests (attempting to get the global "type" into P5) were left without
> a response, but I doubt whether this signifies that the editors or the
> Council have had a change of mind/heart on this issue.

Can't speak for all of the afore-mentioned, but this baby certainly
hasn't. The topic *did* come up at a Council meeting some time ago and
there was some support for the notion, but the issue wasn't really
discussed in any detail, thank Heavens.

[1] Look ma, it's RDF!
=========================================================================
Date:         Fri, 21 Jan 2005 12:52:33 -0000
Reply-To:     Michael Beddow <mbteil-2@mbeddow.net>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Michael Beddow <mbteil-2@MBEDDOW.NET>
Subject:      Re: How does one add type to a.global (as modification to P4,
              not something in P5)
MIME-Version: 1.0
Content-Type: text/plain; charset="iso-8859-1"
Content-Transfer-Encoding: 7bit

Lou Burnard wrote:

 > Otherwise, why don't we just say <element
> type="blort"> and have done?

Indeed, that corresponds uncannily to something I was just about to pass on
to the list for readers' weekend enlightenment.

It's a Modest Proposal that shows how easy this TEI stuff could become if
only the principle behind a globally available type attribute were followed
through consistently. Aside from its intrinsic elegance and ready
comprehensibility, the following has the considerable advantage that the
DTD, a substantial example, AND the whole of the Guidelines fit into a
single posting.

1. The DTD
<?xml version="1.0" encoding="UTF-8"?>
<!--Proposal for hugely flexible TEI DTD-->
<!--(C) Richeal Heddon 2005 -->
<!ELEMENT TEI.99 (element+)>
<!ELEMENT element (#PCDATA | element)*>
<!ATTLIST element
type CDATA #REQUIRED
>

2. Worked Example

<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE TEI.99 SYSTEM "tei99.dtd">
<TEI.99>
<element type="teiHeader">
</element>
<element type="text">
  <element type="body">
    <element type="div">
       <element type="p"> Now that's what I call <element
type="hi">flexible</element>!
        </element>
     </element>
  </element>
</element>
</TEI.99>

3. The Guidelines

Analyse the structure of your source. Whenever you identify something that
is of a distinctive structural type, enclose it in an <element> and assign a
value to the "type" attribute  that indicates what sort of thing you
think it is.

THE END

Michael Beddow

PS If anyone's wondering who this "Richeal Heddon" is who asserts
intellectual property rights over the DTD, the only other thing I know about
him (?her) is that, according to the very wonderful computer system of the
UK Vehicle Licensing Agency, he/she owns my car.  So Richeal, if you're
reading this, I'd love to meet up with you some time to discover if there's
anything else we have in common.
=========================================================================
Date:         Fri, 21 Jan 2005 08:37:36 -0700
Reply-To:     daniel.odonnell@uleth.ca
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Daniel O'Donnell <daniel.odonnell@ULETH.CA>
Organization: Department of English, University of Lethbridge
Subject:      Re: How does one add type to a.global (as modification to P4,
              not something in P5)
Comments: To: Michael Beddow <mbteil-2@mbeddow.net>
In-Reply-To:  <200501211006.j0LA6xf05391@listserv.brown.edu>
MIME-Version: 1.0
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit

Michael Beddow wrote:
>>I have a question I can't find in the mailing archive and can't get a
>>cookbook-type answer from the P4 guidelines:
>>
> %a.analysis might be a potential
> candidate for redeclaration.
This just moves the problem. None of these have x-dot declarations to be
added to that I can see. Is there a way of adding an attribute to an
a-dot class?

>
> But although I am sure you have a good specific reason for wanting a global
> type attribute, the reasons why a standard availability of a global type
> would be a Bad Thing have been often rehearsed on this list. I think the
> earliest detailed statement of the case is by Robin Cover at
>
> http://listserv.brown.edu/archives/cgi-bin/wa?A2=ind9601&L=tei-l&P=R1230&D=0&H=0&O=T&T=1
>
> (some of the technicalities referred to in that posting are, of course,
> addressed to SGML, but the core points are still valid).

Therefore I find it amusing that one of Robin's initial worries is that
@type might conflict with the (even then) current abuse of @n as a
substitute for type (a bit like arguing that legalising marijuana is bad
because it might cut down on glue-sniffing). Not everything can have a
number; everything can be further broken down in to more specific
typologies. The fact that there have been two solid opinions about this
by informed people going back to pre-history makes me wonder if there is
maybe not a little moral guardianship going on.

And from two other postings:

> In my optinion, members of the typed
> class should be "generic" style elements like <seg> or <milestone> --
> with even less semantic weight than usual--  rather than specific ones
> like <w> or <lb>. Otherwise, why don't we just say <element
> type="blort"> and have done?

and

> It's a Modest Proposal that shows how easy this TEI stuff could become if
> only the principle behind a globally available type attribute were followed
> through consistently. Aside from its intrinsic elegance and ready
> comprehensibility, the following has the considerable advantage that the
> DTD, a substantial example, AND the whole of the Guidelines fit into a
> single posting.
>
> 1. The DTD
> <?xml version="1.0" encoding="UTF-8"?>
> <!--Proposal for hugely flexible TEI DTD-->
> <!--(C) Richeal Heddon 2005 -->
> <!ELEMENT TEI.99 (element+)>
> <!ELEMENT element (#PCDATA | element)*>
> <!ATTLIST element
> type CDATA #REQUIRED
>
>>>
>
>
> 2. Worked Example
>
> <?xml version="1.0" encoding="UTF-8"?>
> <!DOCTYPE TEI.99 SYSTEM "tei99.dtd">
> <TEI.99>
> <element type="teiHeader">
> </element>
> <element type="text">
>   <element type="body">
>     <element type="div">
>        <element type="p"> Now that's what I call <element
> type="hi">flexible</element>!
>         </element>
>      </element>
>   </element>
> </element>
> </TEI.99>

Both of these are really beside the point. First of all, of course one
could use global type to ignore all elements and essentially create an
ad-hoc and unenforcible dtd; but one also could use the extension and
modification mechanism to "extend" tei until it became html 2.0 for
Netscape, or express 3/4 of a document using the already existing <seg
type="blort">. One can't help people who are determined to hurt
themselves; but that doesn't mean everything dangerous should be taken
away from responsible adults.

Secondly, I think Lou is missing the point of the legitimate,
non-abusive function @type actually has. Currently one has semantically
general elements and semantically specific elements. Many/most/all? the
semantically specific ones are synonymous with a general element and a
specific type: e.g. <seg type='w'> = <w>. In other words, the specific
elements are canonised @type values of the general element. <w> is an
element because <seg type="w"> is a pretty universal coding; <blort> is
not an element because <seg type="blort"> is not.

At the semantically specific level, similar things can happen. You can
have different kinds of words or different kinds of dates:  When a
typological distinction is very common, the creation of a new element
name might be useful; but when the distinction is very fine, the
creation of a new element name might be more confusing than useful. A
good example of this is probably w: the distinction between linguistic
and transcriptional words seems pretty fine to me; <w
type="linguistic">/<w type="transcriptional"> seems to me better than
either <w>/<tw> or <seg type="transcriptionalword">/<w>.

I wonder if there isn't a bit of markup moral majoritanianism going on
here: i.e. I'm agin it, so it otta be banned. Cover's e-mail is
significant for a number of reasons:
1) it lays out some of the arguments against;
2) it shows that @n abuse to cover for missing @type goes back to 1996
at least;
3) he is disagreeing with David Megginson: this is a debate between
reasonable and informed people not the enlightened vs. the rabble.

Were a global @type to be added, nobody is saying you'd be required to
use it.

-dan
--
Daniel Paul O'Donnell, PhD
Associate Professor of English
University of Lethbridge
Lethbridge AB T1K 3M4
Tel. (403) 329-2377
Fax. (403) 382-7191
E-mail <daniel.odonnell@uleth.ca>
Home Page <http://people.uleth.ca/~daniel.odonnell/>
The Digital Medievalist Project: <http://www.digitalmedievalist.org/>
=========================================================================
Date:         Fri, 21 Jan 2005 17:20:42 +0000
Reply-To:     Lou Burnard <lou.burnard@COMPUTING-SERVICES.OXFORD.AC.UK>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Lou Burnard <lou.burnard@COMPUTING-SERVICES.OXFORD.AC.UK>
Subject:      Re: How does one add type to a.global (as modification to P4,
              not something in P5)
Comments: To: daniel.odonnell@uleth.ca
In-Reply-To:  <200501211537.j0LFbnf01113@listserv.brown.edu>
Content-Type: text/plain
Content-Transfer-Encoding: binary
MIME-Version: 1.0

In message <200501211537.j0LFbnf01113@listserv.brown.edu>
daniel.odonnell@uleth.ca writes:
> Michael Beddow wrote:
> >>I have a question I can't find in the mailing archive and can't get a
> >>cookbook-type answer from the P4 guidelines:
> >>
> > %a.analysis might be a potential
> > candidate for redeclaration.
> This just moves the problem. None of these have x-dot declarations to be
> added to that I can see. Is there a way of adding an attribute to an
> a-dot class?

In P4, you cannot modify attribute lists without redefining the entire parameter
entity concerned. The metalanguage committee of the time decided it was not
worth the implementation pain.

As my earlier post indicated, the facilities in P5 to deal with this problem are
simpler and (I think) better.


[...]

> Therefore I find it amusing that one of Robin's initial worries is that
> @type might conflict with the (even then) current abuse of @n as a
> substitute for type (a bit like arguing that legalising marijuana is bad
> because it might cut down on glue-sniffing).

I agree that this particular one of Robin's argument is a little odd (I think it
derives from the fact that in P1 or 2 we used to use N on <div> elements instead
of TYPE -- but I cant remember why we did that!)

> Not everything can have a
> number; everything can be further broken down in to more specific
> typologies.

But everything *can* have a name, and N is used to supply a name as well as a
number. My guess is that this is what lay at the root of the argument way back then.

The fact that there have been two solid opinions about this
> by informed people going back to pre-history makes me wonder if there is
> maybe not a little moral guardianship going on.

I don't quite see why differences of opinion necessarily equate to assertions of
  "moral guardianship", but maybe that's because I'm not a North American!



[ humorous suggestions about single-element dtd deleted]

> Both of these are really beside the point. First of all, of course one
> could use global type to ignore all elements and essentially create an
> ad-hoc and unenforcible dtd; but one also could use the extension and
> modification mechanism to "extend" tei until it became html 2.0 for
> Netscape, or express 3/4 of a document using the already existing <seg
> type="blort">. One can't help people who are determined to hurt
> themselves; but that doesn't mean everything dangerous should be taken
> away from responsible adults.

I am comfortable with that as a general princuiple. However I also think that in
general sharp scissors should be put away in drawers, access to dangerous
narcotics should be controlled, and traffic's freedom to circulate at high speed
in built up areas seriously curtailed.

>
> Secondly, I think Lou is missing the point of the legitimate,
> non-abusive function @type actually has. Currently one has semantically
> general elements and semantically specific elements. Many/most/all? the
> semantically specific ones are synonymous with a general element and a
> specific type: e.g. <seg type='w'> = <w>. In other words, the specific
> elements are canonised @type values of the general element.

I'm not sure that I agree with that. It's true that any specific element can be
generalized, and there is often an element for representing the general case,
but this is by no means universally the case.
 <w> is an
> element because <seg type="w"> is a pretty universal coding; <blort> is
> not an element because <seg type="blort"> is not.

I may just be nit picking here, but the "because"s in this sentence are far from
 accurate. There is no <blort> (except as an example of a non-existent element)
for reasons which have nothing to do with whether or not there is a <seg
type="blort">

>
> At the semantically specific level, similar things can happen. You can
> have different kinds of words or different kinds of dates:  When a
> typological distinction is very common, the creation of a new element
> name might be useful; but when the distinction is very fine, the
> creation of a new element name might be more confusing than useful. A
> good example of this is probably w: the distinction between linguistic
> and transcriptional words seems pretty fine to me; <w
> type="linguistic">/<w type="transcriptional"> seems to me better than
> either <w>/<tw> or <seg type="transcriptionalword">/<w>.
>

I agree with this entirely, except that it takes a rather lofty view: if you're
a transcriptional kind of guy, you'll expect your <w> to be transcriptional, and
the other to be "demoted" to a <seg type="linguistic">; if you;re a linguistic
kind of person, exactly the opposite. The one thing you'll agree on is that you
don't like using <seg>s for both!

> I wonder if there isn't a bit of markup moral majoritanianism going on
> here: i.e. I'm agin it, so it otta be banned.

Nothing is banned in P5, as I thought I had indicated in my previous post. You
can add as many elements as you want to the typed class.

Cover's e-mail is
> significant for a number of reasons:
> 1) it lays out some of the arguments against;
> 2) it shows that @n abuse to cover for missing @type goes back to 1996
> at least;
> 3) he is disagreeing with David Megginson: this is a debate between
> reasonable and informed people not the enlightened vs. the rabble.

I hope you're not suggesting that you, or I, or Michael, should be cast in the
role of the "rabble" here!


>
> Were a global @type to be added, nobody is saying you'd be required to
> use it.
>


You haven't addressed the specific technical problems that introducing it
globally would involve -- namely the conflicts with the existing explicitly
defined TYPE attribute
=========================================================================
Date:         Fri, 21 Jan 2005 17:51:29 -0000
Reply-To:     Michael Beddow <mbteil-2@mbeddow.net>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Michael Beddow <mbteil-2@MBEDDOW.NET>
Subject:      Re: How does one add type to a.global (as modification to P4,
              not something in P5)
MIME-Version: 1.0
Content-Type: text/plain; charset="iso-8859-1"
Content-Transfer-Encoding: 7bit

> > %a.analysis might be a potential
> > candidate for redeclaration.

> This just moves the problem. None of these have x-dot declarations to be
> added to that I can see. Is there a way of adding an attribute to an
> a-dot class?

Not without working around the problem of undeclared entities, no. The
reason why "shameless guile" was involved in this option was that I had in
mind, not adding the @type attribute to the existing definition of
%a.analysis, but replacing the existing definition of  %a.analysis (or one
of the other %a. classes if that proved more dispensible) by one that
defined @type alone. But as Lou pointed out, this wouldn't work anyway
because it would clash with the other places where @type is already allowed
unless they, too, were redefined. I was misled into this suggestion by false
analogy with the way I have from time to time added, not a global, but a
pretty pervasive @mytype attribute to various elements for specific ad-hoc
developmental purposes  That's easily possible because of course there are
no existing "@mytype" attributes there already. (These attributes are
destined to be replaced by project-specific elements as the markup scheme
firms up and is transferred into the final customisation).
>
>
> Therefore I find it amusing that one of Robin's initial worries is that
> @type might conflict with the (even then) current abuse of @n as a
> substitute for type (a bit like arguing that legalising marijuana is bad
> because it might cut down on glue-sniffing).

I read his remarks as being more concerned about the prospect that horrible
examples of the use of ad-hoc typologies with @n, already emerging all those
years ago, might spill over into the use of a global @type and have a
devastating effect on consistency of practice and  comprehensibility of
coding between projects, not to mention on interchangeability.

> Not everything can have a
> number;

Indeed not, but who said @n is mnemonic for number?  Not the Guidelines.
Apparently the rationale for this particular example of terse nomenclature
was that "n" could be equally and indifferently mnemonic for "name" or
"number", thus allowing the encoding of a whole range of designators that
variously come attached to all sorts of things in texts in the wild. The
prime reason for allowing a ubiquitous means of so encoding them is not
because the *encoder* has "named" or "counted" them and wants to put the
result of his/her efforts into the markup, but because these designators are
actually there in the source in some form or another, so fidelity to the
source may mandate their being recorded.  Cf.  the other often-misunderstood
global @rend, which is primarily there not to inform a processor about how
the encoder *thinks* something should be rendered, but to record how it *is*
rendered in the source.   Though "n" as an attribute name must have seemed a
good idea at the time, it may have been too clever by half. I think Lou once
suggested replacing it by "label", which might avoid some of the
misunderstandings.

> The fact that there have been two solid opinions about this
> by informed people going back to pre-history [...]

I've yet to be convinced that this is a fact. Yes, people who generally know
what they're talking about have from time to time suggested there should be
a global @type in TEI, but I have yet to see that suggestion supported with
anything like the quality and detail of argument with which others have
responded to it, apparently with the result pro tem that those making the
suggestion thought better of it.

> makes me wonder if there is
> maybe not a little moral guardianship going on.

If "moral guardianship" means trying to ensure that a proposal which has the
potential to damage core TEI principles in an uncontrollable fashion isn't
allowed in unchallenged, then so be it. It is not a core aim of the TEI to
make the encoding of humanities texts convenient. The whole thing is about
squaring a circle: enabling the huge variety of texts that fall within our
many ambits (far less homogeneous than the things any other application of
SGML or XML has to deal with) to be encoded in a way that does justice to
their individuality, while maximising consistency and mutual
comprehensibility across projects and disciplines.  The encoder faced with
his or her own texts naturally wants the instantly gratifying freedom to
encode what appear to be their essential facets in an expressive and
unambigious way. Against this, the discipline of TEI conformance tries to
ensure that the encoder will also enjoy, along with others elsewhere, the
deferred  gratification of seeing the finished markup prove to as
comprehensible (and usable) as possible to other people, in other times as
well as other places. Sometimes that means placing or leaving obstacles in
the way of "quick fixes".

>
> And from two other postings:
>
> > In my optinion, members of the typed
> > class should be "generic" style elements like <seg> or <milestone> --
> > with even less semantic weight than usual--  rather than specific ones
> > like <w> or <lb>. Otherwise, why don't we just say <element
> > type="blort"> and have done?
>[...]
> >
> Both of these are really beside the point. First of all, of course one
> could use global type to ignore all elements and essentially create an
> ad-hoc and unenforcible dtd; but one also could use the extension and
> modification mechanism to "extend" tei until it became html 2.0 for
> Netscape, or express 3/4 of a document using the already existing <seg
> type="blort">.

There's a problem with this analogy.  True enough (as the Guidelines
themselves point out) radically subversive redefinition of the TEI content
models is possible within the rules as stated, but it is perceived as pretty
difficult: a lot of people seem either abandon, or shrink away from even
beginning, simple customisations which would be wholly in the interests of
their projects (and much preferable to lobbying to have their special needs
canonised into the core).  And that difficulty (perceived or real) helps
deter the hasty, the under-informed, the unwise or the just plain desperate
from wreaking havoc against the spirit of the tagset while keeping to the
letter of its customisation rules. But allow a global @type and there would
be no such inbuilt resistance to amorphous ad-hoccery, because anyone can
with the utmost ease stick any sort of value they fancy between a pair of
inverted commas and regard the result as Very Good.

>
> Currently one has semantically
> general elements and semantically specific elements. Many/most/all? the
> semantically specific ones are synonymous with a general element and a
> specific type: e.g. <seg type='w'> = <w>. In other words, the specific
> elements are canonised @type values of the general element. <w> is an
> element because <seg type="w"> is a pretty universal coding; <blort> is
> not an element because <seg type="blort"> is not.
>
> At the semantically specific level, similar things can happen. You can
> have different kinds of words or different kinds of dates:  When a
> typological distinction is very common, the creation of a new element
> name might be useful; but when the distinction is very fine, the
> creation of a new element name might be more confusing than useful. A
> good example of this is probably w: the distinction between linguistic
> and transcriptional words seems pretty fine to me; <w
> type="linguistic">/<w type="transcriptional"> seems to me better than
> either <w>/<tw> or <seg type="transcriptionalword">/<w>.

As far as I can make out, Lou wasn't denying the substance of this. The
basic objection is not to the utility of a @type attribute where there is an
undoubted need for a typology (and some chance of using an at least
prospectively standardised and codified one), or to its reasoned addition to
specific elements or classes of elements that don't currently have it,
though there is the implied rider that the perceived need for such an
addition may sometimes signal the need for a new element, with the phase of
being  typed by attribute value proving merely transitional.  The issue is:
are there potentially harmful consequences to allowing @type as a global?

> Were a global @type to be added, nobody is saying you'd be required to
> use it.

No, but the existence of a global attribute might easily send out a
particularly strong "why not use me, since I've been put here?" sort of
message. Thanks to the switch to  xml:lang and xml:id, P5 will have (at
least in any version that more or less corresponds to the old "core") an
even more slender set of global attributes in its own baileywick than P4. @n
and @rend, as I have tried to indicate, merit ubiquitous availability
because they are arguably needed to represent things that are out there in
the wild, with a variety and scope beyond anyone's power to generalise and
predict. But typological assignments of the kind that the values of a global
@type would express are not "out there". They are of the essence of the
analyst/encoder's craft, art and judgment. As such it is vital that they are
as well-considered, coherent and consensual (even if they cannot always be
standardised) as can be managed. Obliging encoders who want such attributes
where they are not already available to engage in at least the degree of
forethought necessary to add them via a conformant customisation seems to me
to be both wise and prudent. Since P5 makes such customisations even easier
than P4 did, I fail to see that the case for global availability out of the
box has been made.

Michael Beddow
=========================================================================
Date:         Sat, 22 Jan 2005 00:05:25 -0700
Reply-To:     daniel.odonnell@uleth.ca
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Daniel O'Donnell <daniel.odonnell@ULETH.CA>
Organization: Department of English, University of Lethbridge
Subject:      Anybody have a tei:biblStruct > chicago B xhtml xslt sheet?
MIME-Version: 1.0
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit

Hi y'all,
        I'm busy putting together references for the first issue of the Digital
Medievalist (due out at the end of the month, mark your calendars). Our
stylesheet calls for Chicago B (inline) references and works cited.
Currently, I'm just flubbing (or should that be blorting) along with
bibl and putting the periods etc. in the right place by hand. Given the
volume and great standardisation of work in the preparation of multiple
volumes, however, I'd like to automate this.
        Does anybody have an xslt template that would output tei:bibl or
biblStruct as Chicago B? Would they be willing to donate it to me? You
would get 1000 thanks and public acknowledgement in the first editorial
of the new journal.
        This raises a related issue I hope to be speaking on soon: is there a
mechanism for sharing tei-oriented xslt fragments? I would imagine there
is a lot of duplication going on. It seems to me that there might be
room for some kind of wiki-based xslt template exchange for tei-ers.
-dan
--
Daniel Paul O'Donnell, PhD
Associate Professor of English
University of Lethbridge
Lethbridge AB T1K 3M4
Tel. (403) 329-2377
Fax. (403) 382-7191
E-mail <daniel.odonnell@uleth.ca>
Home Page <http://people.uleth.ca/~daniel.odonnell/>
The Digital Medievalist Project: <http://www.digitalmedievalist.org/>
=========================================================================
Date:         Sat, 22 Jan 2005 21:41:24 +0900
Reply-To:     acmuller@jj.em-net.jp
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Charles Muller <cmuller-lst@JJ.EM-NET.JP>
Subject:      Re: Anybody have a tei:biblStruct > chicago B xhtml xslt sheet?
In-Reply-To:  <41F1FB35.6090309@uleth.ca>
Mime-Version: 1.0
Content-Type: Text/Plain; charset=us-ascii
Content-Transfer-Encoding: 7bit

Daniel O'Donnell wrote:

>         Does anybody have an xslt template that would output tei:bibl or
> biblStruct as Chicago B?

I don't know how far this falls from what you need, but in the event no one responds
to this with a clear positive, please see

  http://www.acmuller.net/xml-tei-tut/index.html

especially the third and fourth items.

Regards,

Chuck

---------------------------
Charles Muller

Toyo Gakuen University
Faculty of Humanities
1660 Hiregasaki, Nagareyama-shi
Chiba 270-0161 JAPAN
Mobile Phone: 090-9310-1787

Web Site: Resources for East Asian Language and Thought
http://www.acmuller.net

<acmuller[at]jj.em-net.jp>
=========================================================================
Date:         Sat, 22 Jan 2005 15:49:34 -0500
Reply-To:     Francois Lachance <lachance@ORIGIN.CHASS.UTORONTO.CA>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Francois Lachance <lachance@ORIGIN.CHASS.UTORONTO.CA>
Subject:      Attributes - type, n, ana
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit

Subject:  Re: [TEI-L] How does one add type to a.global (as modification
to P4, not something in P5)

A few observations on Michael Beddow's approach to global attributes.

The TEI Guidelines also offer assistance to those authoring texts in a
structured editing environment and, of course, to those that are marking
up readings of extant textual evidence. In other words, the TEI can be
used by both authors and editors.  This author-editor orientation to the
TEI is perhaps why I fail to understand the appeal to what exists in the
wild, out there.

Global or not,the attributes "n" and "rend" are as interpretative as the
attribute "type".

Compare the intial description of the attribute "n" in the Guidelines (3.5
"Global Attributes") with the initial description of the attribute "type"
(5.1.1 "The TEI Header and Its Components").

The "n" attribute description follows immediately that for the "id"
attribute. The "n" attribute "gives a number (or other label) for an
element, which is not necessarily unique within the document." The
"document" referenced here is the "document instance" not a text that is
the object of editorial concern, i.e. a text being marked up. Like the
"id" attribute with which there is an evident comparaison (unique / not
unique), the "n" attribute is independent of what is out there. There is
some liberty in its use.

The "type" element is introduced in a specifically restrictive context. It
"specifies the kind of document to which the header is attached. Legal
values are ["text" or "corpus"]." Again the reference to document is I
take it to be re"document instance".  The DTD does supply "text" as the
default value. Oddly, however the declarattypes the "type" attribute of a
<teiHeader element> as CDATA. No way to validate the legal values as
stipulated by the Guidelines. Compare the declaration for the "type"
attribute with the "status" attribute where the choice of value is
constrained ("new" or "update") with the default set to "new"

Now then back to "n" as attribute for name, number, label or marker and
the question of information interchange. Information interchange is not
only about preservation. It is also about the creation of information.
Information is created through transformations. The example of a use case:

                <p n="lapidary">...</p>
                <p n="purple">................</p>

Perfectly acceptable, non-abusive and valid use of the "n" attribute to
capture a single simple flat typology.  Separators add character :
"purple_lachancian" "purple_beddowist"

However, natural languages being what they are ...

                <p n="hypotactic">...>
                <p n="stones">....</p>
                <p n="lapidary"> ....</p>


And so for cases involving overlapping typologies, the typologist, be they
author or editor, can consider the attribute "ana" [introduced in P3] and
on to feature structures. The attribute "ana" is of type IDREFS and can
therefore be used to reference oneelements that have "id" elements of type
ID. The attribute "ana" is global (available for use on any element) when
the analysis tag set is invoked.

BTW worth examining the discussion of inheritence (3.7.1 "Classes Which
Share Attributes") and its connection tthe contention that extending the
class of global attributes to include a "type" attribute would impact the
existing declarations for "type" attributes.Is there in all the DTD
fragments an Attribute List that contains a declaration for "type"
attributes that does not type that attribute as CDATA? Is the proposed
extension (local modification) of the DTDto add an attribute "type" to the
global attributes proposing CDATA or a set of restricted values? Wouldn't
the answers to these questions affect the inheritance?

--
Francois Lachance, Scholar-at-large
http://www.chass.utoronto.ca/~lachance/jardin

2005 Year of Comparative Connections. DIA: Comparative connections? LOGZ:
Connection, first. Comparison, next. DIA: Check. Comparable ways of
connecting. LOGZ: Selection outcomes, first. Comparative Connections,
next.
=========================================================================
Date:         Tue, 25 Jan 2005 22:05:51 -0700
Reply-To:     daniel.odonnell@uleth.ca
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Daniel O'Donnell <daniel.odonnell@ULETH.CA>
Organization: Department of English, University of Lethbridge
Subject:      [tan] emacs spelling
MIME-Version: 1.0
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit

I was just having a meta discussion about our discussion of emacs and
the following came up: in eight years of working with the program, I've
never got the spelling checker to work properly. I've been too
shamefaced ever to admit this to anybody (my correspondent promised me a
beer at Kalamazoo if I told my most shameful emacs story) and it has
never been a problem to transfer the output to something like word with
a point-and-click spelling checker. But now I'd like to get it done in
emacs.

Currently, if in xml mode I go to tools>Spell checking>check buffer I
get a "searching for program; no such directory or file, ispell" error.
I've looked up ispell in the manual and didn't see anything obvious to
solve this problem. I'm sure I have been correctly shamefaced to admit I
can't get it... but can anybody help me? I'll give them the drink of
their choice at the next conference we attend together.
-dan
--
Daniel Paul O'Donnell, PhD
Associate Professor of English
University of Lethbridge
Lethbridge AB T1K 3M4
Tel. (403) 329-2377
Fax. (403) 382-7191
E-mail <daniel.odonnell@uleth.ca>
Home Page <http://people.uleth.ca/~daniel.odonnell/>
The Digital Medievalist Project: <http://www.digitalmedievalist.org/>
=========================================================================
Date:         Wed, 26 Jan 2005 08:37:48 +0000
Reply-To:     Stuart Yeates <stuart.yeates@COMPUTING-SERVICES.OXFORD.AC.UK>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Stuart Yeates <stuart.yeates@COMPUTING-SERVICES.OXFORD.AC.UK>
Subject:      Re: [tan] emacs spelling
Comments: To: daniel.odonnell@uleth.ca
In-Reply-To:  <41F7252F.7050609@uleth.ca>
MIME-Version: 1.0
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit

Daniel O'Donnell wrote:
> I was just having a meta discussion about our discussion of emacs and
> the following came up: in eight years of working with the program, I've
> never got the spelling checker to work properly. I've been too
> shamefaced ever to admit this to anybody (my correspondent promised me a
> beer at Kalamazoo if I told my most shameful emacs story) and it has
> never been a problem to transfer the output to something like word with
> a point-and-click spelling checker. But now I'd like to get it done in
> emacs.
>
> Currently, if in xml mode I go to tools>Spell checking>check buffer I
> get a "searching for program; no such directory or file, ispell" error.
> I've looked up ispell in the manual and didn't see anything obvious to
> solve this problem. I'm sure I have been correctly shamefaced to admit I
> can't get it... but can anybody help me? I'll give them the drink of
> their choice at the next conference we attend together.

Emacs does spell checking by farming the hard work out to an external
program called ispell, and it appears that ispell is not being found.

Things to check:

(1) Do you have ispell installed?

(2) Is ispell in you default path? [Go to the command line and type
"ispell", you'll either get a messages about how to use ispell or a
message that ispell was not found].

(3) Do you have the correct language dictionaries installed? [Emacs has
an idea of what language (i.e. American English or British English) it
is using and will expect an appropriate dictionary].

To help fix these things we need to know:

(a) What platform are you using Windows/Mac/Linux?

(b) What version of emacs are you using?

cheers
stuart
--
Stuart Yeates            stuart.yeates@computing-services.oxford.ac.uk
OSS Watch                                  http://www.oss-watch.ac.uk/
Humbul Humanities Hub                         http://www.humbul.ac.uk/
=========================================================================
Date:         Wed, 26 Jan 2005 09:18:16 +0000
Reply-To:     Sebastian Rahtz <sebastian.rahtz@COMPUTING-SERVICES.OXFORD.AC.UK>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Sebastian Rahtz <sebastian.rahtz@COMPUTING-SERVICES.OXFORD.AC.UK>
Subject:      Re: [tan] emacs spelling
Comments: To: daniel.odonnell@uleth.ca
In-Reply-To:  <200501260510.j0Q5AFc11467@listserv.brown.edu>
MIME-Version: 1.0
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit

er, you install the "ispell" package. no more, no less.

Sebastian
=========================================================================
Date:         Wed, 26 Jan 2005 11:12:27 +0100
Reply-To:     Christian-Emil Ore <c.e.s.ore@EDD.UIO.NO>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Christian-Emil Ore <c.e.s.ore@EDD.UIO.NO>
Subject:      call for abstracts ICOM-CIDOC'2005
Mime-Version: 1.0
Content-Type: multipart/alternative;
              boundary="=====================_69470890==.ALT"

--=====================_69470890==.ALT
Content-Type: text/plain; charset="us-ascii"; format=flowed

Dear all,
ICOM-CIDOC is an international committee under ICOM, (International Council
of Museums, http://icom.museum/,
http://www.willpowerinfo.myby.co.uk/cidoc/), and is the international focus
for the documentation interests of museums and related organizations. It
has over 450 members in 60 countries.

A considerable amount of the documentation in museums are texts of great
cultural historical interest both viewed as artefacts and with respect to
the content. Unfortunately the use and knowlegde of TEI is not as
widespread as it could be in the museum communities. The CIDOC 2005
conference is very good opportunity for the TEI community to meet the
museum documentation world.

The annual CIDOC conference will take place in Zagreb, Croatia May 23. -
27. 2005.

The deadline for the submission of abstract is now February 15. More
information about the conference can be found at http://www.cidoc2005.com.

Regards,
Christian-Emil Ore
Chair of CIDOC

****************************
Worldwide, museums have put in and are still investing enormous efforts in
the field of the expert documentation of the objects and collections that
they have assembled, are looking after, investigating and presenting. The
global information community expects and peremptorily demands access to the
information and knowledge stored in museums. For whom are we documenting if
not for this community? So let us take the time to consider museum
documentation from the point of view of the user. Are the forms of
documentation that we use in museums going to be just as interesting and
relevant to the general public? What kind of expectations does the public
have? How can we affect the museum-public relationship through documentation?


The theme of this conference is "Documentation and Users". The list of
sub-topics proposed below does not aim at finality or exhaustiveness, and
every contribution to the theme is welcome:
    * From inventorisation and cataloguing to documentation for users:
internal vs external documentation, professional vs public priorities,
visitors vs users
    * The impact of users on documentation:
    * Interaction, information exchange, community expectations, focusing
on groups of users
    * The digital heritage: new forms of museum documentation, contents
management vs collection management, user-friendly knowledge systems, the
Internet and electronic possibilities, digital preservation
    * Problems and challenges: additional professional efforts, costs,
copyright, theft, etc.

--=====================_69470890==.ALT
Content-Type: text/html; charset="us-ascii"

<html>
<body>
Dear all,<br>
ICOM-CIDOC is an international committee under ICOM, (International
Council of Museums,
<a href="http://icom.museum/" eudora="autourl">http://icom.museum/</a>,
<a href="http://www.willpowerinfo.myby.co.uk/cidoc/" eudora="autourl">http://www.willpowerinfo.myby.co.uk/cidoc/</a>),
and is the international focus for the documentation interests of museums
and related organizations. It has over 450 members in 60 countries.
<br><br>
A considerable amount of the documentation in museums are texts of great
cultural historical interest both viewed as artefacts and with respect to
the content. Unfortunately the use and knowlegde of TEI is not as
widespread as it could be in the museum communities. The CIDOC 2005
conference is very good opportunity for the TEI community to meet the
museum documentation world.<br><br>
The annual CIDOC conference will take place in Zagreb, Croatia May 23. -
27. 2005. <br><br>
The deadline for the submission of abstract is now February 15. More
information about the conference can be found at
<a href="http://www.cidoc2005.com/" eudora="autourl">http://www.cidoc2005.com</a>.
<br><br>
Regards,<br>
Christian-Emil Ore<br>
Chair of CIDOC<br><br>
****************************<br>
Worldwide, museums have put in and are still investing enormous efforts
in the field of the expert documentation of the objects and collections
that they have assembled, are looking after, investigating and
presenting. The global information community expects and peremptorily
demands access to the information and knowledge stored in museums. For
whom are we documenting if not for this community? So let us take the
time to consider museum documentation from the point of view of the user.
Are the forms of documentation that we use in museums going to be just as
interesting and relevant to the general public? What kind of expectations
does the public have? How can we affect the museum-public relationship
through documentation?<br>
&nbsp;<br>
&nbsp; <br>
The theme of this conference is “<b>Documentation and Users</b>”. The
list of sub-topics proposed below does not aim at finality or
exhaustiveness, and every contribution to the theme is welcome:
<ul>
<li>From inventorisation and cataloguing to documentation for users:
internal vs external documentation, professional vs public priorities,
visitors vs users
<li>The impact of users on documentation:
<li>Interaction, information exchange, community expectations, focusing
on groups of users
<li>The digital heritage: new forms of museum documentation, contents
management vs collection management, user-friendly knowledge systems, the
Internet and electronic possibilities, digital preservation
<li>Problems and challenges: additional professional efforts, costs,
copyright, theft, etc.
</ul></body>
</html>

--=====================_69470890==.ALT--
=========================================================================
Date:         Wed, 26 Jan 2005 06:40:27 -0500
Reply-To:     Clifford Wulfman <Clifford_Wulfman@BROWN.EDU>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Clifford Wulfman <Clifford_Wulfman@BROWN.EDU>
Subject:      Re: [tan] emacs spelling
Comments: cc: Sebastian Rahtz <sebastian.rahtz@COMPUTING-SERVICES.OXFORD.AC.UK>
In-Reply-To:  <41F76058.9020400@computing-services.oxford.ac.uk>
Mime-Version: 1.0 (Apple Message framework v619)
Content-Type: multipart/alternative; boundary=Apple-Mail-1--416591624

--Apple-Mail-1--416591624
Content-Transfer-Encoding: 7bit
Content-Type: text/plain;
        charset=US-ASCII;
        format=flowed

Er, it *is* a bit more if you're working under OS X: the Emacs.app
doesn't inherit an environment from the shell (it isn't usually
launched from a shell), so it often has trouble finding external
programs. You have to add the path to ispell to Emacs' exec-path:

(setq exec-path (cons "/usr/local/bin" exec-path))

I put this in my .emacs file.

(Thanks go to
http://clozure.com/pipermail/openmcl-devel/2004-January/001350.html for
this tip, by the way: Mr. Byers explains the situation very clearly.
Worth a read if you use Emacs in OS X.)



        Dr. Clifford E. Wulfman
        Project Manager
        Modernist Journals Project


On Jan 26, 2005, at 4:18 AM, Sebastian Rahtz wrote:

> er, you install the "ispell" package. no more, no less.
>
> Sebastian

--Apple-Mail-1--416591624
Content-Transfer-Encoding: 7bit
Content-Type: text/enriched;
        charset=US-ASCII

Er, it *is* a bit more if you're working under OS X: the Emacs.app
doesn't inherit an environment from the shell (it isn't usually
launched from a shell), so it often has trouble finding external
programs. You have to add the path to ispell to Emacs' exec-path:


(setq exec-path (cons "/usr/local/bin" exec-path))


I put this in my .emacs file.


(Thanks go to
http://clozure.com/pipermail/openmcl-devel/2004-January/001350.html
for this tip, by the way: Mr. Byers explains the situation very
clearly. Worth a read if you use Emacs in OS X.)





<fontfamily><param>Helvetica</param><x-tad-bigger>      Dr. Clifford E.
Wulfman

        Project Manager

        Modernist Journals Project</x-tad-bigger><x-tad-bigger>


</x-tad-bigger></fontfamily>

On Jan 26, 2005, at 4:18 AM, Sebastian Rahtz wrote:


<excerpt>er, you install the "ispell" package. no more, no less.


Sebastian

</excerpt>
--Apple-Mail-1--416591624--
=========================================================================
Date:         Wed, 26 Jan 2005 11:32:25 +0000
Reply-To:     Peter Heslin <public@HESLIN.ECLIPSE.CO.UK>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Peter Heslin <public@HESLIN.ECLIPSE.CO.UK>
Subject:      Re: [tan] emacs spelling

On 2005-01-26, Daniel O'Donnell <daniel.odonnell@uleth.ca> wrote:
>  Currently, if in xml mode I go to tools>Spell checking>check buffer I
>  get a "searching for program; no such directory or file, ispell" error.

As others have said, you need to install ispell, which is a separate,
stand-alone program.  Or, you can install aspell, which is a better
replacement for ispell, and which has an ispell compatibility mode.
Aspell is much better at coming up with intelligent suggestions for
correct spelling.

You don't say what platform you are using, but if you are on Windows,
then aspell is probably easier to install than ispell, since you can
install it as part of the cygwin environment (www.cygwin.com).  If you
are on a Mac, then both ispell and aspell are available as part of
Fink (fink.sf.net).  On Linux, both are readily available as packages
for most distributions.

If you regularly type languages other than English, you may want also
to install other dictionaries; again, aspell has many more available
than ispell.

If you do install aspell, then you need to tell Emacs to use that
instead of ispell, by putting this in your .emacs (or _emacs)
configuration file:

    ;; For older versions of Emacs
    (setq-default ispell-program-name "aspell")
    ;; For newer versions
    (setq ispell-really-aspell t)

    ;; If the wrong language is chosen by default, you can change it
    ;; like this:
    (set-default 'ispell-local-dictionary "american")

There are two ways of using ispell/aspell.  The traditional way is as
you described, to run through and prompt at each misspelling.  But you
can also have it underline suspected misspellings as you type (just
as Word does).  This is done with flyspell-mode.  Try M-x
flyspell-mode.  If that doesn't work (because you have an older
version of Emacs), you'll have to install it separately
http://www-sop.inria.fr/mimosa/Manuel.Serrano/flyspell/flyspell.html

What I love best about flyspell-mode is the C-; command, which
auto-corrects the previous misspelling without you having to go back
and put the cursor there and correct it by hand; if the first
suggested spelling is not correct, hit it again and again to cycle
through suggestions.  If you do use aspell and flyspell-mode, I
suggest putting the following line in your configuration file, which
will tell aspell to work a bit quicker at the expense of the quality
of some of its suggestions (default aspell is noticeably slower than
ispell):

    (setq ispell-extra-args '("--sug-mode=fast"))

To turn on flyspell in all xml-mode buffers, use this line:

    (add-hook 'xml-mode-hook 'flyspell-mode)

or, to turn it on for other types of buffers, use this instead:

    (add-hook 'text-mode-hook 'flyspell-mode)

Best wishes,

Peter
=========================================================================
Date:         Wed, 26 Jan 2005 19:18:57 +0700
Reply-To:     Doug Cooper <doug@TH.NET>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Doug Cooper <doug@TH.NET>
Subject:      Emacs, shemacs
MIME-Version: 1.0
Content-Type: text/plain; charset="iso-8859-1"
Content-Transfer-Encoding: 7bit

(with apologies to Gary Larsen's dog Ginger)

What many recent messages have said:

> > I only recently picked up emacs for the first time, and I didn't ...
> > I think the notable feature of Emacs usage is that ...
> > What I love best about flyspell-mode is the C-; command, which

What I -- and I assume many other TEI-L subscribers -- hear:

> > blah blah blah blah blah blah emacs blah blah blah blah...
> > blah blah blah Emacs blah blah blah blah blah blah ...
> > blah blah blah blah blah blah blah blah blah blah blah ...

 'Nuff said.
=========================================================================
Date:         Wed, 26 Jan 2005 12:35:28 +0000
Reply-To:     Lou Burnard <lou.burnard@COMPUTING-SERVICES.OXFORD.AC.UK>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Lou Burnard <lou.burnard@COMPUTING-SERVICES.OXFORD.AC.UK>
Subject:      Re: Emacs, shemacs
Comments: To: Doug Cooper <doug@TH.NET>
In-Reply-To:  <200501261229.j0QCTA329094@listserv.brown.edu>
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii; format=flowed
Content-Transfer-Encoding: 7bit

Sorry Doug, but occasional bursts of blahblahblah come with the
territory. TEI-L is populated by people who have all sorts of weird
obsessions. It's true that we may have been emaxxing out over the last
week or so, but believe me there are plenty of people who feel the same
way about -- say -- how to encode abbreviations in manuscripts, what the
ontological status of a feature structure is, and whether blorts have wings.

That's why it's such a cool list...

Lou

Doug Cooper wrote:
> (with apologies to Gary Larsen's dog Ginger)
>
> What many recent messages have said:
>
>
>>>I only recently picked up emacs for the first time, and I didn't ...
>>>I think the notable feature of Emacs usage is that ...
>>>What I love best about flyspell-mode is the C-; command, which
>
>
> What I -- and I assume many other TEI-L subscribers -- hear:
>
>
>>>blah blah blah blah blah blah emacs blah blah blah blah...
>>>blah blah blah Emacs blah blah blah blah blah blah ...
>>>blah blah blah blah blah blah blah blah blah blah blah ...
>
>
>  'Nuff said.
>
=========================================================================
Date:         Wed, 26 Jan 2005 10:04:39 -0700
Reply-To:     daniel.odonnell@uleth.ca
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Daniel O'Donnell <daniel.odonnell@ULETH.CA>
Organization: Department of English, University of Lethbridge
Subject:      Re: [tan] emacs spelling
Comments: To: Stuart Yeates <stuart.yeates@COMPUTING-SERVICES.OXFORD.AC.UK>
In-Reply-To:  <200501260838.j0Q8cw313007@listserv.brown.edu>
MIME-Version: 1.0
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit

Stuart Yeates wrote:
 >
 > (1) Do you have ispell installed?

I have ispell.el and ispell.elc in a couple of directories: they were
always in tei-emacs\emacs-21.2\lisp\textmodes; now I've also got them in
tei-emacs\bin and tei-emacs\emacs-21.2\bin
 >
 > (2) Is ispell in you default path? [Go to the command line and type
 > "ispell", you'll either get a messages about how to use ispell or a
 > message that ispell was not found].

No. In fact this has always been the problem.
 >
 > (3) Do you have the correct language dictionaries installed? [Emacs has
 > an idea of what language (i.e. American English or British English) it
 > is using and will expect an appropriate dictionary].

I don't think it has made it that far yet.
 >
 > To help fix these things we need to know:
 >
 > (a) What platform are you using Windows/Mac/Linux?

WinXP
 >
 > (b) What version of emacs are you using?

21.2.1

Thanks, Dan
 >
 > cheers
 > stuart
 > --
 > Stuart Yeates            stuart.yeates@computing-services.oxford.ac.uk
 > OSS Watch                                  http://www.oss-watch.ac.uk/
 > Humbul Humanities Hub                         http://www.humbul.ac.uk/
--
Daniel Paul O'Donnell, PhD
Associate Professor of English
University of Lethbridge
Lethbridge AB T1K 3M4
Tel. (403) 329-2377
Fax. (403) 382-7191
E-mail <daniel.odonnell@uleth.ca>
Home Page <http://people.uleth.ca/~daniel.odonnell/>
The Digital Medievalist Project: <http://www.digitalmedievalist.org/>
=========================================================================
Date:         Wed, 26 Jan 2005 17:20:23 +0000
Reply-To:     Stuart Yeates <stuart.yeates@COMPUTING-SERVICES.OXFORD.AC.UK>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Stuart Yeates <stuart.yeates@COMPUTING-SERVICES.OXFORD.AC.UK>
Subject:      Re: [tan] emacs spelling
Comments: To: daniel.odonnell@uleth.ca
In-Reply-To:  <41F7CDA7.1070006@uleth.ca>
MIME-Version: 1.0
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit

Daniel O'Donnell wrote:
> Stuart Yeates wrote:
>  >
>  > (1) Do you have ispell installed?
>
> I have ispell.el and ispell.elc in a couple of directories: they were
> always in tei-emacs\emacs-21.2\lisp\textmodes; now I've also got them in
> tei-emacs\bin and tei-emacs\emacs-21.2\bin

ispell.el and ispell.elc are not the spell checker, they are the emacs
interface to the external spell checker. I suggest that you go to:

http://www.luziusschneider.com/Speller/English/

and follow the appropiate instructions.

cheers
stuart

--
Stuart Yeates            stuart.yeates@computing-services.oxford.ac.uk
OSS Watch                                  http://www.oss-watch.ac.uk/
Humbul Humanities Hub                         http://www.humbul.ac.uk/
=========================================================================
Date:         Wed, 26 Jan 2005 17:21:41 +0000
Reply-To:     Sebastian Rahtz <sebastian.rahtz@COMPUTING-SERVICES.OXFORD.AC.UK>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Sebastian Rahtz <sebastian.rahtz@COMPUTING-SERVICES.OXFORD.AC.UK>
Subject:      Re: [tan] emacs spelling
Comments: To: daniel.odonnell@uleth.ca
In-Reply-To:  <200501261704.j0QH4a323359@listserv.brown.edu>
MIME-Version: 1.0
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit

Daniel O'Donnell wrote:

>Stuart Yeates wrote:
> >
> > (1) Do you have ispell installed?
>
>I have ispell.el and ispell.elc in a couple of directories: they were
>always in tei-emacs\emacs-21.2\lisp\textmodes; now I've also got them in
>tei-emacs\bin and tei-emacs\emacs-21.2\bin
> >
>
>
You misunderstand, I am afraid.
ispell.el(c) is the Emacs interface to ispell,
not the software itself.

Surely someone here uses ispell under Windows and can advise?
I will add it to the tei-emacs bundle for Windows at some point.

--
Sebastian Rahtz
Information Manager, Oxford University Computing Services
13 Banbury Road, Oxford OX2 6NN. Phone +44 1865 283431

OSS Watch: JISC Open Source Advisory Service
http://www.oss-watch.ac.uk
=========================================================================
Date:         Wed, 26 Jan 2005 19:01:02 +0100
Reply-To:     Sylvain Loiseau <sylvain.loiseau@U-PARIS10.FR>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Sylvain Loiseau <sylvain.loiseau@U-PARIS10.FR>
Subject:      Re: [tan] emacs spelling
MIME-Version: 1.0
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 8bit

> Surely someone here uses ispell under Windows and can advise?
> I will add it to the tei-emacs bundle for Windows at some point.

Sure: I install it 2 minutes ago, thanks to your advices :-) :

I downloaded aspell here :
http://aspell.net/win32/

Change the path variable (adding
"D:\Program Files\Aspell\bin")

add the following in .emacs :
    (setq-default ispell-program-name "aspell")
(Thanks Peter Heslin),

and it works. Which function C-; is supposed to call? I don't found function
with the behaviour described.

Yours,
SL



----------------------------------------------------------------
This message was sent using IMP, the Internet Messaging Program.
=========================================================================
Date:         Thu, 27 Jan 2005 18:41:07 +0900
Reply-To:     acmuller@jj.em-net.jp
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Charles Muller <cmuller-lst@JJ.EM-NET.JP>
Subject:      Re: Emacs, shemacs
In-Reply-To:  <0b6a01c503a1$395cacc0$0e00000a@bangkok>
Mime-Version: 1.0
Content-Type: Text/Plain; charset=us-ascii
Content-Transfer-Encoding: 7bit

Doug Cooper wrote:

> What I -- and I assume many other TEI-L subscribers -- hear:
>
> > > blah blah blah blah blah blah emacs blah blah blah blah...
> > > blah blah blah Emacs blah blah blah blah blah blah ...
> > > blah blah blah blah blah blah blah blah blah blah blah ...

Well, since TEI-Emacs is my XML editor of first choice, I'll be
counted as one who is delighted to pick up as many Emacs tips as
possible, and I have to assume that there are many TEI-L subscribers
who feel the same way. It also happens to be the case that many of
those who are asking and giving advice about Emacs, are also asking
and giving advice about oXygen, Serna, eXist, and many other fine
tools. Try not to take it so seriously.

Chuck

---------------------------
Charles Muller

Toyo Gakuen University
Faculty of Humanities
1660 Hiregasaki, Nagareyama-shi
Chiba 270-0161 JAPAN
Mobile Phone: 090-9310-1787

Web Site: Resources for East Asian Language and Thought
http://www.acmuller.net

<acmuller[at]jj.em-net.jp>
=========================================================================
Date:         Thu, 27 Jan 2005 15:39:19 +0100
Reply-To:     Katrien Depuydt <depuydt@INL.NL>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Katrien Depuydt <depuydt@INL.NL>
Subject:      Announcement: Dutch Parole Corpus
MIME-Version: 1.0
Content-Type: multipart/alternative;
              boundary="------------050806020900010209050407"

This is a multi-part message in MIME format.
--------------050806020900010209050407
Content-Type: text/plain; charset=us-ascii; format=flowed
Content-Transfer-Encoding: 7bit

A new INL corpus has become available via Internet: the Dutch PAROLE
corpus, a corpus of modern Dutch texts, TEI-encoded and tagged with part
of speech and lemma. Unlike the other INL Internet corpora,  this corpus
is accessible through a web browser (Microsoft Internet Explorer 5.5 or
higher).

Particular attention has been paid to the user-friendliness of the
interface, enabling the user to submit complex queries (using both
TEI-encoding and PoS and lemma) in a relatively simple way. Detailed
help texts are available as well, both general and screen-related.

Interface, documentation and help texts are also available in English.
All information can be found at http://parole.inl.nl
<http://rulxug/html-eng/index.html>. In order to gain (free) access,
please send a signed user agreement to the Institute for Dutch
Lexicology (INL), by fax: (0031) (0)71-5272115, or by mail: Postbus
9515, 2300 RA Leiden.



De IT and Language Database Departments of the Institute for Dutch
Lexicology (INL)


--------------050806020900010209050407
Content-Type: text/html; charset=us-ascii
Content-Transfer-Encoding: 7bit

<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
<head>
  <meta content="text/html;charset=ISO-8859-1" http-equiv="Content-Type">
  <title></title>
</head>
<body bgcolor="#ffffff" text="#000000">
<p class="MsoNormal"><span lang="EN-GB">A new INL corpus has become
available via
Internet: the Dutch PAROLE corpus, a corpus of modern Dutch texts,
TEI-encoded
and tagged with part of speech and lemma. Unlike the other INL Internet
corpora,<span style="">&nbsp; </span>this corpus is accessible through a
web browser
(Microsoft Internet Explorer 5.5 or higher). </span></p>
<p class="MsoNormal"><span lang="EN-GB">Particular attention has been
paid to the user-friendliness
of the interface, enabling the user to submit complex queries (using
both
TEI-encoding and PoS and lemma) in a relatively simple way. Detailed
help texts
are available as well, both general and screen-related.</span></p>
<p class="MsoNormal"><span lang="EN-GB">Interface, documentation and
help texts are
also available in English. All information can be found at <a
 href="http://rulxug/html-eng/index.html">http://parole.inl.nl</a>. In
order to
gain (free) access, please send a signed user agreement to the
Institute for
Dutch Lexicology (INL), by fax: (0031) (0)71-5272115, or by mail:
Postbus 9515,
2300 RA Leiden.</span></p>
<p class="MsoNormal"><span lang="EN-GB"><o:p>&nbsp;</o:p></span></p>
<p class="MsoNormal"><span lang="EN-GB">De IT and Language Database
Departments of
the Institute for Dutch Lexicology (INL)</span></p>
</body>
</html>

--------------050806020900010209050407--
=========================================================================
Date:         Thu, 27 Jan 2005 16:13:09 +0100
Reply-To:     Katrien Depuydt <depuydt@INL.NL>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Katrien Depuydt <depuydt@INL.NL>
Subject:      Dutch Parole Corpus: hyperlink
MIME-Version: 1.0
Content-Type: text/html; charset=us-ascii
Content-Transfer-Encoding: 7bit

<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
<head>
  <meta content="text/html;charset=ISO-8859-1" http-equiv="Content-Type">
  <title></title>
</head>
<body bgcolor="#ffffff" text="#000000">
<meta content="text/html;charset=ISO-8859-1" http-equiv="Content-Type">
<title></title>
<><span lang="EN-GB">Our apologies. Something seems to have gone wrong
with the hyperlink to the Parole Corpus. The correct address is :
<a class="moz-txt-link-freetext" href="[http://parole.inl.nl">http://parole.inl.nl</a]http://parole.inl.nl">http://parole.inl.nl</a>. The second link you might have found in our
previous mail is the direct link to the English version of the Parole
interface.<br>
<br>
<br>
<br>
<br>
Announcement:<br>
<br>
A new INL corpus has become
available via
Internet: the Dutch PAROLE corpus, a corpus of modern Dutch texts,
TEI-encoded
and tagged with part of speech and lemma. Unlike the other INL Internet
corpora,<span style="">&nbsp; </span>this corpus is accessible through a
web browser
(Microsoft Internet Explorer 5.5 or higher). </span></>
<p class="MsoNormal"><span lang="EN-GB">Particular attention has been
paid to the user-friendliness
of the interface, enabling the user to submit complex queries (using
both
TEI-encoding and PoS and lemma) in a relatively simple way. Detailed
help texts
are available as well, both general and screen-related.</span></p>
<p class="MsoNormal"><span lang="EN-GB">Interface, documentation and
help texts are
also available in English. All information can be found at
<a class="moz-txt-link-freetext" href="[http://parole.inl.nl">http://parole.inl.nl</a]http://parole.inl.nl">http://parole.inl.nl</a>. In
order to
gain (free) access, please send a signed user agreement to the
Institute for
Dutch Lexicology (INL), by fax: (0031) (0)71-5272115, or by mail:
Postbus 9515,
2300 RA Leiden.</span></p>
<p class="MsoNormal"><span lang="EN-GB"><o:p>&nbsp;</o:p></span></p>
<p class="MsoNormal"><span lang="EN-GB">The IT and Language Database
Departments of
the Institute for Dutch Lexicology (INL)</span></p>
</body>
</html>
=========================================================================
Date:         Thu, 27 Jan 2005 15:50:48 +0000
Reply-To:     James.Cummings@ota.ahds.ac.uk
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         James Cummings <James.Cummings@OTA.AHDS.AC.UK>
Organization: Oxford Text Archive
Subject:      Admin and Collection relation metadata
MIME-Version: 1.0
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit

Hi all,

We are looking for a straightforward way to add some collection-level
and administrative metadata to our existing headers.  This will be used
to generate metadata to fit into a METS wrapper elsewhere, but we want
to see where in the teiHeader might be the best place to store it.

1) We want to store some information about the status and policy of the
accrual of the deposit:

<accrualPolicy>closed|passive|active|selective</accrualPolicy>
<accrualMethod>purchase|deposit</accrualMethod>
<accrualPeriodicity>closed|irregular|periodic</accrualPeriodicity>

These being fairly self-evidently whether a deposit is locked, actively,
  passively or selectively looking to have material added to it to it.
In most cases, for us, this will be closed.  Whether the deposit was
purchased or deposited (again, in our case always deposit), and whether
we don't look for new material for this resource, do so irregularly or
periodically.  I have some ideas where I would put this data, but
thought I'd ask for any helpful suggestions.


2) The second set of information we want to store is how this deposit
relates to others in the collection.  So the data we need to be able to
generate is of the sort:
<isPartOf uri="http://foo.com/foo"/>
<hasPart uri="http://foo.com/foo"/>
<associatedCollection uri="http://foo.com/foo"/>
<associatedPublication uri="http://foo.com/foo"/>
<hasDescription uri="http://foo.com/foo"/>
<isDescriptionOf uri="http://foo.com/foo"/>
<hasVersion uri="http://foo.com/foo"/>
<isVersionOf uri="http://foo.com/foo"/>
<hasFormat uri="http://foo.com/foo"/>
<isFormatOf uri="http://foo.com/foo"/>

Where:
isPartOf: contains the identifier of a second resource that contains the
electronic resource.

hasPart: contains the identifier of any second resource contained within
the electronic resource

associatedCollection: contains the identifier of a second resource that
is associated by provenance with the electronic resource.

hasDescription: contains the identifier of a second resource (hard-copy
or electronic) that describes the electronic resource.

isDescriptionOf: contains the identifier of a second resource that is
described by the electronic resource.

hasVersion: contains the identifier of a second resource which is a
later version of the deposited electronic resource.

isVersionOf: contains the identifier of a second resource of which the
deposited electronic resource is a version.

hasFormat: contains the identifier of a second resource (physical or
electronic) that reproduces the deposited electronic resource in another
format or technology whilst leaving the intellectual content unchanged.

isFormatOf: contains the identifier of a pre-existing resource that the
deposited electronic resource reproduces in another format or technology
whilst leaving the intellectual content unchanged.

Again, I have thoughts on where these uri's should be stored, but didn't
want to reinvent the wheel.  Nor did I want to use P5 and embed the
desired elements somewhere in a different context, just wanted to find
where their proper home should be in the header.

Many thanks for any suggestions,
-James

--
Dr James Cummings, Oxford Text Archive, University of Oxford
James dot Cummings at oucs dot ox dot ac dot uk
=========================================================================
Date:         Thu, 27 Jan 2005 12:34:25 -0500
Reply-To:     David Sewell <dsewell@VIRGINIA.EDU>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         David Sewell <dsewell@VIRGINIA.EDU>
Subject:      Valid HTML Considered Harmful?
MIME-Version: 1.0
Content-Type: TEXT/PLAIN; charset=US-ASCII

Everyone,

This may have been discussed in the past, but if so I don't see it in
the list archives.

There's a major difference in the content model of TEI and (X)HTML when
it comes to block-level elements. In TEI, they can generally be nested;
in HTML, they cannot.

Legal TEI:  <p>As someone said: <quote>blah blah</quote> and so on.</p>
Legal HTML: <p>As someone said:</p><blockquote>blah blah</blockquote>
            <p>and so on.</p>

Obviously this causes big headaches if your goal is to generate valid
HTML from valid TEI documents. I'm guessing that most of us just figure
that the HTML content model is stupid in this respect and that browsers
know how to handle nested block elements, and therefore in
transformation stylesheets we just turn <quote> into <blockquote>
regardless of whether or not it's inside a <p> or between them. (The
alternative requires horrible incantations involving <xsl:text
disable-output-escaping="yes"> to close and open tags, and such like.)

Someone once put it succinctly to me: "If it's not the archival form of
the document, don't agonize over validity." Reasonable? Is it time for a
position paper, "Valid HTML Considered Harmful"? Or do you still feel a
pang of guilt if you're proclaiming markup standards with the right hand
and sending out Web pages that flunk the W3C validator test with the
left?

DS

--
David Sewell, Editorial and Technical Manager
Electronic Imprint, The University of Virginia Press
PO Box 400318, Charlottesville, VA 22904-4318 USA
Courier: 310 Old Ivy Way, Suite 302, Charlottesville VA 22903
Email: dsewell@virginia.edu   Tel: +1 434 924 9973
Web: http://www.ei.virginia.edu/
=========================================================================
Date:         Thu, 27 Jan 2005 12:42:21 -0500
Reply-To:     Syd_Bauman@Brown.edu
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Syd Bauman <Syd_Bauman@BROWN.EDU>
Subject:      Re: How does one add type to a.global (as modification to P4,
              not something in P5)
In-Reply-To:  <008e01c4ffe1$dbcebca0$0201010a@michaelnt2k>
MIME-Version: 1.0
Content-Type: multipart/mixed; boundary="He8bd/JGSb"
Content-Transfer-Encoding: 7bit

--He8bd/JGSb
Content-Type: text/plain; charset=us-ascii
Content-Description: message body text
Content-Transfer-Encoding: 7bit

Speaking as one of the rabble, my personal opinion on the
globalization of type= is that it's a bad idea. That said, there may
well be TEI elements that deserve a type= but don't have one. What
elements in particular did you need a type= on, Daniel?

I really believe in the dictum "constrain your data early and
often".[1] And thus, at least for now, I still think that it's better
to constrain your data with your schema than with your stylesheet.
Therefore I tend to think that most TEI users should be redeclaring
the type= attribute as a closed value list ("EnumeratedType" in
XMLese). E.g. the type= attribute of the <name> element might be
redeclared as follows at the StarTrek-in-TEI project:

   type ( human | alien | place | ship ) #REQUIRED

So even if you convinced me that most every TEI element deserved a
type= attribute, globalization would not be the way to do it, at
least at the project level. Even at the TEI level it would mean that
the 13 elements that already have closed value lists for type= would
become problematic.

Another reason why adding type= to a.global is problematic is mostly
practical. In order to do so, assuming just the prose base tag set
and no additional tagsets, you need to declare:
* 38 "controlling" parameter entities
* 6 parameter entities just because they need to be declared before
  referenced -- i.e., there's no change to the declaration, just a
  change to where it is positioned in the DTD (I'll call this
  "predeclare")
* 25 elements and their corresponding attribute lists
* 3 attribute class parameter entities[2]

In many cases, redeclaring something is a recipe for problems later.
E.g., let's say you have a project that uses just the prose base tag
set and wrote extension files with all the above. You then get a
grant to perform some metrical analysis on the songs included in your
project, so you decide to switch from the prose base tag set to the
verse base tag set to pick up the met= and rhyme= attributes. You
change "TEI.prose" to "TEI.verse" in your doctype declaration subset,
and add met= and rhyme= attributes to your <lg> tags. On validating,
you'll find that the met= and rhyme= attributes are not declared. It
may take you quite a while to figure out why not -- that a.metrical
is predeclared in your local extensions .ent file, and when you created
that file you were not using the verse base, so the declaration you
copied declared it to be nil.

So, my advice is to shun globalization of type=, and instead to think
carefully about which elements need a type=, and what possible values
there are for each one, and then add them individually with a closed
value list as needed.[3]

An example of how to add type= with possible values "postal",
"e-mail", and "shipping" to <address> is appended.


Notes
-----
[1] <bibl>GML source at http://www.tei-c.org/Vault/ED/edw31.gml, in
    HTML at http://www.w3.org/People/cmsmcq/1992/edw31.html.</bibl>

[2] You'd think it would be easier if you used the additional tagset
    for linking, segmentation, and alignment and just added
    "%a.typed;" to the declaration of a.global. In a way, it is, as
    you only need to predeclare 5 instead of 6 parameter entities.
    But because there are more elements and classes that now have
    type=, you need to declare 4 additional elements and 3 additional
    attribute classes. So this method is only a plus if you are
    already using the additional tagset for linking, segmentation,
    and alignment and also want subtype= as a global attribute.
    (Which seems like a very bad idea to me!)

[3] Note that if you are going to declare a generic type= that can
    take any value (rather than a closed value list, which I highly
    recommend), you should seriously consider using NMTOKEN or
    NMTOKENS as the attribute type, rather than CDATA. The main
    differences are that NMTOKENS will
    * prohibit non-name characters (e.g. U+0024 the dollar sign,
      U+00B1 the plus-minus sign, or U+2980 the triple verticle bar
      delimiter) inside the value
    * normalize leading and trailing blanks to nil
    * normalize internal whitespace to a single blank
    and NMTOKEN will prohibit whitespace inside the value rather than
    normalize it. If type= is declared as CDATA, the parser
    would report that
       <div type="variable index">
    is different than
       <div type="variable  index">
    but if type= is declared as NMTOKENS it would report them both as
    "variable index". (And would report an error if declared as
    NMTOKEN :-) Of course, I personally think the best solution is to
    declare type= with a controlled vocabulary of single tokens:
       type ( variableIndex | conceptIndex | functionIndex ... ) #REQUIRED
    I think there is a pretty strong argument that TEI should be
    using NMTOKEN or NMTOKENS instead of CDATA for type=.

Appendix
--------

--He8bd/JGSb
Content-Type: text/xml
Content-Description: TEI.extensions.ent
Content-Disposition: inline;
        filename="addr.ent"
Content-Transfer-Encoding: 7bit

<!-- ignore the TEI P4 declaration of <address> in teicore2.dtd, so
     that we can declare it ourselves to make changes -->
<!ENTITY % address 'IGNORE'>

--He8bd/JGSb
Content-Type: text/xml
Content-Description: TEI.extensions.dtd
Content-Disposition: inline;
        filename="addr.dtd"
Content-Transfer-Encoding: 7bit

<!--
 ** our redefined <address> elment to restrict values of type=
 -->
<!-- first, just repeat the element declaration; copied-and-pasted -->
<!-- from file teicore2.dtd -->
<!ELEMENT %n.address; %om.RO;  ( (%m.Incl;)*,
                    ( ((%n.addrLine;), (%m.Incl;)*)+ | ((%m.addrPart;), (%m.Incl;)*)* ) ) >
<!-- but for the attribute list declaration, after copying it insert -->
<!-- a type= attribute -->
<!ATTLIST %n.address;
      %a.global;
      type ( postal | e-mail | shipping ) #REQUIRED
      TEIform CDATA 'address'  >

--He8bd/JGSb
Content-Type: text/xml
Content-Description: sample instance
Content-Disposition: inline;
        filename="addr.xml"
Content-Transfer-Encoding: 7bit

<?xml version="1.0" encoding="UTF-8" ?>
<!DOCTYPE TEI.2 PUBLIC "-//TEI P4//DTD Main Document Type//EN" '/your/path/to/TEI_P4/DTD/tei2.dtd' [
 <!ENTITY % TEI.XML      'INCLUDE' >
 <!ENTITY % TEI.prose    'INCLUDE' >
 <!ENTITY % TEI.extensions.ent SYSTEM 'addr.ent' >
 <!ENTITY % TEI.extensions.dtd SYSTEM 'addr.dtd' >
]>
<TEI.2>
  <teiHeader>
    <fileDesc>
      <titleStmt>
        <title>test</title>
      </titleStmt>
      <publicationStmt>
        <address type="e-mail">
          <addrLine>tei-l@listserv.brown.edu</addrLine>
        </address>
      </publicationStmt>
      <sourceDesc>
        <p>None, this is the source</p>
      </sourceDesc>
    </fileDesc>
  </teiHeader>
  <text>
    <body>
      <p>See? It worked.</p>
    </body>
  </text>
</TEI.2>

--He8bd/JGSb--
=========================================================================
Date:         Thu, 27 Jan 2005 10:42:48 -0700
Reply-To:     daniel.odonnell@uleth.ca
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Daniel O'Donnell <daniel.odonnell@ULETH.CA>
Organization: Department of English, University of Lethbridge
Subject:      Re: Valid HTML Considered Harmful?
Comments: To: David Sewell <dsewell@VIRGINIA.EDU>
In-Reply-To:  <200501271734.j0RHYS301452@listserv.brown.edu>
MIME-Version: 1.0
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit

David Sewell wrote:
> Everyone,
>
> This may have been discussed in the past, but if so I don't see it in
> the list archives.
>
> There's a major difference in the content model of TEI and (X)HTML when
> it comes to block-level elements. In TEI, they can generally be nested;
> in HTML, they cannot.
>
> Legal TEI:  <p>As someone said: <quote>blah blah</quote> and so on.</p>
> Legal HTML: <p>As someone said:</p><blockquote>blah blah</blockquote>
>             <p>and so on.</p>
>
> Obviously this causes big headaches if your goal is to generate valid
> HTML from valid TEI documents. I'm guessing that most of us just figure
> that the HTML content model is stupid in this respect and that browsers
> know how to handle nested block elements, and therefore in
> transformation stylesheets we just turn <quote> into <blockquote>
> regardless of whether or not it's inside a <p> or between them. (The
> alternative requires horrible incantations involving <xsl:text
> disable-output-escaping="yes"> to close and open tags, and such like.)

Wouldn't you do this example like this:

<p>As someone said <q>blah blah blah</q> and so on?</p>

Then there is no content model conflict.

For larger block level quotations, I've perhaps been cheating in my tei.
I always do:

<p>As someone said at great length:</p>
<quote>
<p>One paragraph of interesting citation</p>
<p>Two paragraphs of interesting citation</p>
</quote>
<p>And so on and so forth</p>

Again no real xsl issue, but perhaps that's why its dangerous?

>
> Someone once put it succinctly to me: "If it's not the archival form of
> the document, don't agonize over validity." Reasonable? Is it time for a
> position paper, "Valid HTML Considered Harmful"? Or do you still feel a
> pang of guilt if you're proclaiming markup standards with the right hand
> and sending out Web pages that flunk the W3C validator test with the
> left?

The validation standards are important for portability and
accessibility, aren't they? I also like the little image.

>
> DS
>
> --
> David Sewell, Editorial and Technical Manager
> Electronic Imprint, The University of Virginia Press
> PO Box 400318, Charlottesville, VA 22904-4318 USA
> Courier: 310 Old Ivy Way, Suite 302, Charlottesville VA 22903
> Email: dsewell@virginia.edu   Tel: +1 434 924 9973
> Web: http://www.ei.virginia.edu/

--
Daniel Paul O'Donnell, PhD
Associate Professor of English
University of Lethbridge
Lethbridge AB T1K 3M4
Tel. (403) 329-2377
Fax. (403) 382-7191
E-mail <daniel.odonnell@uleth.ca>
Home Page <http://people.uleth.ca/~daniel.odonnell/>
The Digital Medievalist Project: <http://www.digitalmedievalist.org/>
=========================================================================
Date:         Thu, 27 Jan 2005 13:04:01 -0500
Reply-To:     David Sewell <dsewell@VIRGINIA.EDU>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         David Sewell <dsewell@VIRGINIA.EDU>
Subject:      Re: Valid HTML Considered Harmful?
Comments: To: Daniel O'Donnell <daniel.odonnell@uleth.ca>
In-Reply-To:  <41F92818.3040805@uleth.ca>
MIME-Version: 1.0
Content-Type: TEXT/PLAIN; charset=US-ASCII

On Thu, 27 Jan 2005, Daniel O'Donnell wrote:

> Wouldn't you do this example like this:
>
> <p>As someone said <q>blah blah blah</q> and so on?</p>
>
> Then there is no content model conflict.

Consider that "blah blah blah" is a long passage maybe containing a
couple of paragraphs. Anyway, it's a generalizable issue that affects a
lot of TEI-to-HTML translation. The <address> tag, for example (which
Sebastian's stylesheets turn into <blockquote>), which is the particular
tag I was working with in a stylesheet before I posted the note.

> For larger block level quotations, I've perhaps been cheating in my tei.
> I always do:
>
> <p>As someone said at great length:</p>
> <quote>
> <p>One paragraph of interesting citation</p>
> <p>Two paragraphs of interesting citation</p>
> </quote>
> <p>And so on and so forth</p>

There are places where that cheat would have serious consequences. For
example, in a legal document with numbered paragraphs, where the
paragraph clearly surrounded the embedded quotation. Splitting it up
would be illegal in maybe more than one sense.

--
David Sewell, Editorial and Technical Manager
Electronic Imprint, The University of Virginia Press
PO Box 400318, Charlottesville, VA 22904-4318 USA
Courier: 310 Old Ivy Way, Suite 302, Charlottesville VA 22903
Email: dsewell@virginia.edu   Tel: +1 434 924 9973
Web: http://www.ei.virginia.edu/
=========================================================================
Date:         Thu, 27 Jan 2005 11:43:38 -0700
Reply-To:     daniel.odonnell@uleth.ca
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Daniel O'Donnell <daniel.odonnell@ULETH.CA>
Organization: Department of English, University of Lethbridge
Subject:      Re: Valid HTML Considered Harmful?
Comments: To: David Sewell <dsewell@VIRGINIA.EDU>
In-Reply-To:  <200501271804.j0RI46305120@listserv.brown.edu>
MIME-Version: 1.0
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit

David Sewell wrote:
> On Thu, 27 Jan 2005, Daniel O'Donnell wrote:
>
>
>> Wouldn't you do this example like this:
>>
>> <p>As someone said <q>blah blah blah</q> and so on?</p>
>>
>> Then there is no content model conflict.
>
>
> Consider that "blah blah blah" is a long passage maybe containing a
> couple of paragraphs. Anyway, it's a generalizable issue that affects
>  a lot of TEI-to-HTML translation. The <address> tag, for example
> (which Sebastian's stylesheets turn into <blockquote>), which is the
>  particular tag I was working with in a stylesheet before I posted
> the note.

I realised you had a more general point in mind, but sometimes they can
vanish in the face of detail, so I thought I'd try.

And at risk of sounding snippy, the use of
blockquote for address in teihtml-misc.xsl looks like depreciated xhtml
to me:

> BLOCKQUOTE is for long quotations (block-level content) and Q is
> intended for short quotations (inline content) that don't require
> paragraph breaks.


> The usage of BLOCKQUOTE to indent text is deprecated in favor of
> style sheets.
(http://www.w3.org/TR/html4/struct/text.html#h-9.2.2)


>
>
>> For larger block level quotations, I've perhaps been cheating in my
>>  tei. I always do:
>>
>> <p>As someone said at great length:</p> <quote> <p>One paragraph of
>>  interesting citation</p> <p>Two paragraphs of interesting
>> citation</p> </quote> <p>And so on and so forth</p>
>
>
> There are places where that cheat would have serious consequences.
> For example, in a legal document with numbered paragraphs, where the
> paragraph clearly surrounded the embedded quotation. Splitting it up
> would be illegal in maybe more than one sense.

Not to disagree with your underlying point: tei allows multiparagraph
quotations
in the middle of structural paragraphs and xhtml doesn't, but:

a) there is no need for there to be a problem in the case of a numbered
legal document: the numbers show up as @id or @n. In fact that is how I
get my XSLT and CSS to rend paras: paras with id or n numbers (depending
on the context) get indentation or whatever; those without are left aligned.

b) another way of looking at it is to use segmentation and alignment
mechanisms to indicate the existence of a discontinguous whole (e.g.
join and joingroup, if one wants to be very complex; if one doesn't one
could use @part="i", ="m", or ="l" or even @id on first part and
@corresp on the post-quote bits of p.

As I said, however, this doesn't undermine your essential point. They
are really work-arounds with the target output language in mind. On the
other hand, however, paragraph-internal block-quotations are an
interesting meta phenomenon, in some ways like notes (or perhaps the
opposite of notes since they are what the surrounding text is presumably
contextualising in some way). I'm sure some version of this could be
done with other elements.

I think personally there is something to be said for keeping things
standard (or at least legal) in both worlds, and, if I'm right about the
use of blockquote, it may show some of the advantages of the discipline.

Cheers
-dan
>
> -- David Sewell, Editorial and Technical Manager Electronic Imprint,
>  The University of Virginia Press PO Box 400318, Charlottesville, VA
>  22904-4318 USA Courier: 310 Old Ivy Way, Suite 302, Charlottesville
>  VA 22903 Email: dsewell@virginia.edu   Tel: +1 434 924 9973 Web:
> http://www.ei.virginia.edu/

--
Daniel Paul O'Donnell, PhD
Associate Professor of English
University of Lethbridge
Lethbridge AB T1K 3M4
Tel. (403) 329-2377
Fax. (403) 382-7191
E-mail <daniel.odonnell@uleth.ca>
Home Page <http://people.uleth.ca/~daniel.odonnell/>
The Digital Medievalist Project: <http://www.digitalmedievalist.org/>
=========================================================================
Date:         Thu, 27 Jan 2005 19:29:12 +0000
Reply-To:     Lou Burnard <lou.burnard@COMPUTING-SERVICES.OXFORD.AC.UK>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Lou Burnard <lou.burnard@COMPUTING-SERVICES.OXFORD.AC.UK>
Subject:      Re: Valid HTML Considered Harmful?
Comments: To: David Sewell <dsewell@VIRGINIA.EDU>
In-Reply-To:  <200501271734.j0RHYS301452@listserv.brown.edu>
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii; format=flowed
Content-Transfer-Encoding: 7bit

David Sewell wrote:
> Everyone,
>
> This may have been discussed in the past, but if so I don't see it in
> the list archives.
>
> There's a major difference in the content model of TEI and (X)HTML when
> it comes to block-level elements. In TEI, they can generally be nested;
> in HTML, they cannot.
>

TEI has no concept of "block level" elements. It has a "chunk-level"
which looks superficially similar, but is a logical concept more than a
physical one. Some chunks have the property of being phrase-like and
therefore can self-nest (<q> and <quote> for example), or can act as
wrappers for chunks (like <p>) which cannot self-nest.
So <p><q><p></p></q> is valid, but <p><p></p></p> is not. This has
everything to do with the differing semantics of <p> and <q>, and
nothing to do with their likely rendition as blocks.

In point of fact, I can think of very few TEI chunks which can
self-nest. There's <text> of course, but that's probably not one you
want to consider...
=========================================================================
Date:         Thu, 27 Jan 2005 16:08:53 -0500
Reply-To:     Jelks Cabaniss <jelks@JELKS.NU>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Jelks Cabaniss <jelks@JELKS.NU>
Subject:      Re: Valid HTML Considered Harmful?
In-Reply-To:  <Pine.OSX.4.61.0501271203250.2701@lister.ei.virginia.edu>
MIME-Version: 1.0
Content-Type: text/plain; charset="US-ASCII"
Content-Transfer-Encoding: 7bit

David Sewell wrote:
> Someone once put it succinctly to me: "If it's not the archival form
> of the document, don't agonize over validity." Reasonable? Is it time
> for a position paper, "Valid HTML Considered Harmful"?

ONPNACHA[1]

[1]: Oh no, please not another Considered Harmful article!


/Jelks
=========================================================================
Date:         Thu, 27 Jan 2005 16:09:09 -0500
Reply-To:     Jelks Cabaniss <jelks@JELKS.NU>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Jelks Cabaniss <jelks@JELKS.NU>
Subject:      Re: Valid HTML Considered Harmful?
In-Reply-To:  <41F9365A.4050304@uleth.ca>
MIME-Version: 1.0
Content-Type: text/plain; charset="iso-8859-1"
Content-Transfer-Encoding: 7bit

Daniel O'Donnell wrote:
> Not to disagree with your underlying point: tei allows multiparagraph
> quotations in the middle of structural paragraphs and xhtml doesn't

The proposed XHTML 2 draft does:

    http://www.w3.org/TR/xhtml2/mod-structural.html#edef_structural_p

But whether XHTML 2 ever gets beyond working draft status -- a somewhat
dubious propostion because of some Theological Correctness issues[1], plus
the W3C being entirely vendor-driven -- is another story altogether.

[1] http://lists.w3.org/Archives/Public/www-tag/2002Sep/thread.html#183


/Jelks
=========================================================================
Date:         Thu, 27 Jan 2005 21:24:55 +0000
Reply-To:     Sebastian Rahtz <sebastian.rahtz@COMPUTING-SERVICES.OXFORD.AC.UK>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Sebastian Rahtz <sebastian.rahtz@COMPUTING-SERVICES.OXFORD.AC.UK>
Subject:      blockquote
MIME-Version: 1.0
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit

the current release of my XSLT stylesheets on Sourceforge does not use
blockquote for address.

One of the good things about the internet is that no-one can see you blush.

--
Sebastian Rahtz
Information Manager, Oxford University Computing Services
13 Banbury Road, Oxford OX2 6NN. Phone +44 1865 283431

OSS Watch: JISC Open Source Advisory Service
http://www.oss-watch.ac.uk
=========================================================================
Date:         Thu, 27 Jan 2005 22:11:20 -0500
Reply-To:     Francois Lachance <lachance@ORIGIN.CHASS.UTORONTO.CA>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Francois Lachance <lachance@ORIGIN.CHASS.UTORONTO.CA>
Subject:      Re: Valid HTML Considered Harmful?
Comments: To: dsewell@VIRGINIA.EDU
In-Reply-To:  <no.id> from "David Sewell" at Jan 27, 2005 01:04:01 PM
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit

David,

What if the target HTML wasn't <blockquote> elements?
What if the target HTML was <div> elements?

Wouldn't that solve the  validation of the nesting?

A transformation that added a value for the "class" attribute would allow
CSS with HTML to control the rendering.

A TEI <p> can be transformed into an HTML <div>.

A TEI <quote> can be transformed into an HTML <div class="quote">

TEI
        <p>...<quote> *** </quote> ... </p>

could be transformed into

HTML

        <div> ...<div class="quote"> *** </div> ... </div>


--
Francois Lachance, Scholar-at-large
http://www.chass.utoronto.ca/~lachance/jardin

2005 Year of Comparative Connections. DIA: Comparative connections? LOGZ:
Connection, first. Comparison, next. DIA: Check. Comparable ways of
connecting. LOGZ: Selection outcomes, first. Comparative Connections,
next.
=========================================================================
Date:         Thu, 27 Jan 2005 23:03:31 -0500
Reply-To:     David Sewell <dsewell@VIRGINIA.EDU>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         David Sewell <dsewell@VIRGINIA.EDU>
Subject:      Re: Valid HTML Considered Harmful?
In-Reply-To:  <200501280311.WAA65481@origin.chass.utoronto.ca>
MIME-Version: 1.0
Content-Type: TEXT/PLAIN; charset=US-ASCII; format=flowed

On Thu, 27 Jan 2005, Francois Lachance wrote:

> A TEI <p> can be transformed into an HTML <div>.
>
> A TEI <quote> can be transformed into an HTML <div class="quote">
>
> TEI
>        <p>...<quote> *** </quote> ... </p>
>
> could be transformed into
>
> HTML
>
>        <div> ...<div class="quote"> *** </div> ... </div>

True. Although by using "div-based" HTML you sacrifice the chance to use
some of the conventionally meaningful HTML tags (<p>...</p> is something
that functions like a paragraph, etc.). Possibly this is a loss only to
certain text-only browsers (Links spaces between <p> but not <div>, though
lynx spaces both) and to the mythical semantic-Web harvesters that are
supposed to be out there figuring out things about our HTML documents
based on the tags they use (good luck!).

DS

--
David Sewell, Editorial and Technical Manager
Electronic Imprint, The University of Virginia Press
PO Box 400318, Charlottesville, VA 22904-4318 USA
Courier: 310 Old Ivy Way, Suite 302, Charlottesville VA 22903
Email: dsewell@virginia.edu   Tel: +1 434 924 9973
=========================================================================
Date:         Fri, 28 Jan 2005 10:01:39 +0000
Reply-To:     Sebastian Rahtz <sebastian.rahtz@COMPUTING-SERVICES.OXFORD.AC.UK>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Sebastian Rahtz <sebastian.rahtz@COMPUTING-SERVICES.OXFORD.AC.UK>
Subject:      Re: Valid HTML Considered Harmful?
Comments: To: Francois Lachance <lachance@ORIGIN.CHASS.UTORONTO.CA>
In-Reply-To:  <200501280300.j0S30m301942@listserv.brown.edu>
MIME-Version: 1.0
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit

Francois Lachance wrote:

>What if the target HTML wasn't <blockquote> elements?
>What if the target HTML was <div> elements?
>
>
does that work with lists? if you have <p><list><item></item></list></p>,
can you make the CSS with nested divs to get the right behaviour? possibly.
I am not sure.

in principle, though, I agree. punt more and more to CSS.

--
Sebastian Rahtz
Information Manager, Oxford University Computing Services
13 Banbury Road, Oxford OX2 6NN. Phone +44 1865 283431

OSS Watch: JISC Open Source Advisory Service
http://www.oss-watch.ac.uk
=========================================================================
Date:         Fri, 28 Jan 2005 16:27:39 +0100
Reply-To:     benoit <jean-luc.benoit@ATILF.FR>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         benoit <jean-luc.benoit@ATILF.FR>
Subject:      rend
MIME-Version: 1.0
Content-Type: text/plain; charset=windows-1252; format=flowed
Content-Transfer-Encoding: 8bit

Dear all !

In the text :

<corr sic="qu’il" rend="qu’il[z]">qu’ilz</corr>
<corr sic="voulderoient" rend="vould(e)roient">vouldroient</corr>

the attribute rend="" corresponds to the typographical aspect of the
scientific edition, which makes visible the intervention of the editor
scientific.
Is this employment of the attribute rend is correct ? in the example
given ?
Thank you for your assistance.

Jluc B.
=========================================================================
Date:         Fri, 28 Jan 2005 08:32:38 -0700
Reply-To:     daniel.odonnell@uleth.ca
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Daniel O'Donnell <daniel.odonnell@ULETH.CA>
Organization: Department of English, University of Lethbridge
Subject:      Re: Valid HTML Considered Harmful?
Comments: To: Sebastian Rahtz <sebastian.rahtz@COMPUTING-SERVICES.OXFORD.AC.UK>
In-Reply-To:  <200501281001.j0SA1r312646@listserv.brown.edu>
MIME-Version: 1.0
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit

Sebastian Rahtz wrote:
> Francois Lachance wrote:
>
>
>>What if the target HTML wasn't <blockquote> elements?
>>What if the target HTML was <div> elements?
>>
>>
>
> does that work with lists? if you have <p><list><item></item></list></p>,
> can you make the CSS with nested divs to get the right behaviour? possibly.
> I am not sure.
>
> in principle, though, I agree. punt more and more to CSS.

I disagree with this in principle, actually, as I think this solution
ends up paradoxically confusing style and structure. The xhtml elements
may be a very minimal set, but they are structural and there is a reason
for observing them. Reducing the xhtml dtd to div@type and span@type is
as bad practice as reducing the tei dtd to element@type. What you end up
with is simply a hook to hang CSS on.

I think current xslt practice tends to lead us into thinking of xhtml
(incorrectly) as a "display" language. In fact, of course, it is really
a minimal structural "exchange" language that handles css well in most
user agents. There is no principled reason, even now, why we couldn't
transform complex tei master documents to simple tei views for output in
xml-capable agents with css style. We tend not to do so for two main
reasons: 1) xhtml is more reliable for completely unnegotiated exchange
(we can assume that most users will have an agent that understands
xhtml, but can't assume that about tei); and 2) most if not all agents
have built in support for xhtml allowing minimal styling if our css has
ignored their requirements. Even if we assume that lets say 10 years
from now everybody has standards-compliant xml browsers (eliminating
advantage #1), advantage #2 will remain: if you use valid xhtml for your
output language you can rely on built-in display support in agents you
haven't explicitly styled for (e.g. cell-phones, screen-readers, braille
devices, holographic brainwave renders, etc.).

So in the end, I think the unstated premise ("the expense of producing
valid xhtml isn't compensated for by any commensurate advantages") is
wrong. What we get is a very reliable exchange mechanism. Converting
from one language to the other brings challenges with it, because their
purposes are so different. But it seems to me the same obligation is
there. Just as it is allowable (but a mistake) to "extend" TEI to the
point that it just becomes html, it is a mistake to use the generic tags
in xhtml to fudge the structural limitations of the language. If
something is a list, it should be in <ul>/<ol>; if it is a paragraph or
paragraph-like (as defined in xhtml), then it should be in <p>; if it is
a larger section, it should be in <div>. Only if the tag doesn't exist,
or the construction described is really impossible in the dtd (e.g.
presenting in-line code using <pre>, should the generic elements be
used. Otherwise, we end up doing in xhtml what Syd and others were
complaining was wrong with using a universal type in tei: reducing the
dtd to span and div. In the case of xhtml, it also totally removes the
principal enduring value of the language: internal support in
unanticipated interface devices.




>
> --
> Sebastian Rahtz
> Information Manager, Oxford University Computing Services
> 13 Banbury Road, Oxford OX2 6NN. Phone +44 1865 283431
>
> OSS Watch: JISC Open Source Advisory Service
> http://www.oss-watch.ac.uk

--
Daniel Paul O'Donnell, PhD
Associate Professor of English
University of Lethbridge
Lethbridge AB T1K 3M4
Tel. (403) 329-2377
Fax. (403) 382-7191
E-mail <daniel.odonnell@uleth.ca>
Home Page <http://people.uleth.ca/~daniel.odonnell/>
The Digital Medievalist Project: <http://www.digitalmedievalist.org/>
=========================================================================
Date:         Fri, 28 Jan 2005 15:41:52 +0000
Reply-To:     Sebastian Rahtz <sebastian.rahtz@COMPUTING-SERVICES.OXFORD.AC.UK>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Sebastian Rahtz <sebastian.rahtz@COMPUTING-SERVICES.OXFORD.AC.UK>
Subject:      Re: Valid HTML Considered Harmful?
Comments: To: daniel.odonnell@uleth.ca
In-Reply-To:  <41FA5B16.6020409@uleth.ca>
MIME-Version: 1.0
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit

Daniel O'Donnell wrote:

>
> I disagree with this in principle, actually, as I think this solution
> ends up paradoxically confusing style and structure. The xhtml
> elements may be a very minimal set, but they are structural

true. one must remember accessibility needs

> There is no principled reason, even now, why we couldn't transform
> complex tei master documents to simple tei views for output in
> xml-capable agents with css style.

actually, there is. CSS and browsers remain tied to (X)HTML specifics.
you cannot render <graphic url="foo.png"/> in CSS. Nor can you can
attach Javascript
or set  meta tags.

I met this yesterday when trying to make Eric Meyers "S5" slide
presentation kit work with raw XML.
I gave up, and had to transform first.

>
> So in the end, I think the unstated premise ("the expense of producing
> valid xhtml isn't compensated for by any commensurate advantages") is
> wrong.

If I ever seemed to say this, I recant. I agree with you.

Sigh. I am not looking forward to changing all my stylesheets to make
XHTML, mind. It means adding namespaces
across the shop. XHTML *is* in a special namespace, right?

--
Sebastian Rahtz
Information Manager, Oxford University Computing Services
13 Banbury Road, Oxford OX2 6NN. Phone +44 1865 283431

OSS Watch: JISC Open Source Advisory Service
http://www.oss-watch.ac.uk
=========================================================================
Date:         Fri, 28 Jan 2005 08:44:50 -0700
Reply-To:     daniel.odonnell@uleth.ca
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Daniel O'Donnell <daniel.odonnell@ULETH.CA>
Organization: Department of English, University of Lethbridge
Subject:      Re: rend
Comments: To: benoit <jean-luc.benoit@ATILF.FR>
In-Reply-To:  <200501281531.j0SFVX316019@listserv.brown.edu>
MIME-Version: 1.0
Content-Type: text/plain; charset=windows-1252; format=flowed
Content-Transfer-Encoding: 8bit

benoit wrote:
> Dear all !
>
> In the text :
>
> <corr sic="qu’il" rend="qu’il[z]">qu’ilz</corr>
> <corr sic="voulderoient" rend="vould(e)roient">vouldroient</corr>
>
> the attribute rend="" corresponds to the typographical aspect of the
> scientific edition, which makes visible the intervention of the editor
> scientific.
> Is this employment of the attribute rend is correct ? in the example
> given ?

If I'm understanding your question correctly, then the answer is
probably no.

I'm assuming that what you mean is that the text reads "qu'il" or
"voulderoient"; that the correct readings (for example in a clear-text
reading edition) should be "qu'ilz" or "vouldroient"; and that a
critical edition would indicate the editorial changes being made using
the forms "qu'il[z]" and "vould(e)roient".

If that's the case, in P4 you should probably do something like this:

<sic id="s1" corresp="c1">qu'il</sic>
<corr id="c1" corresp="s1">qu'il<supplied>z</supplied></corr>

<sic id="s2" corresp="c2">voulderoient</sic>
<corr id="c2" corresp="s2">vould<del>e</del>roient</corr>

or

<sic corr="qu'ilz">qu'il</sic>
<corr sic="qu'il">qu'il<supplied>z</supplied></corr>

<sic corr="vouldroient">voulderoient</sic>
<corr sic="voulderoient">vould<del>e</del>roient</corr>

And rely on stylesheets to handle the appearance of the supplied and del
elements in different uses. Of the two versions, I think it is fair to
say that the second might be described as informally depreciated: there
are lots of problems with the use of text on attributes like this; in
P5, a new mechanism is coming to avoid the problem. There you will
ultimately be able to do something like this:

<choice>
<sic>qu'il</sic>
<corr>qu'il<supplied>z</supplied></corr>
</choice>

<choice>
<sic>voulderoient</sic>
<corr>vould<del>e</del>roient</corr>
</choice>

-dan
> Thank you for your assistance.
>
> Jluc B.

--
Daniel Paul O'Donnell, PhD
Associate Professor of English
University of Lethbridge
Lethbridge AB T1K 3M4
Tel. (403) 329-2377
Fax. (403) 382-7191
E-mail <daniel.odonnell@uleth.ca>
Home Page <http://people.uleth.ca/~daniel.odonnell/>
The Digital Medievalist Project: <http://www.digitalmedievalist.org/>
=========================================================================
Date:         Fri, 28 Jan 2005 16:11:13 +0000
Reply-To:     Sebastian Rahtz <sebastian.rahtz@COMPUTING-SERVICES.OXFORD.AC.UK>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Sebastian Rahtz <sebastian.rahtz@COMPUTING-SERVICES.OXFORD.AC.UK>
Subject:      P5 (was Re: rend)
Comments: To: daniel.odonnell@uleth.ca
In-Reply-To:  <200501281545.j0SFjC318774@listserv.brown.edu>
MIME-Version: 1.0
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit

Daniel O'Donnell wrote:

> in
>P5, a new mechanism is coming to avoid the problem. There you will
>ultimately be able to do something like this:
>
><choice>
><sic>qu'il</sic>
><corr>qu'il<supplied>z</supplied></corr>
></choice>
>
>
Just to clarify, the new mechanism isn't "coming ... ultimately",
it has arrived. The release of P5 (beta, alpha, test, call it what
you will) on http://tei.sf.net is there to be used and tested.
There is much, much work to be done on the text of the Guidelines,
and a fair amount of technical wrangling over semi-internals
like the class system; but unless disaster strikes I at least hope
that instance documents may remain stable.

The best way to make P5 stable is to try it out,
find the things which don't work, and report them.

if you are one of those <choice><seg>lucky</seg><seg>unlucky</seg></choice>
souls who use my XSLT stylesheets, they come in a P5 flavour which is
identical to the P4 one (the P4 one is derived from P5), so you can jump
in and render your P5 docs. There is even a crude
<ref target="http://www.tei-c.org/Activities/META/p4top5.xsl">XSLT
transform</ref>
to do the initial pass at converting P4 instances to P5.

--
Sebastian Rahtz
Information Manager, Oxford University Computing Services
13 Banbury Road, Oxford OX2 6NN. Phone +44 1865 283431

OSS Watch: JISC Open Source Advisory Service
http://www.oss-watch.ac.uk
=========================================================================
Date:         Fri, 28 Jan 2005 11:24:54 -0500
Reply-To:     "John W. Kennedy" <jwkenne@ATTGLOBAL.NET>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         "John W. Kennedy" <jwkenne@ATTGLOBAL.NET>
Subject:      Re: Valid HTML Considered Harmful?
In-Reply-To:  <41FA5D40.6060408@computing-services.oxford.ac.uk>
MIME-version: 1.0
Content-type: text/plain; charset=ISO-8859-1; format=flowed
Content-transfer-encoding: 8BIT

Sebastian Rahtz wrote:
> Sigh. I am not looking forward to changing all my stylesheets to make
> XHTML, mind. It means adding namespaces
> across the shop. XHTML *is* in a special namespace, right?

Yes, but in an XHTML document it is normally the default namespace, so
that's no problem. In XHTML 1.1, however, the "lang" attribute has been
dropped, in favor of the "xml.lang" attribute, which does the same
thing. Outside of that and the usual SGML->XML matters like the <tag/>
idiom for empty elements, XHTML 1.1 and HTML 4.01 Strict are pretty much
the same, and my HTML and XHTML copies of "Double Falshood" and "André"
use the same external CSS files.

--
John W. Kennedy
"The poor have sometimes objected to being governed badly; the rich have
always objected to being governed at all."
   -- G. K. Chesterton.  "The Man Who Was Thursday"
=========================================================================
Date:         Fri, 28 Jan 2005 16:38:26 +0000
Reply-To:     Sebastian Rahtz <sebastian.rahtz@COMPUTING-SERVICES.OXFORD.AC.UK>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Sebastian Rahtz <sebastian.rahtz@COMPUTING-SERVICES.OXFORD.AC.UK>
Subject:      Re: Valid HTML Considered Harmful?
Comments: To: "John W. Kennedy" <jwkenne@ATTGLOBAL.NET>
In-Reply-To:  <200501281625.j0SGPJ324934@listserv.brown.edu>
MIME-Version: 1.0
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 8bit

John W. Kennedy wrote:

>Yes, but in an XHTML document it is normally the default namespace, so
>that's no problem.
>
but in XSLT (1.0) output you cannot change the defaulf namespace.
honest.

> and my HTML and XHTML copies of "Double Falshood" and "André"
>use the same external CSS files.
>
>
one of the (many) things wrong with CSS is that it is namespace-unaware...

--
Sebastian Rahtz
Information Manager, Oxford University Computing Services
13 Banbury Road, Oxford OX2 6NN. Phone +44 1865 283431

OSS Watch: JISC Open Source Advisory Service
http://www.oss-watch.ac.uk
=========================================================================
Date:         Fri, 28 Jan 2005 11:42:33 -0500
Reply-To:     Wendell Piez <wapiez@MULBERRYTECH.COM>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Wendell Piez <wapiez@MULBERRYTECH.COM>
Subject:      Re: Valid HTML Considered Harmful?
In-Reply-To:  <41FA5D40.6060408@computing-services.oxford.ac.uk>
Mime-Version: 1.0
Content-Type: text/plain; charset="us-ascii"; format=flowed

At 10:41 AM 1/28/2005, Sebastian wrote:
>>So in the end, I think the unstated premise ("the expense of producing
>>valid xhtml isn't compensated for by any commensurate advantages") is
>>wrong.
>
>If I ever seemed to say this, I recant. I agree with you.

I agree too, and commend Daniel for explaining it so well, in terms we can
understand.

>Sigh. I am not looking forward to changing all my stylesheets to make
>XHTML, mind. It means adding namespaces
>across the shop. XHTML *is* in a special namespace, right?

It is.

Nevertheless there may be reasons not to go the entire distance just yet.
Browsers are only beginning to catch up to XHTML, and they do not all
handle it well, to say nothing of their consistency. This will take a few
months at least to shake out.

This is the best case scenario, on the assumption that XHTML will "stick",
in the face of growing awareness across the web (as among ourselves) that
validation to an abstract, external spec (here, the XHTML DTD) isn't quite
the same for a "display language" meant for the end-user as it is for an
archival format. For reasons relating to Daniel's for urging that we
respect the semantics of HTML tagging -- essentially, reasons relating to
interchange -- I think validation of XHTML or of any HTML remains a good
thing -- though not for precisely the same reasons as validation of your
TEI "home format" -- and so valid output should be our goal. The question,
however, is how far towards that goal we should stretch ourselves, when.

One obstacle that remains is the difficulty -- even, maybe, the theoretical
impossibility (I'm not sure how far the mathematicians have plumbed this
issue yet) -- of guaranteeing that all output from a given stylesheet (or
at any rate of a "meaningful" stylesheet that produces the kind of sensible
output we want) will be valid to a given DTD. That is, except in trivial
cases, the only way to know the XHTML that comes out of an XHTML stylesheet
is valid, is to validate it in a post-process: it might not be possible to
know this a priori ahead of time. Developments in Schema technology and in
XSLT 2.0 help to move us in this direction, but there is still much work to
be done before we know how "provable" stylesheets can be.

Given all this, it might be prudent for the short-medium term to deploy
stylesheets that generate code that is XHTML in spirit, but not in letter,
leaving it up to projects and applications to take it the next step when
appropriate. In this context it might make sense *not* to add the namespace
until the output has actually been validated to XHTML.

Cheers,
Wendell


======================================================================
Wendell Piez                            mailto:wapiez@mulberrytech.com
Mulberry Technologies, Inc.                http://www.mulberrytech.com
17 West Jefferson Street                    Direct Phone: 301/315-9635
Suite 207                                          Phone: 301/315-9631
Rockville, MD  20850                                 Fax: 301/315-8285
----------------------------------------------------------------------
   Mulberry Technologies: A Consultancy Specializing in SGML and XML
======================================================================
=========================================================================
Date:         Fri, 28 Jan 2005 17:01:48 +0000
Reply-To:     Sebastian Rahtz <sebastian.rahtz@COMPUTING-SERVICES.OXFORD.AC.UK>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Sebastian Rahtz <sebastian.rahtz@COMPUTING-SERVICES.OXFORD.AC.UK>
Subject:      Re: Valid HTML Considered Harmful?
Comments: To: Wendell Piez <wapiez@MULBERRYTECH.COM>
In-Reply-To:  <200501281648.j0SGmw329071@listserv.brown.edu>
MIME-Version: 1.0
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit

Wendell Piez wrote:

>Browsers are only beginning to catch up to XHTML, and they do not all
>handle it well, to say nothing of their consistency. This will take a few
>months at least to shake out.
>
>
you are an optimist!

>That is, except in trivial
>cases, the only way to know the XHTML that comes out of an XHTML stylesheet
>is valid, is to validate it in a post-process: it might not be possible to
>know this a priori ahead of time. Developments in Schema technology and in
>XSLT 2.0 help to move us in this direction, but there is still much work to
>be done before we know how "provable" stylesheets can be.
>
>
ah, an interesting topic. I can see it would be really hard to
do properly. One can, however, be very defensive in ones
XSLT to minimize the problem, I suppose.

>Given all this, it might be prudent for the short-medium term to deploy
>stylesheets that generate code that is XHTML in spirit, but not in letter,
>
>
surely worth trying to get it right. if it fails the validation,
remove the DOCTYPE....

(I just depressed myself by testing a file. a million errors)

--
Sebastian Rahtz
Information Manager, Oxford University Computing Services
13 Banbury Road, Oxford OX2 6NN. Phone +44 1865 283431

OSS Watch: JISC Open Source Advisory Service
http://www.oss-watch.ac.uk
=========================================================================
Date:         Fri, 28 Jan 2005 12:47:16 -0500
Reply-To:     Francois Lachance <lachance@ORIGIN.CHASS.UTORONTO.CA>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Francois Lachance <lachance@ORIGIN.CHASS.UTORONTO.CA>
Subject:      Re: Valid HTML Considered Harmful?
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit

For the record, I, Francois Lachance, was proposing an example not a
principle. That said I have some interlinear observations on the
expense/value theme. At the outset, let me re-address the original
question of how to avoid disable-output escaping in the transformation of
TEI document instances into HTML document instances that makes use of
<blockquote> and <p> elements.


TEI
<p> ... <quote> *** </quote> ... </p>


1st pass XSLT (transform TEI-XML to HTML)

HTML
<div class="container"> ... <div class="quote"> *** </div> ... </div>


2nd pass XSLT (transform HTML to HTML)

HTML
<p> ... <p><blockquote> *** </blockquote><p> ... </p>


### If this is not evident, recall that XSLT transforms nodes ###


You may wonder what happens if the TEI-XML looks like:

<p> ... </p> <quote> *** </quote> <p> ... </p>


1st pass result:

<p> ... </p> <div class="quote"> *** </div> <p>... </p>

2nd pass result:

<p> ... </p> <blockquote> *** </blockquote> <p>... </p>



My interlinear observations follow...

Daniel Paul O'Donnell wrote:
> Sebastian Rahtz wrote:
> > Francois Lachance wrote:
> >
> >>What if the target HTML wasn't <blockquote> elements?
> >>What if the target HTML was <div> elements?
> >>
> >>
> >
> > does that work with lists? if you have <p><list><item></item></list></p>,
> > can you make the CSS with nested divs to get the right behaviour? possibly.
> > I am not sure.
> >
> > in principle, though, I agree. punt more and more to CSS.
>
> I disagree with this in principle, actually, as I think this solution
> ends up paradoxically confusing style and structure.

How does the confusion arise? There is no argument that the following two
are different:

        <element_foo>...</element_foo>

        <element_bar attribute="foo">...</element_bar>

or
        <blockquote> is not <div class="quote">


Sebastian's claim, in my reading, is specific, it is about the control of
the styling of nested divs. It is interesting that he
characterizes styling as behaviour.


> The xhtml elements
> may be a very minimal set, but they are structural and there is a reason
> for observing them. Reducing the xhtml dtd to div@type and span@type is
> as bad practice as reducing the tei dtd to element@type. What you end up
> with is simply a hook to hang CSS on.


I am confused. Doesn't the set of HTML elements include a <div> element?
If I read the rest of the intervention correctly what is being proposed is
not a whole sale avoidance of <div> elements but a favouring of the
continuing practice of using <blockquote> elements. The HTML DTD has no
provisions for extensions. The "type" attribute is not declared. Using the
already available "class" attribute in creating HTML instances is not at
all reducing the DTD. And it certainly not at all like extending the TEI
DTD to create a global "type" attribute. Using the "class" attribute in
HTML is indeed used for processing (styling) a document instance with CSS.
The "class" attribute can also be used for other processing such as with
XSLT, for example, to indicate sections with different distribution
permissions

        <div class="restricted">...</div>

> I think current xslt practice tends to lead us into thinking of xhtml
> (incorrectly) as a "display" language. In fact, of course, it is really
> a minimal structural "exchange" language that handles css well in most
> user agents. There is no principled reason, even now, why we couldn't
> transform complex tei master documents to simple tei views for output in
> xml-capable agents with css style.


Concur. See above.


>  We tend not to do so for two main
> reasons: 1) xhtml is more reliable for completely unnegotiated exchange
> (we can assume that most users will have an agent that understands
> xhtml, but can't assume that about tei);

What is "unnegotiated exchange"? Even with early unXML aware browsers, a
user is usually given the option of saving the file locally. Is that not a
negotiation? The user can then open the TEI document instance in a text
editor. Granted not all users want to be faced with angled brackets. I
just want to disentangle the question of "agent" from that of "exchange"
from that of "access".

> and 2) most if not all agents
> have built in support for xhtml allowing minimal styling if our css has
> ignored their requirements. Even if we assume that lets say 10 years
> from now everybody has standards-compliant xml browsers (eliminating
> advantage #1), advantage #2 will remain: if you use valid xhtml for your
> output language you can rely on built-in display support in agents you
> haven't explicitly styled for (e.g. cell-phones, screen-readers, braille
> devices, holographic brainwave renders, etc.).

No you cannot rely on built-in display support to control what a person
sees or hears. It can and is overridden by users. You can hope.

> So in the end, I think the unstated premise ("the expense of producing
> valid xhtml isn't compensated for by any commensurate advantages") is
> wrong.

I wonder how far Julia Flanders got with marking up syllogisms? (See TEI
archive). What is expressed about the connection between expense and
advantages is not a premise. It's a conclusion.

        First premise: statement of expense
        Second premise: tally of advantages
        Conclusion: cost/benefit ratio


> What we get is a very reliable exchange mechanism. Converting
> from one language to the other brings challenges with it, because their
> purposes are so different.

Language or dialect?
TEI-conformant XML and XML-conformant HTML are both XML. I could not have
proposed the 2 pass XSLT-mediated transformations (sans
disable-output-escaping) above if I thought otherwise.

> But it seems to me the same obligation is
> there. Just as it is allowable (but a mistake) to "extend" TEI to the
> point that it just becomes html, it is a mistake to use the generic tags
> in xhtml to fudge the structural limitations of the language.

How to judge a case of tag abuse? This may be two questions rolled into
one: How to read the structure of a document instance? How to name the
structure that is read? Some fine shuttling between the possible and the
actual and then back and forth again.

> If
> something is a list, it should be in <ul>/<ol>; if it is a paragraph or
> paragraph-like (as defined in xhtml), then it should be in <p>; if it is
> a larger section, it should be in <div>. Only if the tag doesn't exist,
> or the construction described is really impossible in the dtd (e.g.
> presenting in-line code using <pre>, should the generic elements be
> used. Otherwise, we end up doing in xhtml what Syd and others were
> complaining was wrong with using a universal type in tei: reducing the
> dtd to span and div. In the case of xhtml, it also totally removes the
> principal enduring value of the language: internal support in
> unanticipated interface devices.

The priniciple value? Are there other competing values? I think what is
referenced here as "internal support" is called elsewhere "default
settings". For me the great value in creating and accessing valid document
instances is that well designed interface devices allow for "graceful
degradation".


Like the TEI Guidelines, the W3C Recommendations, are not just that --
recommendations -- a place round which an information manager, an
associate professor and a scholar-at-large can exchange views about what
some of them call "information interchange" and others call "exchange
mechanisms" and which may or may not be the same ontological entities.

> > Sebastian Rahtz
> > Information Manager, Oxford University Computing Services
>
> Daniel Paul O'Donnell wrote:
> Associate Professor of English

Francois Lachance
Scholar-at-large
=========================================================================
Date:         Fri, 28 Jan 2005 13:12:26 -0500
Reply-To:     Wendell Piez <wapiez@MULBERRYTECH.COM>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Wendell Piez <wapiez@MULBERRYTECH.COM>
Subject:      Re: Valid HTML Considered Harmful?
In-Reply-To:  <200501281747.MAA53587@origin.chass.utoronto.ca>
Mime-Version: 1.0
Content-Type: text/plain; charset="us-ascii"; format=flowed

Francois,

At 12:47 PM 1/28/2005, you wrote:
>HTML
><div class="container"> ... <div class="quote"> *** </div> ... </div>
>
>
>2nd pass XSLT (transform HTML to HTML)
>
>HTML
><p> ... <p><blockquote> *** </blockquote><p> ... </p>

It's this second pass that is problematic in XSLT.

Recall the input may be something like

<div class="container"> ... <emph>...</emph> ... <strong>...</strong> ...
<div class="quote"> *** </div> ... </div>

How, in XSLT, do you construct the first and third divs in the result, out
of the sequence of children of the outer div up to but not including the
inner div (for the first), or after it (for the third)? (And of course
there may be more than one inner div.)

There are solutions. David's approach, tag-writing, is one. Another is to
brute-force walk the tree forward node by node until you run into an
element (the inner div in this case) you want to split out (or use
key-magic to group them) ... and then picking up again after you've handled
it. Not pretty.

Here you are looking at the Dark Side of the "XML is a Tree" orthodoxy.
Tag-writing processing (which depends on a serializer not a tree processor
for its output) is much better at coping with this kind of thing, at the
price of losing the advantage of XSLT's guarantee of well-formed output.

(But I haven't tackled this yet in XSLT 2.0, where it might be easier,
since you have better support for grouping. That's a solution I'm eager to
see, preferably before I have to write it!)

Cheers,
Wendell



======================================================================
Wendell Piez                            mailto:wapiez@mulberrytech.com
Mulberry Technologies, Inc.                http://www.mulberrytech.com
17 West Jefferson Street                    Direct Phone: 301/315-9635
Suite 207                                          Phone: 301/315-9631
Rockville, MD  20850                                 Fax: 301/315-8285
----------------------------------------------------------------------
   Mulberry Technologies: A Consultancy Specializing in SGML and XML
======================================================================
=========================================================================
Date:         Fri, 28 Jan 2005 14:28:11 -0500
Reply-To:     Jelks Cabaniss <jelks@JELKS.NU>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Jelks Cabaniss <jelks@JELKS.NU>
Subject:      Re: Valid HTML Considered Harmful?
In-Reply-To:  <6.1.2.0.0.20050128112305.02dbcae0@earthlink.net>
MIME-Version: 1.0
Content-Type: text/plain; charset="us-ascii"
Content-Transfer-Encoding: 8bit

Wendell Piez wrote:
> Given all this, it might be prudent for the short-medium term to
> deploy stylesheets that generate code that is XHTML in spirit, but
> not in letter, leaving it up to projects and applications to take it
> the next step when appropriate. In this context it might make sense
> *not* to add the namespace until the output has actually been
> validated to XHTML.

I agree.  You could use something like an

  <xsl:output method="xml"
    doctype-public="-//WHEW!//NAMESPACE-FREE XHTML//EN"
    doctype-system="http://www.example.org/no-ns.dtd" />

where no-ns.dtd is a copy of (for simplicity's sake) the XHTML 1.0 Strict
DTD, modified to not have the namespace on <html>.  There is no reason for
that namespace requirement in 99.99% of the *current* XHTML out there.  When
your transform outputs are valid, you can always use perl/sed/text editor to
replace the DOCTYPE and add the "official" namespace onto <html> if you
really need Theologically Correct XHTML.

This would have to be revisited of course, if embedded SVG and MathML
advance beyond the bleeding-edge testbed -- in browser-support and practice
as well as formalisms.  But that's probably a year off (at least).


/Jelks
=========================================================================
Date:         Fri, 28 Jan 2005 14:47:11 -0500
Reply-To:     Wendell Piez <wapiez@MULBERRYTECH.COM>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Wendell Piez <wapiez@MULBERRYTECH.COM>
Subject:      Re: Valid HTML Considered Harmful?
In-Reply-To:  <000001c5056f$8174ee80$6401a8c0@blackie>
Mime-Version: 1.0
Content-Type: text/plain; charset="us-ascii"; format=flowed

At 02:28 PM 1/28/2005, Jelks wrote:
> > Given all this, it might be prudent for the short-medium term to
> > deploy stylesheets that generate code that is XHTML in spirit, but
> > not in letter, leaving it up to projects and applications to take it
> > the next step when appropriate. In this context it might make sense
> > *not* to add the namespace until the output has actually been
> > validated to XHTML.
>
>I agree.  You could use something like an
>
>   <xsl:output method="xml"
>     doctype-public="-//WHEW!//NAMESPACE-FREE XHTML//EN"
>     doctype-system="http://www.example.org/no-ns.dtd" />
>
>where no-ns.dtd is a copy of (for simplicity's sake) the XHTML 1.0 Strict
>DTD, modified to not have the namespace on <html>.

Right. Or leave the DOCTYPE declaration off altogether, and claim no
conformance of any kind.

(Part of the idea here is that the transform output should not, in good
conscience, be claimed to be valid until it's actually been validated.)

>   There is no reason for
>that namespace requirement in 99.99% of the *current* XHTML out there.

Right.

>   When
>your transform outputs are valid, you can always use perl/sed/text editor to
>replace the DOCTYPE and add the "official" namespace onto <html> if you
>really need Theologically Correct XHTML.

Or another transform!

Cheers,
Wendell



======================================================================
Wendell Piez                            mailto:wapiez@mulberrytech.com
Mulberry Technologies, Inc.                http://www.mulberrytech.com
17 West Jefferson Street                    Direct Phone: 301/315-9635
Suite 207                                          Phone: 301/315-9631
Rockville, MD  20850                                 Fax: 301/315-8285
----------------------------------------------------------------------
   Mulberry Technologies: A Consultancy Specializing in SGML and XML
======================================================================
=========================================================================
Date:         Fri, 28 Jan 2005 20:16:12 -0000
Reply-To:     Michael Beddow <mbteil-2@mbeddow.net>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Michael Beddow <mbteil-2@MBEDDOW.NET>
Subject:      Re: Valid HTML Considered Harmful?
MIME-Version: 1.0
Content-Type: text/plain; charset="iso-8859-1"
Content-Transfer-Encoding: 7bit

Wendell Piez wrote:

[...]

>
> Right. Or leave the DOCTYPE declaration off altogether, and claim no
> conformance of any kind.
>
> (Part of the idea here is that the transform output should not, in good
> conscience, be claimed to be valid until it's actually been validated.)

Makes sense. But bear in mind that both Mozilla and IE6 adjust their
behaviour (including some rather important CSS-related things) depending on
the presence and content of the DOCTYPE declaration. There might also be
knock-on effects on accessibility aids that took their cue from the DOCTYPE,
though I don't know of any current issues there.

For Moz (= also Firefox), see
http://www.mozilla.org/docs/web-developer/quirks/

Michael Beddow
=========================================================================
Date:         Fri, 28 Jan 2005 15:59:56 -0500
Reply-To:     Francois Lachance <lachance@ORIGIN.CHASS.UTORONTO.CA>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Francois Lachance <lachance@ORIGIN.CHASS.UTORONTO.CA>
Subject:      Re: Valid HTML Considered Harmful?
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit

Wendell,

I did have tree walking in mind. But perhaps not of the brutal sort. I had
in mind an adaptation of the Piez method for avoiding XSLT procesor crash
upon recursive processing:  use of count() and position() to control the
output of Result Tree Fragments; in particular, a count of the nodes and a
count of the nodes of a specific type.

The node counts provide what could be called a recursivity limit.
Something that is signalled as desirable in the explanations of the Piez
method.

The Piez method would work in case of zero or more contained elements
which in the case that sparked the discussion was <div class="quote> to be
transformed to <blockquote> and the appropriate splitting of <div
class="container"> into <p>.

In passing, allow me to underscore the importance of thinking through the
proposed problem in the terms of the appropriate datatype. In this case,
in terms of Result Tree Fragments and not in terms of node sets. That is,
wrapping Result Tree Fragments. Rather than say outputting start and end
tags. Or even creating node-sets.


http://www.w3.org/TR/xslt#section-Result-Tree-Fragments


It would be a pity if the heuristic value of the RTF data type were lost
with the introduction of the node-set() fundtion in XSLT 2.0.

Of course not all tree walking is RTF grabbing.


--
Francois Lachance, Scholar-at-large
http://www.chass.utoronto.ca/~lachance/jardin

2005 Year of Comparative Connections. DIA: Comparative connections? LOGZ:
Connection, first. Comparison, next. DIA: Check. Comparable ways of
connecting. LOGZ: Selection outcomes, first. Comparative Connections,
next.
=========================================================================
Date:         Fri, 28 Jan 2005 16:15:42 -0500
Reply-To:     Jelks Cabaniss <jelks@JELKS.NU>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Jelks Cabaniss <jelks@JELKS.NU>
Subject:      Re: Valid HTML Considered Harmful?
In-Reply-To:  <6.1.2.0.0.20050128144113.02e63758@earthlink.net>
MIME-Version: 1.0
Content-Type: text/plain; charset="US-ASCII"
Content-Transfer-Encoding: 8bit

Wendell Piez wrote:
>>   <xsl:output method="xml"
>>     doctype-public="-//WHEW!//NAMESPACE-FREE XHTML//EN"
>>     doctype-system="http://www.example.org/no-ns.dtd" />
>>
>> where no-ns.dtd is a copy of (for simplicity's sake) the XHTML 1.0
>> Strict DTD, modified to not have the namespace on <html>.

> Right. Or leave the DOCTYPE declaration off altogether, and claim no
> conformance of any kind.

The only problem with leaving off the DOCTYPE declaration -- and for that
matter referencing any of the HTML4/XTHML1 "Transitional" DTDs (or earlier
"official" DTDs) -- is that it invokes the old "broken box model" CSS
rendering in common web browsers.  Why Mozilla decided to trigger CSS
rendering based on a DOCTYPE declaration seems a bit odd to me, but
evidently IE (and unless I'm mistaken, even Opera and Safari) saw great
wisdom in it and dutifully copied this behavior, so there we are.

Using any of the "Strict" or newer (i.e., 1.1) declarations, or using a
custom one, sets them into "correct" CSS mode.

None of this should be much of an issue for simple documents, and if you're
assuming a subsequent transform anyway it shouldn't be an issue at all.

PS.  The only real advantage of having a DOCTYPE declaration at all on
[X]HTML is that it makes the document "validation-ready" using common tools.
(The suggestion of a modified 1.0 Strict one was to help ensure that <font>
and "bgcolor" (and the like) attributes didn't creep in.)


/Jelks
=========================================================================
Date:         Fri, 28 Jan 2005 16:11:01 -0500
Reply-To:     Wendell Piez <wapiez@MULBERRYTECH.COM>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Wendell Piez <wapiez@MULBERRYTECH.COM>
Subject:      Re: Valid HTML Considered Harmful?
In-Reply-To:  <00ae01c50576$39b65e60$0201010a@michaelnt2k>
Mime-Version: 1.0
Content-Type: text/plain; charset="us-ascii"; format=flowed

At 03:16 PM 1/28/2005, Michael Beddow wrote:
> > Right. Or leave the DOCTYPE declaration off altogether, and claim no
> > conformance of any kind.
> >
> > (Part of the idea here is that the transform output should not, in good
> > conscience, be claimed to be valid until it's actually been validated.)
>
>Makes sense. But bear in mind that both Mozilla and IE6 adjust their
>behaviour (including some rather important CSS-related things) depending on
>the presence and content of the DOCTYPE declaration. There might also be
>knock-on effects on accessibility aids that took their cue from the DOCTYPE,
>though I don't know of any current issues there.
>
>For Moz (= also Firefox), see
>http://www.mozilla.org/docs/web-developer/quirks/

Excellent caveat, Michael.

What makes this particularly sticky is how it's such a moving target.
Ultimately (as so often) Sebastian and other stylesheet authors will have
to strike a balance somewhere.

Cheers,
Wendell


======================================================================
Wendell Piez                            mailto:wapiez@mulberrytech.com
Mulberry Technologies, Inc.                http://www.mulberrytech.com
17 West Jefferson Street                    Direct Phone: 301/315-9635
Suite 207                                          Phone: 301/315-9631
Rockville, MD  20850                                 Fax: 301/315-8285
----------------------------------------------------------------------
   Mulberry Technologies: A Consultancy Specializing in SGML and XML
======================================================================
=========================================================================
Date:         Fri, 28 Jan 2005 16:39:20 -0500
Reply-To:     Wendell Piez <wapiez@MULBERRYTECH.COM>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Wendell Piez <wapiez@MULBERRYTECH.COM>
Subject:      Re: Valid HTML Considered Harmful?
In-Reply-To:  <200501282059.PAA15314@origin.chass.utoronto.ca>
Mime-Version: 1.0
Content-Type: text/plain; charset="us-ascii"; format=flowed

Francois,

At 03:59 PM 1/28/2005, you wrote:
>I did have tree walking in mind. But perhaps not of the brutal sort. I had
>in mind an adaptation of the Piez method for avoiding XSLT procesor crash
>upon recursive processing:  use of count() and position() to control the
>output of Result Tree Fragments; in particular, a count of the nodes and a
>count of the nodes of a specific type.
>
>The node counts provide what could be called a recursivity limit.
>Something that is signalled as desirable in the explanations of the Piez
>method.

Hm, I didn't think of that approach! :->

>The Piez method would work in case of zero or more contained elements
>which in the case that sparked the discussion was <div class="quote> to be
>transformed to <blockquote> and the appropriate splitting of <div
>class="container"> into <p>.

In principle I think I see where you're going, but I'd like to see a
working demonstration before I felt confident it was better than the other
approaches.

In any case, it's not a trivial transform. (And where XSLT is not trivial,
I'm inclined to consider other alternatives as well. I learn about both my
problems and my tools that way. To my mind, elegance is something more than
a nice-to-have: for long-term community maintainability, simplicity is a must.)

This particular problem, BTW, is not limited to TEI -> HTML transforms. The
XML format of OpenOffice, for example, also needs things to be flat at the
paragraph level -- lists appearing inside lists are especially bad: as in
many presentation-oriented formats, list "depth" is signalled only by the
indent level of the items, which are not grouped. This can be especially
hard when a list item contains something block-level, such as a chunk of
code, and then resumes again after the block (still indented, but without
another bullet).

Yet as an optimist in outlook, I'm confident that better solutions to this
problem will emerge in time (especially if we keep pushing), and I am
really hopeful that XSLT 2.0 grouping will help. It's just too common a
requirement to remain an impediment.

I should also add, in good conscience, that (you know) I'm on record as
calling the so-called Piez method a "shameful hack" (surely I'm allowed
to!) -- and I think of it as something to be avoided -- despite its
simplicity and usefulness for doing certain sorts of otherwise-difficult
things.

Cheers,
Wendell


======================================================================
Wendell Piez                            mailto:wapiez@mulberrytech.com
Mulberry Technologies, Inc.                http://www.mulberrytech.com
17 West Jefferson Street                    Direct Phone: 301/315-9635
Suite 207                                          Phone: 301/315-9631
Rockville, MD  20850                                 Fax: 301/315-8285
----------------------------------------------------------------------
   Mulberry Technologies: A Consultancy Specializing in SGML and XML
======================================================================
=========================================================================
Date:         Fri, 28 Jan 2005 16:52:40 -0500
Reply-To:     Wendell Piez <wapiez@MULBERRYTECH.COM>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Wendell Piez <wapiez@MULBERRYTECH.COM>
Subject:      Re: Valid HTML Considered Harmful?
In-Reply-To:  <000001c5057e$868e2d50$6401a8c0@blackie>
Mime-Version: 1.0
Content-Type: text/plain; charset="us-ascii"; format=flowed

Hi Jelks,

At 04:15 PM 1/28/2005, you wrote:
>The only problem with leaving off the DOCTYPE declaration -- and for that
>matter referencing any of the HTML4/XTHML1 "Transitional" DTDs (or earlier
>"official" DTDs) -- is that it invokes the old "broken box model" CSS
>rendering in common web browsers.  Why Mozilla decided to trigger CSS
>rendering based on a DOCTYPE declaration seems a bit odd to me, but
>evidently IE (and unless I'm mistaken, even Opera and Safari) saw great
>wisdom in it and dutifully copied this behavior, so there we are.
>
>Using any of the "Strict" or newer (i.e., 1.1) declarations, or using a
>custom one, sets them into "correct" CSS mode.

Yes: you'll have seen Michael caught this too (and I thank you both).

(Hm: so the DOCTYPE declaration both claims conformance to a DTD, and
triggers behavior in browsers. It hadn't occurred to me before that this
may be a case of overloaded semantics. But I guess requirements for
backward-compatibility will do that.)

>None of this should be much of an issue for simple documents, and if you're
>assuming a subsequent transform anyway it shouldn't be an issue at all.

Agreed -- and I think this is the nub of the issue. What is fair to assume
for the application of this code? is nigh unto the problem of what it can
warrant. These are the shoals upon which many a high-minded community-based
effort has been wrecked.

Cheers,
Wendell


======================================================================
Wendell Piez                            mailto:wapiez@mulberrytech.com
Mulberry Technologies, Inc.                http://www.mulberrytech.com
17 West Jefferson Street                    Direct Phone: 301/315-9635
Suite 207                                          Phone: 301/315-9631
Rockville, MD  20850                                 Fax: 301/315-8285
----------------------------------------------------------------------
   Mulberry Technologies: A Consultancy Specializing in SGML and XML
======================================================================
=========================================================================
Date:         Fri, 28 Jan 2005 16:59:22 -0500
Reply-To:     David Sewell <dsewell@VIRGINIA.EDU>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         David Sewell <dsewell@VIRGINIA.EDU>
Subject:      Re: Valid HTML Considered Harmful?
In-Reply-To:  <41FA6FFC.1040907@computing-services.oxford.ac.uk>
MIME-Version: 1.0
Content-Type: TEXT/PLAIN; charset=US-ASCII

On Fri, 28 Jan 2005, Sebastian Rahtz wrote:

> > Given all this, it might be prudent for the short-medium term to deploy
> > stylesheets that generate code that is XHTML in spirit, but not in letter,
> >
> surely worth trying to get it right. if it fails the validation,
> remove the DOCTYPE....
>
> (I just depressed myself by testing a file. a million errors)

You can undepress yourself a bit by running the ISO homepage
(www.iso.org) through the W3C Validator. Quis custodet custodes and all
that.

DS

--
David Sewell, Editorial and Technical Manager
Electronic Imprint, The University of Virginia Press
PO Box 400318, Charlottesville, VA 22904-4318 USA
Courier: 310 Old Ivy Way, Suite 302, Charlottesville VA 22903
Email: dsewell@virginia.edu   Tel: +1 434 924 9973
Web: http://www.ei.virginia.edu/
=========================================================================
Date:         Fri, 28 Jan 2005 19:01:34 -0500
Reply-To:     Jelks Cabaniss <jelks@JELKS.NU>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Jelks Cabaniss <jelks@JELKS.NU>
Subject:      Re: Valid HTML Considered Harmful?
In-Reply-To:  <6.1.2.0.0.20050128164052.02d8cce8@earthlink.net>
MIME-Version: 1.0
Content-Type: text/plain; charset="US-ASCII"
Content-Transfer-Encoding: 8bit

Wendell Piez wrote:
> (Hm: so the DOCTYPE declaration both claims conformance to a DTD, and
> triggers behavior in browsers. It hadn't occurred to me before that
> this may be a case of overloaded semantics. But I guess requirements
> for backward-compatibility will do that.)

It's one of the (hopefully last) remnants of the "HTML is a display
language" mentality that blossomed during the early Netscape days, where
"tags" are "instructions" to "do something".  I.e., <li> means "plop a
bullet", <blockquote> means "indent", <p> means "plop some whitespace here".
The MSDN page[1] on the DOCTYPE declaration (for HTML) still has this gem:

        The !DOCTYPE element does not require a closing tag.


[1]: http://tinyurl.com/85ze


/Jelks
=========================================================================
Date:         Sat, 29 Jan 2005 21:31:51 -0000
Reply-To:     Michael Beddow <mbteil-2@mbeddow.net>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Michael Beddow <mbteil-2@MBEDDOW.NET>
Subject:      Re: Valid HTML Considered Harmful?
MIME-Version: 1.0
Content-Type: text/plain; charset="iso-8859-1"
Content-Transfer-Encoding: 7bit

I appreciate the points made in this thread about the merits of html
validity in general and valid xhtml in particular, but I for one would want
to draw the line at misrepresenting the document's structure in my XML
simply to get a better mapping to valid html. Which is what I think is
happening in this example from earlier on in the thread:

=============================
<p>As someone said at great length:</p>
<quote>
<p>One paragraph of interesting citation</p>
<p>Two paragraphs of interesting citation</p>
</quote>
<p>And so on and so forth</p>
=============================

Here, one paragraph enclosing a quotation which itself has two internal
paragraphs is misrepresented as four separate paragraphs. The unity of the
enclosing paragraph is denied, and the containment of the quoted paras is
translated into sequential contiguity.

That seems to me too high a price to pay for being able to pass the XML
straightforwardly through XSLT and get valid hmtl. Nor am I convinced that
the effort involved in re-expressing the inherent structure of the XML
document via linking and aggregation techniques is worth undertaking for the
sake of the desired html, especially if (as in my case) the html is
generated on demand simply as the delivery vehicle best suited to giving as
many people as possible a reasonably accurate  view of what the XML
contains -- which is pretty much all that can be hoped for in the present
state of technology outside environments where document producers have
complete control over the client software.

To stick with the case that launched this thread (on the understanding that
we're focussing on the blockquote issue because of the generic problems it
raises): two ways of getting an XML <p> to be split into self-contained html
<p>s which are siblings of  <blockquotes> rather than their parent, without
distorting the  XML at source, have been mentioned by earlier contributors.
Let me say a little bit more about them in the hope that it may help those
who want to generate valid html via XSLT from TEI markup see ways forward.

Actually, I'm going to say as little as possible about the first method,
mentioned with appropriate distaste by a couple of people already, namely
abusing disable-output-escaping to pass off markup as text. As others have
said, XSLT is for inputting, transforming, and outputting trees. And
outputting trees is more like wrapping presents than making sandwiches.

You can start making a sandwich by choosing one slice of bread, putting it
on a plate, smearing on some spread, then you can wander at leisure around
the kitchen adding ingredients until you decide your sandwich is finished.
Whereupon you top it with another slice of bread (needn't even be from the
same loaf as long as the size is roughly right) or even opt to leave it as
an open sandwich. And if you decide that slice of pickled gherkin probably
wasn't such a great idea after all, you can take it out again before you
take your first bite. This is what using a serial processor is like; but an
XSLT engine isn't a serial processor.

Wrapping presents is different. You have to decide who's is getting what,
then you group together the gifts intended for a given recipient and only
then reach for the wrapping paper and wrap them all up in a single
operation. In fact, you may have been doing the grouping long before you
even thought about buying the wrapping paper, reaching for the carrier bag
where you are accumulating Uncle Jim's presents whenever you encounter
something in your sock drawer that you realise you are never ever going to
wear yourself. But once you've wrapped the presents, you can't change your
mind without starting all over again, so you'd better be sure you really
have settled what the parcel is to contain before you start the wrapping.
Which is the approach you need to take when using a tree-processing system.

In many cases where XSLT output needs to be grouped in some way, the
required grouping is already explicit in the source markup, so you can grab
the contents of your intended parcels in a single operation and wrap them
straight away, without explicitly being aware of the need to group. In other
words, it's as if your task is simply re-wrapping presents someone else
already assembled and assigned to their future recipients; all you need to
do is strip of the old wrapping and put on a new one using different paper.

Which is fine as long as you encounter only such cases. But then along comes
a document where some of the things that need to be grouped together before
you can do the wrapping operation heven't already been conveniently
pre-grouped for you. Your first reaction may be to think XSLT can't cope.
But it can, provided you learn how to use it to group material according to
specifications that you provide. XSLT 2.0 provides commands to do just that;
but  XSLT 1.0 can do it too, Although the techniques needed to group in XSLT
1.0 are harder to assimilate and deploy than those in XSLT 2.0, the core of
what you need to grasp, namely the crafting of XPath expressions to select
precisely those things you want to group together, is common to both
versions of the language.

I'll try to explain this with reference to the following sample document,
consisting of an XML <p> which contains <q> children which we wish to be set
out as html <blockquotes>, meaning that to achieve valid html we need to
split the single XML parent <p> into a number of sibling html <p>s at the
same level as the <blockquote>s we shall be generating.

======================================
<?xml version="1.0" encoding="UTF-8"?>
<text>
<p>This is the start of a <hi rend="bold">paragraph</hi>, and as it has been
well said <q rend="block"> You never know what will be
in a paragraph.</q> (Meaning among other things that the
possibility that <q rend="block">One good quote deserves
another </q>will <hi rend="italic">always</hi> have to be borne in mind)</p>
</text>
======================================

Let's indicate what the groups are that we intend to wrap in output
elements. I'll do that using start and end tags in square brackets, thus
[G1]Contents of group 1 [/G1] etc

<text>
<p>[G1]This is the start of a <hi rend="bold">paragraph</hi>, and as it has
been
well said[/G1] <q rend="block"> [G2]You never know what will be
in a paragraph.[/G2]</q>[G3] (Meaning among other things that the
possibility that[/G3] <q rend="block">[G4]One good quote deserves
another [/G4]</q>[G5]will <hi rend="italic">always</hi> have to be borne in
mind)[/G5]</p>
</text>

Comparing the placing of my  [Gn] tags to the location of true XML element
boundary markers, it will be evident that two of the groups we want to
"wrap" -- G2 and G4 -- are already "wrapped" in the source xml. So they are
already grouped for us. We could get at them by matching the elements
concerned and writing out their contents wrapped in the new "blockquote"
element of our choice.

So our first thought might be to put these templates into our XSLT.

======================================

<xsl:template match="p">
<p><xsl:apply-templates/></p>
</xsl:template>

<xsl:template match="q[@rend="block"]>
<blockquote><xsl:apply=templates/></blockquote>
</xsl:template>

=======================================

Which sadly doesn't do everything we want. Sure enough, the <q>s with
@rend='block' are successfully transformed into <blockquotes>, but those
<blockquotes> are children of the <p> we have created, and so will not
validate as html.

So now it's time to check our ropes, adjust our crampons, and tackle a steep
bit of the learning curve. The effort could be worth it.

Our first attempt may mean we climb ourselves into trouble. If we think in
serial processing terms, we may assume that the problem needs to be solved
within the template that handles the block-rendered <q>s. So we attempt to
modify that template, reach for the treacherous tool of
disable-output-escaping and try to progress by writing malformed markup,
passed off as <xml:text>, into the output: a </p> before our <blockquote>
and a <p> after it. It will all end badly -- literally so, since you'll
finish up, among various other problems, with one <p> too many after your
last <blockquote>.

Now there's a useful rule of thumb here that's often been formulated by
Wendell (though in a somewhat more rigorous way): if you think you need to
use d.o.e in this sort of way, it's a sign that you are trying to operate
too low down the tree (sorry for the directional confusion, real world trees
are vertically directed like real-world mountains, but CompSci trees alas
grow downwards from a root at the top...) So you need to step back up the
tree a level and re-examine the problem from that higher, "elevated",
standpoint.

In other words, we need to tackle the problem at the level where we process
the enclosing XML <p>, instead of trying to firefight only when a template
for a <q rend='block'> has been triggered. So let's first refine our <p>
template match so that it identifies for special treatment only those <p>s
where the problem arises, viz those that have at least one <q> child with
@rend='block'.

<xsl:template match="p[q/@rend='block']">
[more stuff to come here]
</xsl:template>

Now, when this template fires we want to do the following:
1. Output all the nodes before the first <q> child, [G1] in my example,
wrapping them in a <p>
2. Output the first <q> child, with its contents [G2] wrapped in a
<blockquote>
3. Output all the nodes before the next <q> child, [G3] in my example,
wrapping them in a <p>
4. Output the next <q> child, with its contents [G4] wrapped in a
<blockquote>
And so on, until we have output the last <q> child, duly re-wrapped as a
<blockquote>
5. Then we have finally to output all the nodes after that last <q> child ,
i.e. [G5], again wrapped in a <p>.

So how do we do that? Well, we've already done the necessary for steps 2 and
4. The problem is: how to precede and follow  steps 2 and 4 with the output
of the grouped items of our choice.
Let's pseudo-code that:

<xsl:template match="p[q/@rend='block']">

FOR EACH  ( < q> CHILD HAVING @rend='italic')
   BEGIN
       <p>
         PROCESS NODES PRECEDING THAT CHILD
       </p>
        PROCESS THE CHILD ITSELF (by rewriting as <blockquote>)
   END
        <p>
        PROCESS NODES FOLLOWING LAST <q> CHILD
        </p>
</xsl:template>

All we have to do is replace the pseudo-code by real XSLT and the job's
done, (or at least the apparently hard parts of it are -- there's more to be
done to cope with more realistic documents, but most of it is relatively
straightforward stuff that I won't go into).

What we need now is what Wendell alludes to earlier in this thread as "key
magic".  Like most prestidigitation, such tricks take a bit of practice to
perform, but in principle it's pretty simple. Alas, the nomenclature and
syntax required to put that principle into effect are somewhat rebarbative
in XSLT 1.0. And since the discussions of using keys for grouping found in
XSLT primers tend to concentrate on "datacentric" XML, it may not be
immediately clear how and why keys can also be useful for the grouping tasks
we TEI-ish docucentrics also encounter.

To group things prior to wrapping them we need (a) a way of specifying which
items are candidates for inclusion in one or the other of our groups  (b) a
way of singling out from among those candidates just the items that belong
in each specific group.

In the example case, what qualifies a document node as a potential member of
one of the groups we want to assemble than wrap in an html <p> is that it's
a child node of an XML <p> which also has <q> children where @rend='block".
We need to build an XPath expression that will select just those qualifying
nodes. Let's cast our net fairly widely at first then narrow the mesh. We
can begin with an expression that will select only those <p>s that have "q"
children with a @rend value set to 'block', like so: which we do  by adding
a simple predicate expression in square brackets after the "p":
match = "p[q/@rend='block']
We're making progress, but what we really want to group are not the
aggregated contents of the <p>s we have so far selected: we want as the
candidate constituents of our groups the text and element node children of
those <p>s  . So, leaving our predicate in place to filter the <p>s as
before, we extend the XPath to select children of those filtered<p>s,
whether they are text nodes or element children (along with any text
descendants those children may have), giving:
match = "p[q/@rend='block']/text()|*"

And that's it. All our potential candidates for grouped output will be
selected by that expression.

But how do we now do the actual grouping of those selected candidates into
the required html <p> chunks? Looking back to our pseudo-code, we see that
we want to be able to say to the XSLT processor, "Hand me just those nodes
which (a) match my general criteria for group inclusion AND (b) for which it
is the case that the next <q> node in document order is the next <q> node we
intend to output as a <blockquote>, so that I can wrap those nodes in a <p>
and output them first before that blockquote is processed".

To do that, we need to have a unique identifier for each <q> node with
@rend='block'. Which the XSLT processor is happy to give us. Pass an
expression selecting any node as a parameter to its generate-id() function
and the processor will return an id unique to that node (unique for this run
of the processor, that is, but that's all we need here). Now, each of the
candidate nodes we selected by the XPath above will have, sharing its common
<p> ancestry, one or zero immediate successor <q> nodes with @rend='block'
(why "or zero"? : look at [G5] above for the answer). When one of those
candidate nodes is the current node, that immediate successor <q> node will
be selected by the expression "following::q[@rend='block'][1], which says
"look from the current node along the "following" access and select the
first <q> node along that axis. (Purists might say the [1] is superfluous
for what we are about to do, but it helps some processors optimise the
instruction). And to get a unique id for that selected successor node, so we
can easily retrieve the nodes we want to associate with it, we pass the
expression selecting it to the generate-id() function, like so:

generate-id(following::q[@rend='block'][1])

Time to face the grim syntactic realities of creating the actual XSLT key.

At the top of our document (or more precisely, outside any templates or RTF
constructors), we need to put an expression like
<xsl:key match="XPATH THAT IDENTIFIES OUR CANDIDATE NODES FOR GROUPING"
name="SOMETHING SUITABLY MNEMONIC" use="EXPRESSION WHICH GROUPS THE
CANDIDATE NODES IN OUR CHOSEN WAY" />

We've already worked out the expression that will become our match value,
and the id we just generated turns out to be the criterion we need to form
our groups, because we will always want as members of our group for output
as an html <p> those nodes which have the same immediate successor <q> node.
So we can supply the necessary attribute values to create our key:
<xsl:key match="p[q/@rend='block']/text()|*" name="prequoteNodes"
use="generate-id(following::q[@rend='block'][1])" />

Now if we pass as parameters to the key() function the name of this key,
"prequoteNodes", plus the generated id of any <q> node that has
@rend='block' ,  the processor will return to us the nodes whose immediate
<q> successor is the one whose id we passed in. Which is almost exactly what
we want in order to assemble our groups.

"Almost" because there is a subtle problem with our selection expression.
Consider the second or later <q> node with @rend='block' within any given
<p>, such as the one labelled [G4] above. If you look backwards (i.e. in
reverse document order) from that node, you will see that the last node
which has node [G4] as its first successor <q> with @rend='block' is none
other than node [G2]. That is to say: if we pass in the identifier of node
[G4] to the key we just created, it will return all the nodes we want, plus
one we emphatically don't want, namely {G2]. Unless we do something about
that, we will process node [G2] twice, once where we want it, within its own
<blockquote> and then again as spurious content of the following html<p>.
Rather than risk severe brain-sprain by trying to refine our key-creation
expressions still further, we can set up our <p> handling template so that
as soon as the unwanted node tries to emerge, we pass over it. More of that
in a moment.

Beyond that, we need also to cater for the last group within any such <p>,
those that may have no <q> successor in that <p> and so not be returned by
the key we just created ([G5] above). We need another key that selects
exactly the same candidate nodes, but groups them this time by the
immediately *prior* <q> node with @rend='block'. All we have to do to create
this other key is alter the axis in the "use" value (and, of course, supply
a different name for the key) giving

<xsl:key match="p[q/@rend='block']/text()|*" name="postquoteNodes"
use="generate-id(preceding::q[@rend='block'][1])" />

Since we shall only ever use this key to retrieve the nodes after the last
<q> child of any given <p> there is here no problem about capturing a later
<q> node within that <p> since there will never be one in the circumstances
when we shall use this key.

Whoopee! Time for the real code for the <p> handler...

!-- Handle a <p> with at least one <q> child with @rend='block' -->
<xsl:template match="p[q/@rend='block']">
<!-- Get the set of child <q> nodes with @rend='block' and process each in
turn -->
<xsl:for-each select="q[@rend='block']">
    <!-- Get the id of the q node currently being processed into a
variable -->
    <xsl:variable name="thisID" select="generate-id(.)"/>
    <!-- Now get the nodes preceding the current <q> node back to either the
start of
           the <p> or the previous <q> from our key, so we can process them,
          wrapping the result in a <p>. BUT  if the nodes returned by our
key include
          the preceding <q> node, we must pass over it without processing
it. (see
          discussion in main text)
    -->
     <!--  So we can check for that preceding <q> node, get its ID into a
variable -->
    <xsl:variable name="prevqNode" select="generate-id(preceding::q[1])"/>
    <p>
    <! --Now use our key to get each node in turn -->
    <xsl:for-each select="key('prequoteNodes',$thisID)">
         <! -- Process the node unless its ID matches that of the previous
<q> -->
         <xsl:if test="generate-id(.) != $prevqNode">
            <xsl:apply-templates  select="."/>
         </xsl:if>
    </xsl:for-each>
    </p>

   <!-- Now process the actual <q> node -->
    <xsl:apply-templates select="."/>

</xsl:for-each>

<!-- By this point we have processed everything in the source <p> apart from
any nodes
        following the last <q> element with @rend='block'. So we finish by
retrieving
        and processing those remaining nodes, if they exist.
-->
<!-- Get the id of the last such q child into a variable -->
<xsl:variable name="lastQuote"
select="generate-id(q[@rend='block'][last()])"/>
<!--Use our key to retrieve any  nodes after that last q node and process
them -->
<p><xsl:apply-templates  select="key('postquoteNodes',$lastQuote)"/></p>

</xsl:template>

That's it.

Add handlers for  q and hi elements, and make the root handler do some html
wrapup, and you will get as output something like:

========================
<html>
<body>
<p>This is the start of a <strong>paragraph</strong>, and as it has been
well said </p>
<blockquote>You never know what will be in a paragraph</blockquote>
<p> (Meaning among other things that the possibility that </p>
<blockquote>One good quote deserves another </blockquote>
<p>will <strong>always</strong> have to be borne in mind)</p>
</body>
</html>
========================

To borrow what Ralph Vaughan Williams said about one of his symphonies: "I'm
not sure I like it, but I think it's what I meant".

Since anyone who wants to explore these techniques is probably going to want
to play around with this material, I have zipped up the sample document, the
"complete" stylesheet [scare quotes because of course in any real
application the sheet would have to be greatly extended] and sample output
and made them available for download at
http://www.anglo-norman.net/sitedocs/workshop/keymagic.zip
from whence anyone interested can retrieve them. I'll keep them there for a
few weeks, but this is not intended to be a polished permanent offering but
just an quick adjunct to this thread.

Michael Beddow
=========================================================================
Date:         Sat, 29 Jan 2005 22:57:40 +0000
Reply-To:     mike.fraser@computing-services.oxford.ac.uk
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Michael Fraser <mike.fraser@COMPUTING-SERVICES.OXFORD.AC.UK>
Subject:      DRH2005 -- Digital Resources for the Humanities 2005 CFP
MIME-Version: 1.0
Content-Type: TEXT/PLAIN; charset=US-ASCII; format=flowed

**** First Announcement and call for proposals:  DRH 2005 ****

DRH 2005: Digital Resources for the Humanities
University of Lancaster, UK
4th - 8th September 2005

   IMPORTANT DATES:

* 31st January 2005: proposals can be submitted via the electronic
submission form at the conference website.
* 28th February, 2005: Deadline for submission of abstracts
* 15th April, 2005:  Notification of acceptance of papers, sessions,
posters and workshops
* April 2005: Registration opens
* May 2005: Provisional programme announced.

Conference Web Site: http://www.drh.org.uk

The DRH conferences have established themselves firmly in the UK and
international calendar as a major forum bringing together scholars,
postgraduate students, librarians, archivists, curators, information
scientists and computing professionals in a unique and positive way,
to share ideas and information about the creation, exploitation, use,
management and preservation of digital resources in the arts and
humanities.

At this, the tenth DRH conference, we plan to encourage papers and
sessions that focus on critical evaluation of the use of digital
resources in the arts and humanities.  What has the impact really
been?  What kinds of methodologies are being used?  What are the
assumptions that underlie our work?  How do we know that the work
that we accomplish is truly new and innovative? How does technology
change the way that we work?

The Conference will also address some of the key emerging themes and
strategic issues that engagement with ICT is bringing to scholarly
research in the arts and humanities, with a particular focus on
advanced research methods.  The kinds of questions that we would like
to see addressed might include the following: what sort of research
does ICT in the arts and humanities enable researchers to do that
could not be done before at all? Does this enable 'old' research to
be done in a significantly new way? In what ways does the technology
serve the scholarship?  Similarly, what are the key aspects of
virtual research environments ("cyberinfrasture") which can
facilitate collaborative research?

Proposals for individual papers, sessions, workshops and posters are
invited, and the abstract submission system at the conference website
will be accepting proposals from January 31st, 2005.


Types of presentation for which proposals are invited:

Papers

Proposals for papers should be no less than 750 words. Papers will be
allocated 30 minutes for presentation, including questions.

Sessions

Sessions (90 minutes) take the form of either:

Three papers. The session organizer should submit a 500-word
statement describing the proposed session topic, and include
abstracts of no less than 750 words for each paper. The session
organizer must also indicate that each author is willing to
participate in the session;

or

A panel of four to six speakers. The panel organizer should submit an
abstract of 750-1500 words describing the panel topic, how it will be
organized, the names of all the speakers, and an indication that each
speaker is willing to participate in the session.

Poster Presentations

Poster presentations may include computer technology and project
demonstrations. Posters presentations may be a more suitable way of
presenting late-breaking results, or significant work in progress.
There should be no difference in quality between poster presentations
and papers, and both will be submitted to the same refereeing process.

As an acknowledgement of the special contribution of the posters to
the conference, the Programme Committee will once again award a prize
for the best poster presentation.


The Local Organising Committee is headed by Tony McEnery and Andrew
Hardie, Department of Linguistics and English Language, University of
Lancaster.

Please contact the local organizers with any questions about
registration or conference arrangements at Lancaster:
drhconf@lancaster.ac.uk

The chair of the Programme Committee is Lorna Hughes, Assistant Director
for Humanities Computing, New York University. Please contact the
Programme Chair with any questions about submitting abstracts, or about
the reviewing process: (Lorna.Hughes@nyu.edu).

Please visit http://www.drh.org.uk for regularly updated details about the
conference and, for information on how to submit proposals.

----------------------------------------------------------------------
=========================================================================
Date:         Sat, 29 Jan 2005 21:27:12 -0700
Reply-To:     daniel.odonnell@uleth.ca
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Daniel O'Donnell <daniel.odonnell@ULETH.CA>
Organization: Department of English, University of Lethbridge
Subject:      Re: Valid HTML Considered Harmful?
Comments: To: Michael Beddow <mbteil-2@mbeddow.net>
In-Reply-To:  <200501292132.j0TLW6t10901@listserv.brown.edu>
MIME-Version: 1.0
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit

I'd like to thank Michael for such a detailed primer. I'm PDFing it and
putting in my biblio.

Since I'm the one mentioned the distorted xml,

<p>text part 1</p>
<quote>
<p>quote stuff</p>
<p>quote stuff 2</p>
</quote>
<p>rest of meta paragraph</p>,

let me say in explanation (if not defence) that this approach came very
early in my experience with SGML and Multidoc.* I can't remember if
there was originally an issue in a erroneous dtd about p/q/p (I rather
think there was back in 98 or 99) or if it was multidoc's linear
approach to documents (the Multidoc stylesheets were xsl (without the t)
avant la lettre) that made me do it, but it weren't xslt--which I've
been working with for a little less than two months, to be honest.

-dan

* Here's a challenge for you: encode the above using s, p, and quote.

Michael Beddow wrote:
> I appreciate the points made in this thread about the merits of html
> validity in general and valid xhtml in particular, but I for one would want
> to draw the line at misrepresenting the document's structure in my XML
> simply to get a better mapping to valid html. Which is what I think is
> happening in this example from earlier on in the thread:
>
> =============================
> <p>As someone said at great length:</p>
> <quote>
> <p>One paragraph of interesting citation</p>
> <p>Two paragraphs of interesting citation</p>
> </quote>
> <p>And so on and so forth</p>
> =============================
>
> Here, one paragraph enclosing a quotation which itself has two internal
> paragraphs is misrepresented as four separate paragraphs. The unity of the
> enclosing paragraph is denied, and the containment of the quoted paras is
> translated into sequential contiguity.
>
> That seems to me too high a price to pay for being able to pass the XML
> straightforwardly through XSLT and get valid hmtl. Nor am I convinced that
> the effort involved in re-expressing the inherent structure of the XML
> document via linking and aggregation techniques is worth undertaking for the
> sake of the desired html, especially if (as in my case) the html is
> generated on demand simply as the delivery vehicle best suited to giving as
> many people as possible a reasonably accurate  view of what the XML
> contains -- which is pretty much all that can be hoped for in the present
> state of technology outside environments where document producers have
> complete control over the client software.
>
> To stick with the case that launched this thread (on the understanding that
> we're focussing on the blockquote issue because of the generic problems it
> raises): two ways of getting an XML <p> to be split into self-contained html
> <p>s which are siblings of  <blockquotes> rather than their parent, without
> distorting the  XML at source, have been mentioned by earlier contributors.
> Let me say a little bit more about them in the hope that it may help those
> who want to generate valid html via XSLT from TEI markup see ways forward.
>
> Actually, I'm going to say as little as possible about the first method,
> mentioned with appropriate distaste by a couple of people already, namely
> abusing disable-output-escaping to pass off markup as text. As others have
> said, XSLT is for inputting, transforming, and outputting trees. And
> outputting trees is more like wrapping presents than making sandwiches.
>
> You can start making a sandwich by choosing one slice of bread, putting it
> on a plate, smearing on some spread, then you can wander at leisure around
> the kitchen adding ingredients until you decide your sandwich is finished.
> Whereupon you top it with another slice of bread (needn't even be from the
> same loaf as long as the size is roughly right) or even opt to leave it as
> an open sandwich. And if you decide that slice of pickled gherkin probably
> wasn't such a great idea after all, you can take it out again before you
> take your first bite. This is what using a serial processor is like; but an
> XSLT engine isn't a serial processor.
>
> Wrapping presents is different. You have to decide who's is getting what,
> then you group together the gifts intended for a given recipient and only
> then reach for the wrapping paper and wrap them all up in a single
> operation. In fact, you may have been doing the grouping long before you
> even thought about buying the wrapping paper, reaching for the carrier bag
> where you are accumulating Uncle Jim's presents whenever you encounter
> something in your sock drawer that you realise you are never ever going to
> wear yourself. But once you've wrapped the presents, you can't change your
> mind without starting all over again, so you'd better be sure you really
> have settled what the parcel is to contain before you start the wrapping.
> Which is the approach you need to take when using a tree-processing system.
>
> In many cases where XSLT output needs to be grouped in some way, the
> required grouping is already explicit in the source markup, so you can grab
> the contents of your intended parcels in a single operation and wrap them
> straight away, without explicitly being aware of the need to group. In other
> words, it's as if your task is simply re-wrapping presents someone else
> already assembled and assigned to their future recipients; all you need to
> do is strip of the old wrapping and put on a new one using different paper.
>
> Which is fine as long as you encounter only such cases. But then along comes
> a document where some of the things that need to be grouped together before
> you can do the wrapping operation heven't already been conveniently
> pre-grouped for you. Your first reaction may be to think XSLT can't cope.
> But it can, provided you learn how to use it to group material according to
> specifications that you provide. XSLT 2.0 provides commands to do just that;
> but  XSLT 1.0 can do it too, Although the techniques needed to group in XSLT
> 1.0 are harder to assimilate and deploy than those in XSLT 2.0, the core of
> what you need to grasp, namely the crafting of XPath expressions to select
> precisely those things you want to group together, is common to both
> versions of the language.
>
> I'll try to explain this with reference to the following sample document,
> consisting of an XML <p> which contains <q> children which we wish to be set
> out as html <blockquotes>, meaning that to achieve valid html we need to
> split the single XML parent <p> into a number of sibling html <p>s at the
> same level as the <blockquote>s we shall be generating.
>
> ======================================
> <?xml version="1.0" encoding="UTF-8"?>
> <text>
> <p>This is the start of a <hi rend="bold">paragraph</hi>, and as it has been
> well said <q rend="block"> You never know what will be
> in a paragraph.</q> (Meaning among other things that the
> possibility that <q rend="block">One good quote deserves
> another </q>will <hi rend="italic">always</hi> have to be borne in mind)</p>
> </text>
> ======================================
>
> Let's indicate what the groups are that we intend to wrap in output
> elements. I'll do that using start and end tags in square brackets, thus
> [G1]Contents of group 1 [/G1] etc
>
> <text>
> <p>[G1]This is the start of a <hi rend="bold">paragraph</hi>, and as it has
> been
> well said[/G1] <q rend="block"> [G2]You never know what will be
> in a paragraph.[/G2]</q>[G3] (Meaning among other things that the
> possibility that[/G3] <q rend="block">[G4]One good quote deserves
> another [/G4]</q>[G5]will <hi rend="italic">always</hi> have to be borne in
> mind)[/G5]</p>
> </text>
>
> Comparing the placing of my  [Gn] tags to the location of true XML element
> boundary markers, it will be evident that two of the groups we want to
> "wrap" -- G2 and G4 -- are already "wrapped" in the source xml. So they are
> already grouped for us. We could get at them by matching the elements
> concerned and writing out their contents wrapped in the new "blockquote"
> element of our choice.
>
> So our first thought might be to put these templates into our XSLT.
>
> ======================================
>
> <xsl:template match="p">
> <p><xsl:apply-templates/></p>
> </xsl:template>
>
> <xsl:template match="q[@rend="block"]>
> <blockquote><xsl:apply=templates/></blockquote>
> </xsl:template>
>
> =======================================
>
> Which sadly doesn't do everything we want. Sure enough, the <q>s with
> @rend='block' are successfully transformed into <blockquotes>, but those
> <blockquotes> are children of the <p> we have created, and so will not
> validate as html.
>
> So now it's time to check our ropes, adjust our crampons, and tackle a steep
> bit of the learning curve. The effort could be worth it.
>
> Our first attempt may mean we climb ourselves into trouble. If we think in
> serial processing terms, we may assume that the problem needs to be solved
> within the template that handles the block-rendered <q>s. So we attempt to
> modify that template, reach for the treacherous tool of
> disable-output-escaping and try to progress by writing malformed markup,
> passed off as <xml:text>, into the output: a </p> before our <blockquote>
> and a <p> after it. It will all end badly -- literally so, since you'll
> finish up, among various other problems, with one <p> too many after your
> last <blockquote>.
>
> Now there's a useful rule of thumb here that's often been formulated by
> Wendell (though in a somewhat more rigorous way): if you think you need to
> use d.o.e in this sort of way, it's a sign that you are trying to operate
> too low down the tree (sorry for the directional confusion, real world trees
> are vertically directed like real-world mountains, but CompSci trees alas
> grow downwards from a root at the top...) So you need to step back up the
> tree a level and re-examine the problem from that higher, "elevated",
> standpoint.
>
> In other words, we need to tackle the problem at the level where we process
> the enclosing XML <p>, instead of trying to firefight only when a template
> for a <q rend='block'> has been triggered. So let's first refine our <p>
> template match so that it identifies for special treatment only those <p>s
> where the problem arises, viz those that have at least one <q> child with
> @rend='block'.
>
> <xsl:template match="p[q/@rend='block']">
> [more stuff to come here]
> </xsl:template>
>
> Now, when this template fires we want to do the following:
> 1. Output all the nodes before the first <q> child, [G1] in my example,
> wrapping them in a <p>
> 2. Output the first <q> child, with its contents [G2] wrapped in a
> <blockquote>
> 3. Output all the nodes before the next <q> child, [G3] in my example,
> wrapping them in a <p>
> 4. Output the next <q> child, with its contents [G4] wrapped in a
> <blockquote>
> And so on, until we have output the last <q> child, duly re-wrapped as a
> <blockquote>
> 5. Then we have finally to output all the nodes after that last <q> child ,
> i.e. [G5], again wrapped in a <p>.
>
> So how do we do that? Well, we've already done the necessary for steps 2 and
> 4. The problem is: how to precede and follow  steps 2 and 4 with the output
> of the grouped items of our choice.
> Let's pseudo-code that:
>
> <xsl:template match="p[q/@rend='block']">
>
> FOR EACH  ( < q> CHILD HAVING @rend='italic')
>    BEGIN
>        <p>
>          PROCESS NODES PRECEDING THAT CHILD
>        </p>
>         PROCESS THE CHILD ITSELF (by rewriting as <blockquote>)
>    END
>         <p>
>         PROCESS NODES FOLLOWING LAST <q> CHILD
>         </p>
> </xsl:template>
>
> All we have to do is replace the pseudo-code by real XSLT and the job's
> done, (or at least the apparently hard parts of it are -- there's more to be
> done to cope with more realistic documents, but most of it is relatively
> straightforward stuff that I won't go into).
>
> What we need now is what Wendell alludes to earlier in this thread as "key
> magic".  Like most prestidigitation, such tricks take a bit of practice to
> perform, but in principle it's pretty simple. Alas, the nomenclature and
> syntax required to put that principle into effect are somewhat rebarbative
> in XSLT 1.0. And since the discussions of using keys for grouping found in
> XSLT primers tend to concentrate on "datacentric" XML, it may not be
> immediately clear how and why keys can also be useful for the grouping tasks
> we TEI-ish docucentrics also encounter.
>
> To group things prior to wrapping them we need (a) a way of specifying which
> items are candidates for inclusion in one or the other of our groups  (b) a
> way of singling out from among those candidates just the items that belong
> in each specific group.
>
> In the example case, what qualifies a document node as a potential member of
> one of the groups we want to assemble than wrap in an html <p> is that it's
> a child node of an XML <p> which also has <q> children where @rend='block".
> We need to build an XPath expression that will select just those qualifying
> nodes. Let's cast our net fairly widely at first then narrow the mesh. We
> can begin with an expression that will select only those <p>s that have "q"
> children with a @rend value set to 'block', like so: which we do  by adding
> a simple predicate expression in square brackets after the "p":
> match = "p[q/@rend='block']
> We're making progress, but what we really want to group are not the
> aggregated contents of the <p>s we have so far selected: we want as the
> candidate constituents of our groups the text and element node children of
> those <p>s  . So, leaving our predicate in place to filter the <p>s as
> before, we extend the XPath to select children of those filtered<p>s,
> whether they are text nodes or element children (along with any text
> descendants those children may have), giving:
> match = "p[q/@rend='block']/text()|*"
>
> And that's it. All our potential candidates for grouped output will be
> selected by that expression.
>
> But how do we now do the actual grouping of those selected candidates into
> the required html <p> chunks? Looking back to our pseudo-code, we see that
> we want to be able to say to the XSLT processor, "Hand me just those nodes
> which (a) match my general criteria for group inclusion AND (b) for which it
> is the case that the next <q> node in document order is the next <q> node we
> intend to output as a <blockquote>, so that I can wrap those nodes in a <p>
> and output them first before that blockquote is processed".
>
> To do that, we need to have a unique identifier for each <q> node with
> @rend='block'. Which the XSLT processor is happy to give us. Pass an
> expression selecting any node as a parameter to its generate-id() function
> and the processor will return an id unique to that node (unique for this run
> of the processor, that is, but that's all we need here). Now, each of the
> candidate nodes we selected by the XPath above will have, sharing its common
> <p> ancestry, one or zero immediate successor <q> nodes with @rend='block'
> (why "or zero"? : look at [G5] above for the answer). When one of those
> candidate nodes is the current node, that immediate successor <q> node will
> be selected by the expression "following::q[@rend='block'][1], which says
> "look from the current node along the "following" access and select the
> first <q> node along that axis. (Purists might say the [1] is superfluous
> for what we are about to do, but it helps some processors optimise the
> instruction). And to get a unique id for that selected successor node, so we
> can easily retrieve the nodes we want to associate with it, we pass the
> expression selecting it to the generate-id() function, like so:
>
> generate-id(following::q[@rend='block'][1])
>
> Time to face the grim syntactic realities of creating the actual XSLT key.
>
> At the top of our document (or more precisely, outside any templates or RTF
> constructors), we need to put an expression like
> <xsl:key match="XPATH THAT IDENTIFIES OUR CANDIDATE NODES FOR GROUPING"
> name="SOMETHING SUITABLY MNEMONIC" use="EXPRESSION WHICH GROUPS THE
> CANDIDATE NODES IN OUR CHOSEN WAY" />
>
> We've already worked out the expression that will become our match value,
> and the id we just generated turns out to be the criterion we need to form
> our groups, because we will always want as members of our group for output
> as an html <p> those nodes which have the same immediate successor <q> node.
> So we can supply the necessary attribute values to create our key:
> <xsl:key match="p[q/@rend='block']/text()|*" name="prequoteNodes"
> use="generate-id(following::q[@rend='block'][1])" />
>
> Now if we pass as parameters to the key() function the name of this key,
> "prequoteNodes", plus the generated id of any <q> node that has
> @rend='block' ,  the processor will return to us the nodes whose immediate
> <q> successor is the one whose id we passed in. Which is almost exactly what
> we want in order to assemble our groups.
>
> "Almost" because there is a subtle problem with our selection expression.
> Consider the second or later <q> node with @rend='block' within any given
> <p>, such as the one labelled [G4] above. If you look backwards (i.e. in
> reverse document order) from that node, you will see that the last node
> which has node [G4] as its first successor <q> with @rend='block' is none
> other than node [G2]. That is to say: if we pass in the identifier of node
> [G4] to the key we just created, it will return all the nodes we want, plus
> one we emphatically don't want, namely {G2]. Unless we do something about
> that, we will process node [G2] twice, once where we want it, within its own
> <blockquote> and then again as spurious content of the following html<p>.
> Rather than risk severe brain-sprain by trying to refine our key-creation
> expressions still further, we can set up our <p> handling template so that
> as soon as the unwanted node tries to emerge, we pass over it. More of that
> in a moment.
>
> Beyond that, we need also to cater for the last group within any such <p>,
> those that may have no <q> successor in that <p> and so not be returned by
> the key we just created ([G5] above). We need another key that selects
> exactly the same candidate nodes, but groups them this time by the
> immediately *prior* <q> node with @rend='block'. All we have to do to create
> this other key is alter the axis in the "use" value (and, of course, supply
> a different name for the key) giving
>
> <xsl:key match="p[q/@rend='block']/text()|*" name="postquoteNodes"
> use="generate-id(preceding::q[@rend='block'][1])" />
>
> Since we shall only ever use this key to retrieve the nodes after the last
> <q> child of any given <p> there is here no problem about capturing a later
> <q> node within that <p> since there will never be one in the circumstances
> when we shall use this key.
>
> Whoopee! Time for the real code for the <p> handler...
>
> !-- Handle a <p> with at least one <q> child with @rend='block' -->
> <xsl:template match="p[q/@rend='block']">
> <!-- Get the set of child <q> nodes with @rend='block' and process each in
> turn -->
> <xsl:for-each select="q[@rend='block']">
>     <!-- Get the id of the q node currently being processed into a
> variable -->
>     <xsl:variable name="thisID" select="generate-id(.)"/>
>     <!-- Now get the nodes preceding the current <q> node back to either the
> start of
>            the <p> or the previous <q> from our key, so we can process them,
>           wrapping the result in a <p>. BUT  if the nodes returned by our
> key include
>           the preceding <q> node, we must pass over it without processing
> it. (see
>           discussion in main text)
>     -->
>      <!--  So we can check for that preceding <q> node, get its ID into a
> variable -->
>     <xsl:variable name="prevqNode" select="generate-id(preceding::q[1])"/>
>     <p>
>     <! --Now use our key to get each node in turn -->
>     <xsl:for-each select="key('prequoteNodes',$thisID)">
>          <! -- Process the node unless its ID matches that of the previous
> <q> -->
>          <xsl:if test="generate-id(.) != $prevqNode">
>             <xsl:apply-templates  select="."/>
>          </xsl:if>
>     </xsl:for-each>
>     </p>
>
>    <!-- Now process the actual <q> node -->
>     <xsl:apply-templates select="."/>
>
> </xsl:for-each>
>
> <!-- By this point we have processed everything in the source <p> apart from
> any nodes
>         following the last <q> element with @rend='block'. So we finish by
> retrieving
>         and processing those remaining nodes, if they exist.
> -->
> <!-- Get the id of the last such q child into a variable -->
> <xsl:variable name="lastQuote"
> select="generate-id(q[@rend='block'][last()])"/>
> <!--Use our key to retrieve any  nodes after that last q node and process
> them -->
> <p><xsl:apply-templates  select="key('postquoteNodes',$lastQuote)"/></p>
>
> </xsl:template>
>
> That's it.
>
> Add handlers for  q and hi elements, and make the root handler do some html
> wrapup, and you will get as output something like:
>
> ========================
> <html>
> <body>
> <p>This is the start of a <strong>paragraph</strong>, and as it has been
> well said </p>
> <blockquote>You never know what will be in a paragraph</blockquote>
> <p> (Meaning among other things that the possibility that </p>
> <blockquote>One good quote deserves another </blockquote>
> <p>will <strong>always</strong> have to be borne in mind)</p>
> </body>
> </html>
> ========================
>
> To borrow what Ralph Vaughan Williams said about one of his symphonies: "I'm
> not sure I like it, but I think it's what I meant".
>
> Since anyone who wants to explore these techniques is probably going to want
> to play around with this material, I have zipped up the sample document, the
> "complete" stylesheet [scare quotes because of course in any real
> application the sheet would have to be greatly extended] and sample output
> and made them available for download at
> http://www.anglo-norman.net/sitedocs/workshop/keymagic.zip
> from whence anyone interested can retrieve them. I'll keep them there for a
> few weeks, but this is not intended to be a polished permanent offering but
> just an quick adjunct to this thread.
>
> Michael Beddow

--
Daniel Paul O'Donnell, PhD
Associate Professor of English
University of Lethbridge
Lethbridge AB T1K 3M4
Tel. (403) 329-2377
Fax. (403) 382-7191
E-mail <daniel.odonnell@uleth.ca>
Home Page <http://people.uleth.ca/~daniel.odonnell/>
The Digital Medievalist Project: <http://www.digitalmedievalist.org/>
=========================================================================
Date:         Sun, 30 Jan 2005 22:06:27 +1300
Reply-To:     Conal Tuohy <Conal.Tuohy@VUW.AC.NZ>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Conal Tuohy <Conal.Tuohy@VUW.AC.NZ>
Subject:      Re: Valid HTML Considered Harmful?
MIME-Version: 1.0
Content-Type: text/plain; charset="Windows-1252"
Content-Transfer-Encoding: 8bit

Wendell Piez wrote:

> One obstacle that remains is the difficulty -- even, maybe,
> the theoretical impossibility (I'm not sure how far the
> mathematicians have plumbed this issue yet) -- of guaranteeing
> that all output from a given stylesheet (or at any rate of a
> "meaningful" stylesheet that produces the kind of sensible
> output we want) will be valid to a given DTD.

I'd have thought, given XSLT's well-known Turing-completeness, that the general case would have to be unprovable (it's not even possible to prove that any transform will ever halt!). Of course, certain simple transforms could certainly be proved, but whether such transforms would be powerful enough to "meaningfully" transform TEI documents into valid XHTML; well, that's a really interesting question :-)

Cheers

Con
=========================================================================
Date:         Sun, 30 Jan 2005 15:31:03 -0500
Reply-To:     Francois Lachance <lachance@ORIGIN.CHASS.UTORONTO.CA>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Francois Lachance <lachance@ORIGIN.CHASS.UTORONTO.CA>
Subject:      Re: Valid HTML Considered Harmful?
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit

Thank you to Micheal Beddow for the magistral XSLT tutorial on key() and
generate-id() functions. It not only provides an excellent demonstration
of what could be called xylem transformations of XML trees. Michael's care
in recording the thinking process helps learners transfer the skills to
other "pie splitting" situations.  I can foresee future XSLT manuals
referencing "Wedges and Wrappers".

Con,  Any XSLT transform will halt. Try writing an XSLT transform that
nests elements that we provoke an infinite loop. It breaks. The processor
returns an error. That counts as halting.  The XSLT file is validated by
the processor.

        <xsl:template match="*">
        <xsl:variable name="looper" select="."/>
        <xsl:for-each select="$looper"/>
        <xsl:for-each select="$looper"/>
        </xsl:for-each>
        </xsl:for-each>
        </xsl:template>

Likewise, nesting in a document instance be it TEI-conformant and valid
XML or HTML-conformant and valid XML or XSLT-conformant and valid XML may
be very very deep however it is always in each and every document instance
less than infinity.

In response to Wendell's question,  guarantees depen muchly upon the human
factor. The writer of the XSLT transform needs to be mindful of the DTD
(or Schema) . For example, in the case of the <quote> transformation to
<blockquote> it is important to remember that any output that has any
unwrapped <p> nested in a <blockquote> will break when validating against
the HTML DTD. And  so one refines the template to be called.

<xsl:template match="quote" name="q_block">
<blockquote><div>
<xsl:copy-of select="."/>
</blockquote></div>
</xsl:template>

TEI - conformant fragment....

<p> .... <quote><p> one </p> <p> two </p> <p> three </p> </quote> ... </p>

HTML - conformant fragment...

<p> .... </p><blockquote><div><p> one </p> <p> two </p> <p> three </p>
</div></blockquote><p> ... </p>

Success depends upon human knowledge of tree traversal and matrix reading.
Aboriculturally,  grafting is a combination of cutting (selecting
&copying) and splicing (grouping &sorting). As tempting as it is to reach
for analogies, it may be wise not to settle on an incomplete one. Observe
Michael's reminder about XML trees and roots. Because XSLT transforms make
use of machine memory, there is much scope for the activity of marking
before any grouping of selections.

Because an XSLT transform can not only change the position and nesting of
elements but also element names furthermore because the names valid in
both source and target instances, althought valid according to different
DTDs, is limited, translation is possible. The very interesting question
arises of taking a well-formed instance and transforming it into a valid
instances. In the singular, the question is answered by "yes." It is
possible to write an XSLT file to transform a given well-formed instance
into a valid instance. However no guarantees that the file would be
equally applicable to other well-formed instances for lossless
transformations.  It could be written to override default templates ---
<xsl:apply-templates/> ---  simply not converting <mud> into <bricks>
without <straw>.

Now then key() meet name(). What I really like about Michael's magisterial
tutorial is that it suggests how XSLT might be very interestingly applied
to textual analysis and even automate feature structure marking.

Mega thanks to Dan who asked and defended his asking. From the cracked nut
rises the bough.

--
Francois Lachance, Scholar-at-large
http://www.chass.utoronto.ca/~lachance/jardin

2005 Year of Comparative Connections. DIA: Comparative connections? LOGZ:
Connection, first. Comparison, next. DIA: Check. Comparable ways of
connecting. LOGZ: Selection outcomes, first. Comparative Connections,
next.
=========================================================================
Date:         Sun, 30 Jan 2005 13:24:37 -0700
Reply-To:     daniel.odonnell@uleth.ca
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Daniel O'Donnell <daniel.odonnell@ULETH.CA>
Organization: Department of English, University of Lethbridge
Subject:      Re: Valid HTML Considered Harmful?
Comments: To: Francois Lachance <lachance@ORIGIN.CHASS.UTORONTO.CA>
In-Reply-To:  <200501302020.j0UKKSt28718@listserv.brown.edu>
MIME-Version: 1.0
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit

Francois Lachance wrote:
> Mega thanks to Dan who asked and defended his asking. From the cracked nut
> rises the bough.

I don't think I've ever been called nuts so elegantly before. I'll have
to put this in my professional activities report for the year as
evidence of productivity.
--
Daniel Paul O'Donnell, PhD
Associate Professor of English
University of Lethbridge
Lethbridge AB T1K 3M4
Tel. (403) 329-2377
Fax. (403) 382-7191
E-mail <daniel.odonnell@uleth.ca>
Home Page <http://people.uleth.ca/~daniel.odonnell/>
The Digital Medievalist Project: <http://www.digitalmedievalist.org/>
=========================================================================
Date:         Sun, 30 Jan 2005 15:59:00 -0500
Reply-To:     Syd_Bauman@Brown.edu
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Syd Bauman <Syd_Bauman@BROWN.EDU>
Subject:      Re: Mixed content and tei
In-Reply-To:  <41EBF525.507@uleth.ca>
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit

> Good observation. The list is actually supposed to be an index
> with up to three levels. For this reason the only change I'd make
> to your suggestion would be to label the subfield2s as <label> as
> well.

I'm not sure I understand the structure you're going for, but an
alternative encoding you may wish to consider is to put the <label>s
inside the <item>s:

      <list type="index">
        <head>head-a</head>
        <item>
          <label>subfield1-a</label>
          <list>
            <item>
              <label>subfield2-a</label> <ptr target="#locater1"/>
            </item>
          </list>
        </item>
        <item>
          <label>subfield1-b</label>
          <list>
            <item>
              <label>subfield2-g</label> <ptr target="#locater2"/>
            </item>
            <item>
              <label>subfield2-h</label> <ptr target="#locater3"/>
            </item>
          </list>
        </item>
      </list>

Here every <item> has 2 children: either
   <label> <ptr>
or
   <label> <list>.

I didn't quite know what to do with the "head-a", since I didn't know
whether it was really a heading or analagous to a higher level
subfield. If the latter, it could be a <label>, too:

<list type="index">
  <item>
    <label>field-A</label>
    <list>
      <item>
        <label>subfield1-a</label>
        <list>
          <item> <label>subfield2-a</label> <ptr target="locater1"/> </item>
        </list>
      </item>
      <item>
        <label>subfield1-b</label>
        <list>
          <item> <label>subfield2-g</label> <ptr target="locater2"/> </item>
          <item> <label>subfield2-h</label> <ptr target="locater3"/> </item>
        </list>
      </item>
    </list>
  </item>
  <item>
    <label>field-B</label>
    <list>
      <item> <label>subfield1-i</label> <ptr target="lacater4"/> </item>
      <item> <label>subfield1-j</label> <ptr target="lacater5"/> </item>
      <item> <label>subfield1-k</label> <ptr target="lacater6"/> </item>
    </list>
  </item>
</list>

This <list> is valid against TEI vanilla, and also against the much
more restricve declarations:

<!ELEMENT list ( item+ )>
<!ELEMENT item ( label, ( list | ptr ) )>
=========================================================================
Date:         Sun, 30 Jan 2005 15:03:19 -0700
Reply-To:     daniel.odonnell@uleth.ca
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Daniel O'Donnell <daniel.odonnell@ULETH.CA>
Organization: Department of English, University of Lethbridge
Subject:      a repository for xslt questions and fragments?
MIME-Version: 1.0
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit

Hi all,
The last couple of contributions to tei-l bring me back the question of
whether it might be worthwhile to host a wiki-based xslt fragment
exchange. The question of how to extract xhtml:blockquote from tei:p
produced quite complex responses and it would be good to have these
preserved in a searchable way.

As some of you know, the digital medievalist project
(http://www.digitalmedievalist.org/) hosts a wiki which we are
experimenting with as a means of preserving and refining communal
knowledge. While tei:xslt fragment problems like this are not
exclusively problems for medievalists, they are problems shared with
medievalists and hence would fall under our mandate. While I would need
to double check with the other editors, I think this is something we
would gladly host if the rest of the (tei) community thought it was
worthwhile doing.

Wikis by their nature are bottom up type things. One can build them but
they only work if potential contributors feel they are worthwhile to
contribute to. One of the interesting results we've been having with our
experiments at dm, has been the discovery that the economics of academia
tend to make wikis unsuited as a venue for *research* per se: unlike
contributors to the wikipedia, professional academics need to be paid
for their research in publication credit.

xslt fragments on the other hand seem a slightly different type of
thing, and one that might work well in a wiki environment: people
contribute them gladly to lists, and several--the Muench method, the
"Wendell wandle" (or was it Piez process) have even picked up names. A
Wiki might be an attractive in-between-step between posting to a list
and submitting to a refereed journal.

Opinions?
-dan
--
Daniel Paul O'Donnell, PhD
Associate Professor of English
University of Lethbridge
Lethbridge AB T1K 3M4
Tel. (403) 329-2377
Fax. (403) 382-7191
E-mail <daniel.odonnell@uleth.ca>
Home Page <http://people.uleth.ca/~daniel.odonnell/>
The Digital Medievalist Project: <http://www.digitalmedievalist.org/>
=========================================================================
Date:         Mon, 31 Jan 2005 12:48:58 +1300
Reply-To:     Conal Tuohy <Conal.Tuohy@VUW.AC.NZ>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Conal Tuohy <Conal.Tuohy@VUW.AC.NZ>
Subject:      Re: Valid HTML Considered Harmful?
MIME-Version: 1.0
Content-Type: text/plain; charset="iso-8859-1"
Content-Transfer-Encoding: 8bit

Francois Lachance wrote:

> Con,  Any XSLT transform will halt. Try writing an XSLT transform that
> nests elements that we provoke an infinite loop. It breaks.
> The processor
> returns an error. That counts as halting.  The XSLT file is
> validated by
> the processor.

Hi Francois

While it's true that some xslt processors will detect infinite loops, it is in principle not possible to detect all such loops. The XSLT spec itself warns about this issue, pointing out that running 3rd-party stylesheets may present a denial-of-service threat.

http://www.zvon.org/xxl/XSLTreference/W3C/xslt.html#section-Applying-Template-Rules

Some XSLT processors may give up after recursing a certain number of times, but this is implementation-specific, and not in conformance with the spec. NB a stylesheet can recurse without producing output, so detecting an overflow of the output buffer is also not a 100% reliable way to detect a non-terminating transform.

Anyway ... my point was really that automated proof of XSLT transforms (even of the halting problem, let alone compliance of the output to a particular schema) is not only infeasible, but actually theoretically impossible _in the general case_.

That said, I do think it's a feasible (and valuable) project to attempt to prove "output-document-schema-compliance" of stylesheets which are constrained in various ways (e.g. to refer only to the "child" or "descendant" axes in apply-templates; not calling named-templates at all, or at least, not recursively).

Cheers

Con
=========================================================================
Date:         Mon, 31 Jan 2005 13:02:49 +1300
Reply-To:     Conal Tuohy <Conal.Tuohy@VUW.AC.NZ>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Conal Tuohy <Conal.Tuohy@VUW.AC.NZ>
Subject:      Re: Valid HTML Considered Harmful?
MIME-Version: 1.0
Content-Type: text/plain; charset="iso-8859-1"
Content-Transfer-Encoding: 8bit

Thanks Michael for the "flattening" stylesheet!

I realise I ought to contribute something useful to this thread, too, not just blithering on about Turing machines, as is my wont :-)

I wrote a stylesheet for this same purpose - what I called "partitioning" - to flatten the structure of nested TEI elements prior to conversion into XHTML. At the NZETC we use a "pipelined" processing model, in which a number of transforms are applied sequentially to the TEI, each transform taking the output of the previous transform. We use Apache Cocoon for this purpose, but there are a number of other products, including AxKit (which I know Sebastian uses), with a similar processing architecture. The nice thing is that it means you can separate the issue of flattening the TEI from the issue of converting it to XHTML, simply by applying a "flatten" stylesheet first, and then a "tei-to-html" stylesheet.

The partitioning stylesheet is a shocker (in my defence I wrote it some time ago, in a hurry) but it basically does the trick. I will dig it out and post it somewhere for reference. Perhaps, if Daniel can arrange it, on the Digital Medievalist wiki? Or is there some similar feature on SourceForge? Perhaps not a wiki, but something almost as good? :-)

Cheers

Con
=========================================================================
Date:         Sun, 30 Jan 2005 20:03:19 -0500
Reply-To:     Francois Lachance <lachance@ORIGIN.CHASS.UTORONTO.CA>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Francois Lachance <lachance@ORIGIN.CHASS.UTORONTO.CA>
Subject:      Proving validity with XSLT and loops in XSLT
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit

Con,

Quite right in pointing out the W3C reco and the warning against loops.

In the interests of Wendell's original question which you too judge a
feasible and valuable project.

I too want insist on instances. But not by eliminating recursivity.

An XSLT instance can itself be the subject of XSLT transformation, and, as
we have seen Michael Beddow illustrate, of analysis. It becomes possible
to test for loop constructions (which is not the same as testing looping).
Take the example for the W3C recommendation:


<xsl:template match="foo">
  <xsl:apply-templates select="."/>
</xsl:template>


and consider generate() and then testing if for a given <xsl:template>
element what the value of the "match" attribute "match" exists might be
and compare with any <xsl:apply-template> elements that might be located
on the child axis of the given <xsl:template> element with a "select"
attribute of a specified value.

Again, in short, XSLT transform files are themselves transformable using
XSLT.

There must be some way of mapping the recursive functions and nesting of a
stylesheet to the permissible nesting of the input and output instances.


--
Francois Lachance, Scholar-at-large
http://www.chass.utoronto.ca/~lachance/jardin

2005 Year of Comparative Connections. DIA: Comparative connections? LOGZ:
Connection, first. Comparison, next. DIA: Check. Comparable ways of
connecting. LOGZ: Selection outcomes, first. Comparative Connections,
next.
=========================================================================
Date:         Mon, 31 Jan 2005 13:59:43 +0000
Reply-To:     Brad Scott <brad@SEMANTICO.COM>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Brad Scott <brad@SEMANTICO.COM>
Subject:      Re: Valid HTML Considered Harmful?
In-Reply-To:  <41FC6220.8020602@uleth.ca>
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii; format=flowed
Content-Transfer-Encoding: 7bit

For what it's worth, I got round the quotes in paragraphs problem for a
recent project simply by transforming such quotes to <span
class="blockquote">, making its child <p>s into <br />s, and getting the
CSS to do the rest. This way I got strict XHTML conformance rather easily.

It didn't seem any less elegant than creating <p>s in the output that
weren't in the input.

Brad


--
_______________________________

Brad Scott
Project Development Manager
Semantico
32-33 Bond Street
Brighton BN1 1RD
Sussex  UK

Tel: +44 (0)1273 722222 x212
Fax: +44 (0)1273 723232
Email: Brad.Scott@semantico.com
Web: http://www.semantico.com

_______________________________
=========================================================================
Date:         Mon, 31 Jan 2005 17:31:17 +0000
Reply-To:     Sebastian Rahtz <sebastian.rahtz@COMPUTING-SERVICES.OXFORD.AC.UK>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Sebastian Rahtz <sebastian.rahtz@COMPUTING-SERVICES.OXFORD.AC.UK>
Subject:      Re: Valid HTML Considered Harmful?
Comments: To: Brad Scott <brad@SEMANTICO.COM>
In-Reply-To:  <200501311410.j0VEABt26738@listserv.brown.edu>
MIME-Version: 1.0
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit

Brad Scott wrote:

>For what it's worth, I got round the quotes in paragraphs problem for a
>recent project simply by transforming such quotes to <span
>class="blockquote">, making its child <p>s into <br />s, and getting the
>CSS to do the rest. This way I got strict XHTML conformance rather easily.
>
>
>
how about lists inside paragraphs? I meet those all
the time

--
Sebastian Rahtz
Information Manager, Oxford University Computing Services
13 Banbury Road, Oxford OX2 6NN. Phone +44 1865 283431

OSS Watch: JISC Open Source Advisory Service
http://www.oss-watch.ac.uk
=========================================================================
Date:         Mon, 31 Jan 2005 11:55:37 -0500
Reply-To:     "John A. Walsh" <jawalsh@INDIANA.EDU>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         "John A. Walsh" <jawalsh@INDIANA.EDU>
Subject:      Re: Valid HTML Considered Harmful?
Comments: To: Sebastian Rahtz <sebastian.rahtz@COMPUTING-SERVICES.OXFORD.AC.UK>
In-Reply-To:  <41FE6B65.1060208@computing-services.oxford.ac.uk>
Mime-Version: 1.0 (Apple Message framework v619.2)
Content-Type: text/plain; charset=US-ASCII; format=flowed
Content-Transfer-Encoding: 7bit

On Jan 31, 2005, at 12:31 PM, Sebastian Rahtz wrote:

> Brad Scott wrote:
>
>> For what it's worth, I got round the quotes in paragraphs problem for
>> a
>> recent project simply by transforming such quotes to <span
>> class="blockquote">, making its child <p>s into <br />s, and getting
>> the
>> CSS to do the rest. This way I got strict XHTML conformance rather
>> easily.
>>
>>
>>
> how about lists inside paragraphs? I meet those all
> the time
>
>

Because of constructs like lists, which are valid in TEI <p>s but not
in XHTML <p>s, I've had to resort to transforming TEI <p>s to <div
class="p"> for XHTML validity.  It works, but is not ideal.

John

| John A. Walsh, Associate Director for Projects and Services
| Digital Library Program / Indiana University Libraries
| Indiana University, 1320 East Tenth Street, Bloomington, IN 47405
| Voice:812-855-8758 Fax:812-856-2062 <mailto:jawalsh@indiana.edu>
=========================================================================
Date:         Mon, 31 Jan 2005 18:22:33 -0000
Reply-To:     Michael Beddow <mbteil-2@mbeddow.net>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Michael Beddow <mbteil-2@MBEDDOW.NET>
Subject:      Re: Valid HTML Considered Harmful?
MIME-Version: 1.0
Content-Type: text/plain; charset="iso-8859-1"
Content-Transfer-Encoding: 7bit

Brad Scott wrote:

> For what it's worth, I got round the quotes in paragraphs problem for a
> recent project simply by transforming such quotes to <span
> class="blockquote">, making its child <p>s into <br />s, and getting the
> CSS to do the rest. This way I got strict XHTML conformance rather easily.
>

Well yes, if the only aim is to get something that can carry that little
logo at the bottom, then there are all kinds of easy ways to achieve it. (In
particular, emitting atomic presentational events via  <br/> where the
source had structural element boundaries will often work, but conceptually
it's not vastly different from using d.o.e to fake such element boundaries.)

As I remarked in an earlier posting, my personal view and practice is that
it's the XML that matters and I will re-write it on demand in whatever sort
of html works best for the greatest number of clients in the current,
constantly changing, user environment.

But I think a guiding concern of this thread was that the aim was not
(x)html conformance by any means that worked, but achieving on both sides of
the process markup that was (a) valid according to the respective DTD and
(b) maximally expressive of the structure of the document within the
possibilities those DTDs offer.  And a principal  reason for aspiring to
that expressiveness on the xhtml side was the idea that both accessibility
aids and the much-heralded but so far highly elusive "intelligent agents"
supposedly destined to roam the Semantic Web on our behalf could be thwarted
by documents which were either invalid or which hid their semantics under
elements chosen merely to achieve validity rather than to express structure
and semantics. That was why some demurred at what was I think by far the
most elegant *and* easily implemented of the solutions offered, namely
Francois' proposal to re-write the containing TEI <p> as am xhtml <div> and
the contained <blockquotes> as nested xhtml<div>s in their own right,
distinguishing their roles by values on the class attribute which could also
steer presentation via css.

Xhtml 1.0 is a serious attempt to slough off the legacy of html as a
presentational language and to focus on the modelling of structure. Given
the pressures on the WGs from different sides, I think they went
impressively far down that road. Xhtml 2.0, if it ever emerges, will go
still further in that direction, and may well make the particular issue used
to exemplify the problem in this thread otiose.  But for now, there can be
no completely satisfactory solution where the nesting of block quotations
within paragraphs is concerned, because the two DTDs have different ideas of
what a <p> is and how it relates to other elements.  That's why I perceive a
serious problem in the statement

> It didn't seem any less elegant than creating <p>s in the output that
> weren't in the input.

This seems to assume that a TEI <p> is the same thing as an xhtml <p>. But
it isn't. If it were we wouldn't have this thread in the first place. An
element is merely *recognised* by its name: it is *defined* by the DTD or
schema which assigns it that name. Elements with different names in
different XML vocabularies can have identical roles and semantics; elements
with the same name can, by the same token, have very different roles and
mean very different things in different vocabularies. Since all the two <p>s
have in common is their name and a shared subset of their semantics, a more
accurate rephrasing of that sentence would say "creating xthml <p>s in the
output that don't correspond to TEI <p>s in the input."  But that's just a
restatement of the problem we're trying to address, not a valid objection to
any proposed solution to it. It would not be a useful criticism of Francois'
proposal to say it involved "creating <div>s in the output that weren't in
the input."  Because of the vast gulf between the semantics of a TEI <div>
and an xhtml one, the inappropriateness of that remark is obvious. The
considerable semantic overlap between the two different things sharing the
name of <p> shouldn't mislead us into thinking of it as some kind of
identity, though.

Michael Beddow
=========================================================================
Date:         Mon, 31 Jan 2005 15:26:40 -0500
Reply-To:     Matthew Zimmerman <mz34@NYU.EDU>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Matthew Zimmerman <mz34@NYU.EDU>
Subject:      Presentation Tools SIG report - Baltimore 2004
Mime-Version: 1.0 (Apple Message framework v619.2)
Content-Transfer-Encoding: 7bit
Content-Type: text/plain; charset=US-ASCII; format=flowed

Here is a very tardy report from our SIG's activities at the Annual
Members' Meeting in Baltimore.

The notes are a bit lengthy but I hope you find the useful and I
welcome any comments or additions to the notes.

I will post them on the TEI site in a more reader-friendly format soon.

- Matt

--------------------------

TEI Presentation Tools Report from Baltimore, 2004.

The 2004 TEI Consortium Members' Meeting in Baltimore offered three
great opportunities for those of us interested in presentation/delivery
tools.

- a day long "pre-TEI" tools meeting on Oct 21st
- the scheduled SIG meeting on Oct 22nd
- a Tools Open House on Oct 22nd

Pre-TEI meeting, Thursday October 22nd

On Thursday, October 21st we held a "pre-TEI" full day tools meeting.
We chose the day before the meeting because it would afford us the full
day to devote to discussing tools. Of course, not everyone who would
like to have attended could, it being the day before the TEI meeting,
but we felt it was valuable to take advantage of the fact that so many
of us would be on the same continent at the same time.

Alice Hickox volunteered to take notes during the October 21st meeting
and her (slightly edited) notes follow:

Schedule:

13:00 - 13:15: Welcome

13:15 - 14:00: Matt and James (Tools List and Sample Collection)

14:00 - 14:45: Robert and Glen (xPhilologic)

14:45 - 15:15: Break

15:15 - 16:00: Jose Miguel (LEADERS)

16:00 - 16:45: Amit, John, and Susan (TEIPublisher)

16:45 - 17:30: Oyvind (Internal lisp program)

17:30 - 18:00: Closing

The Presentation Tools SIG has 2 initiatives: a tools list and a sample
collection of texts for testing.

Matthew Zimmerman showed a sample of the tools list developed by
Federico Meschini:

http://miro.acs.its.nyu.edu/tei_cms/show.php

The group discussed briefly what tools should be included, but did not
conclude
any particular list.

The group discussed the issue of sample texts, and how to manage them.
We agreed
that a list of sites where one could download or inquire about texts
would work
for the rights management and simplicity. We did not discuss mechanisms
to
collect volunteers or a site for the list. We wondered if it could be
connected
to the projects list on the TEI site.

The rest of the day was devoted to four demos of TEI delivery,
publication, or analysis tools.


--------------------------


Philologic: Robert Voyer, Orion Montoya and Glen Roe
http://philologic.uchicago.edu.

Philologic is an open source full-text search and retrieval and analysis
package.  It runs on Solaris, Debian, RedHat, and Mac OSX. It is
written in C and Perl. For speed in searching it does not use document
trees, but string searching and byte offsets. It does index paths. It
can accommodate TEILite XML, SGML,ATE(HTML with extensions for ARTFL),
and the markup does not need to be
well-formed. The flattened index structure allows faster searching.
Each word
is indexed. Standoff markup is used to collect bibliographic
information, stored in an external SQL database. Installing texts can
be done quickly on the command line. The OSX version has am ore GUI
interface. The program also does some word position analysis, and can
search for a word with variant spellings. There is no standard way to
handle attributes.


The LEADERS project: Jose Miguel Vieira
http://www.bookmarc.pt/
http://leaders.sourceforge.net/

This is a document-centric program that uses EAD, EAC TEI and NISOMIX in
combination to present manuscript text and images together. The
information is
harvested from TEI and stored in EAD format which is indexed for
searching.
It uses standard open source programs to achieve low cost, easy support
and
sustainability. It uses Apache Tomcat servlets, Cocoon and Lucene. It is
available at leaders.sourceforge.net under the BSD license.


TEI publisher: Amit Kumar and John Walsh
http://teipublisher.sourceforge.net/docs/index.php

This software is intended as a blackbox download that people can plug
in and use
to mount TEI documents. It needs only the skills to modify existing XSL
and CSS,
and to write HTML. One can create a repository, select documents,
choose nodes in the Header for browsing and searching, and can format
these for presentation to the user (text box or drop down list. Sort
options are available. It does full text searches, using, at the
administrators choice, eXist or Lucene. It always returns the entire
document. The site builder can configure headers footers, etc. This
software runs on many platforms, though there are some cosmetic
problems on OSX. There are a few constraints on the data that are
necessary to make it work, but they are not difficult to implement.

Oyvind Eide:

Oyvind Eide reported on his thesis project, a software program that
analyzed
names, occupations and language about geography in an 18th c. document
about
the establishment of the boundary of Norway and Sweden. It was written
in Lisp.
It tracked and generated lists of variant name spellings to connect
people with
testimonies across different pieces of text, and eventually provided
numbers
for statistical analysis in SPSS. If you are interested in hearing more
about Oyvind's work you should check out the Ontologies SIG
http://www.tei-c.org/Activities/SIG/Ontologies/


--------------------------


SIG Meeting, Saturday, October 23rd

On Saturday, October 21st at 9:00 we held our regulary scheduled annual
SIG meeting. This meeting covered what the SIG has done in the past
year and what will be done in the coming year.

As was discussed at the October 21st meeting, there are two "tracks" of
people in the SIG. Those who are in need of tools to publish and
deliver their TEI encoded-documents and those developing tools.

The developers are interested in getting a large collection of sample
texts with which to test their applications. Should the TEI house this
collection or just have the TEI act as meeting place for those who
would like to exchange texts? What are the copyright issues involved?

The tool users need the TEI to be a resource for tools, but what will
this resource look like? A tool list? A wiki? Should we produce a
survey to find out needs?

We left the meeting deciding to act on these points:

- Build a web resource
        - tool list with categories and descriptions
        - WIKI

- Plan mechanism for sharing sample collections

- Surveying people to find out how to categorize tools

- Use some existing parts of the TEI site (Projects, Applications)

- Consider overlap with other SIGS


--------------------------


Tools Open House, Saturday, Oct 23rd.

After the SIG meeting we had a one hour Open House for tools developers
to demo their tools to interested parties:

The tools demoed were:

Tapor
http://taporware.mcmaster.ca
(Geoffery Rockwell)

LEADERS
http://leaders.sourceforge.net/
(Jose Miguel Vieira)

Anastasia
http://http://anastasia.sourceforge.net/
(Peter Robinson)

teiPublisher
http://teipublisher.sourceforge.net/docs/index.php
(Amit Kumar, John Walsh, Susan Schreibman)

XMLStarlet
http://xmlstar.sourceforge.net/
(David Sewell)

Philologic
http://philologic.uchicago.edu/
(Mark Olsen)

Xaira
http://www.oucs.ox.ac.uk/rts/xaira/
(Lou Burnard)
=========================================================================
Date:         Mon, 31 Jan 2005 17:56:23 -0500
Reply-To:     Francois Lachance <lachance@ORIGIN.CHASS.UTORONTO.CA>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Francois Lachance <lachance@ORIGIN.CHASS.UTORONTO.CA>
Subject:      TAN: Those damn emacs codes (was: Re: Editors and medium-tech
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit

_A Handful of Observations and A Single Question_

Finger exercises for the migrating user from Emacs to other software
(or vice versa) ...

Cx-Cs to save in Emacs transfered to an application  where
Control+X is for cutting. Does the other software have an Undo function?
On a MacIntosh it is usually Command + Z. In a Windows environment it is,
I believe, usually Control + Z. Of course in Emacs it's Control C + _
[underscore i.e. shift + hyphen] -- a poetic way of "change-shifting".

Coming from elm and pico to Emacs, I had the opposite problem. Control + V
works as expected to advance through the display a screenful at a time.
Control + Y is the way to back up. For a while I found myself
inadvertantly yanking (aka pasting). Cured by opening a buffer and doing
six of seven yanks in a row -- certainly retrained the eye and hand fast.

Of course, after unwanted yanking one wants to learn undo too.

Disclosure : adapting keyboard habits comes with the territory: at home I
work on a Mac and dialup to a Unix box so I often go from Command + C to
Command + V to copy a chunk of text to the Telnet window and then
sometimes use Control + K and Control + U to edit within say a session of
elm. Sometimes I use the Mac commands to copy information from a Telnet
window running Lynx to a Telnet window running elm. At the place of
renumerated work it's a Windows environment.


In reference to the CUA mode
See Kim Storm's site
http://www.cua.dk/cua.html

<quote>

 Emacs Key CUA Key Function
   C-_       C-z     undo
   C-w       C-x     cut
   M-w       C-c     copy
   C-y       C-v     paste

   The tricky part is the handling of the C-x and C-c keys which are
   normally used as prefix keys for most of emacs' built-in commands.
   With CUA-mode they still do!!!

   Only when the region is currently active (and highlighted since
   transient-mark-mode is used), the C-x and C-c keys will work as CUA
   keys, i.e. cut and copy, but when the region is not active, C-x and
   C-c works as ordinary emacs prefix keys!

</quote>


Question: Are there any use cases of TEI-Emacs where on a selected and
higlighted region one would want to initiate a C-x chord {C-x plus another
key combo}? I'm curious. I should go read the manual and examine
all the  C-x initiated commands but I think posting the question to the
list might garner some more responses about people's work habits and that
such exchange informs collective knowledge out of which emerges new
possibilities and forgotten ones re-emerge too.

Thank you for the indulgence.


Dan wrote...

> The emacs sequence I have trouble with is Save current buffer: Cx-Cs. I
> do that by habit for save in all programs and have to keep an eye out I
> don't accidentally cut data out of something. Mostly its not a problem,
> but its been really bad the last little while while I've been doing a
> lot in Open Office's spread sheet. I keep deleting cell contents before
> saving the sheet.
>
> An interesting discussion.
> -dan
>
>
> Wendell Piez wrote:
> > At 03:56 PM 1/14/2005, you wrote:
> >
> >>This is an entirely reasonable perspective, but it's also true that
> >>recent versions of Emacs have become much more newbie-friendly, and
> >>the next version will be more so; e.g it will come with cua-mode
> >>pre-installed, which allows you to select, copy, and paste text in the
> >>way Windows users expect.
> >
> >
> > Ironically, ctrl-c, ctrl-x, ctrl-v, ctrl-z are part of what I have no
> > problem with. They're practically ubiquitous in text editors these days.


--
Francois Lachance, Scholar-at-large
http://www.chass.utoronto.ca/~lachance/jardin

2005 Year of Comparative Connections. DIA: Comparative connections? LOGZ:
Connection, first. Comparison, next. DIA: Check. Comparable ways of
connecting. LOGZ: Selection outcomes, first. Comparative Connections,
next.
=========================================================================
Date:         Mon, 31 Jan 2005 22:49:04 +0000
Reply-To:     Sebastian Rahtz <sebastian.rahtz@COMPUTING-SERVICES.OXFORD.AC.UK>
Sender:       "TEI (Text Encoding Initiative) public discussion list"
              <TEI-L@LISTSERV.BROWN.EDU>
From:         Sebastian Rahtz <sebastian.rahtz@COMPUTING-SERVICES.OXFORD.AC.UK>
Subject:      more ways to get TEI P5
MIME-Version: 1.0
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit

Interested in TEI P5? Wondering how to get started? here's two ways:

1. go to http://sourceforge.net/project/showfiles.php?group_id=106328
and look for the "tei" package. This is a .tar.gz archive with a
complete runtime system of TEI P4 and P5, DTDs, schemas, stylesheets,
what have you, in the file layout recommended for Debian Linux. The tree
starts with "tei", and Debian recommend putting that in /usr/share/xml
on a Linux system, but you can unpack it where you like and point your
editor at it

or

2. go to http://www.tei-c.org/Software/tei-emacs and download the latest
edition of TEI Emacs, a complete copy of Gnu Emacs for Windows set up
for TEI work. again. DTD, schemas, stylesheets all ready to roll.

Want a setup for your favourite editor/tool? help us out - describe what
sort of bundle you want, and I'll see if its
easy to create it automatically.

--
Sebastian Rahtz
Information Manager, Oxford University Computing Services
13 Banbury Road, Oxford OX2 6NN. Phone +44 1865 283431

OSS Watch: JISC Open Source Advisory Service
http://www.oss-watch.ac.uk